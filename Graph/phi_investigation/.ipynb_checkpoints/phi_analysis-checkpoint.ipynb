{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "# Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a graph $\\Gamma$ and a weak stability condition $\\sigma_{\\Gamma}$ we want to produce a $\\phi$ such that $\\sigma_{\\Gamma}=\\sigma_{\\Gamma}^{\\phi}$. To do so we construct regions $R_{\\sigma_{\\Gamma}}$ or $\\bigcap_{T \\in \\mathcal{ST}(\\Gamma)} R_{\\sigma_{\\Gamma}}^{T}$ and pick appropriate $\\phi$ (which we beleive are inside such polytopes) and check if the set of assignments created by such $\\phi$ conisist with $\\sigma_{\\Gamma}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Objectives:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a weak stabilty condition $\\sigma_{\\Gamma}$ we:\n",
    "\n",
    "- Give a method to construct $\\bigcap_{T \\in \\mathcal{ST}(\\Gamma)} R_{\\sigma_{\\Gamma}(T)}$ and $R_{\\sigma_{\\Gamma}(\\Gamma)}$.\n",
    "\n",
    "- Analyse these polytopes and check if equal.\n",
    "\n",
    "- If these are equal we choose a reprsentative $\\phi$ inside and as if that generate the same assingments as $\\sigma_{\\Gamma}$ and hence this gives us $\\sigma_{\\Gamma}=\\sigma_{\\Gamma}^{\\phi}$ if true.\n",
    "\n",
    "- As part of this process we give a method that takes any $\\phi$ and produces as set of assignments. \n",
    "\n",
    "- Using this method propose explicity $phi$ and check if these also generate the set of assignments for $\\sigma_{\\Gamma}$.\n",
    "\n",
    "- These include:\n",
    "    - Taking the average of $\\sigma_{\\Gamma}(\\Gamma)$ i.e $\\phi_{av}$\n",
    "    - The canoncial phi (for the all zero case).\n",
    "    -  average translated by the break and canonical $\\phi$ case\n",
    "    \n",
    "- We store this analysis in a list in \"...Stability_Conditions\\Graph\\phi_investigation\\examples\\{graphname}\\phi_analysis\"\n",
    "\n",
    "in the form of a summary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is enough to focus on $\\bigcap_{T \\in \\mathcal{ST}(\\Gamma)} R_{\\sigma_{\\Gamma}(T)}$ \n",
    "\n",
    "We investigate all \"graphs\" (top of stratification) of $\\overline{M}_{2,n}$ up to $n=5$.\n",
    "\n",
    "We see that of these graphs $\\bigcap_{T \\in \\mathcal{ST}(\\Gamma)} R_{\\sigma_{\\Gamma}(T)}$ is always non-empty. As for all weak stability conditions the associated polytope has dimension $|V(\\Gamma)|-1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results:\n",
    "    \n",
    "    - We see taking the average $\\phi$ fails for $G63$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "# Table of contents\n",
    "1. [Summary of results as table](#s1)\n",
    "    1. [Cyclic graphs: genus 1](#s11)\n",
    "    2. [Genus 2 graphs with middle edges](#s12)\n",
    "        1. [$k_1=1,k_2=1,k_3$](#s121)\n",
    "        3. [$k_1=1,k_2,k_3$](#s122)\n",
    "    3. [Higher genus graphs](#s13)\n",
    "    4. [Vine blowups](#s14)\n",
    "2. [Specific $\\phi$ ](#spec)\n",
    "    1. [Examples of phi terms](#spec1)\n",
    "    2. [Inspecting phi_av for GNkM1](#spec2)\n",
    "3. [Given $\\phi$ get assignments](#phi)\n",
    "4. [Construct Graph-Poly](#Graph-Poly)\n",
    "5. [Construct Tree-Poly](#ConstructTree-Poly)\n",
    "6. [Check Tree-Poly and Graph-Poly are equal](#analyse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Summary of results as table <a name=\"s1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have previously caculated all weak stability conditions (wsc) up to translation for a selection of graphs.\n",
    "\n",
    "For a given graph we construct a table analysisng the each wsc and if diffient phi's generate the same assignments. We record,\n",
    "\n",
    "- Do the tree-polytope equal the graph-polytope (True/False)\n",
    "- If a representative phi generates the same set of wsc-assignments (True/False)\n",
    "- If the average-phi (the average of $\\vec{d} \\in \\sigma_{\\Gamma}(\\Gamma))$ generates the same set of wsc-assignments.(True/False)\n",
    "- If the average-phi translated (by $\\phi_{can}-\\phi_{av-breaks}$ or $\\phi_{av-breaks}-\\phi_{can}$) generates the same set of wsc-assignments.(True/False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "## Cyclic graphs: genus 1 <a name=\"s11\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### G3 D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphname=\"G3\"\n",
    "G=Graph([(\"0\",\"1\"),(\"1\",\"2\"),(\"2\",\"0\")], multiedges=True)\n",
    "\n",
    "data=unpickle(graphname) #Size=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[([[0, 0, 0], [0, 0, 0], [0, 0, 0]], array([[0, 0, 1],\n",
      "       [0, 1, 0],\n",
      "       [1, 0, 0]], dtype=int32), [(Graph on 3 vertices, [0, 0, 0]), (Graph on 3 vertices, [0, 0, 0]), (Graph on 3 vertices, [0, 0, 0])], [(Multi-graph on 3 vertices, (1, 3, 2), Multi-graph on 3 vertices)]), ([[0, 0, 0], [0, 1, -1], [1, 0, -1]], array([[ 0,  1,  0],\n",
      "       [ 1,  0,  0],\n",
      "       [ 1,  1, -1]], dtype=int32), [(Graph on 3 vertices, [0, 0, 0]), (Graph on 3 vertices, [0, 1, -1]), (Graph on 3 vertices, [1, 0, -1])], [(Multi-graph on 3 vertices, (1, 2, 3), Multi-graph on 3 vertices)])]\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start= 0 ---- 0 ----terminator: False\n",
      "Start= 0 ---- 1 ----terminator: False\n"
     ]
    }
   ],
   "source": [
    "#Are we picking the index of the break case properly? #Y ind_breaks=0\n",
    "# data=unpickle(graphname)\n",
    "# for i in data:\n",
    "#     print(i)\n",
    "\n",
    "dic_l=analyse_graphname(G,data,ind_breaks=0)\n",
    "\n",
    "#Store list of dictionaries\n",
    "# pickle_dic_l(graphname,dic_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of wsc 2\n",
      "Number of polytopes of a given (dimension:number of at dim): {2: 2}\n",
      "Number of wsc that are/are not generated by phi_av: {True: 2}\n",
      "Number of wsc that are/are not generated by phi_can: None\n",
      "Number of wsc that are/are not generated by phi_av_translated1: None\n",
      "Number of wsc that are/are not generated by phi_av_translated2: None\n",
      "Number of wsc that are/are not generated by phi_av_translated3: None\n",
      "Number of wsc that are/are not generated by phi_av_translated4: None\n",
      "Number of wsc that are/are not generated by phi_av_translated5: None\n",
      "Number of wsc that are/are not generated by phi_av_translated6: None\n",
      "Number of wsc that are/are not generated by phi_av_translated7: None\n",
      "Number of wsc that are/are not generated by phi_av_translated8: None        \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Store list of dictionaries\n",
    "# pickle_dic_l(graphname,dic_l)\n",
    "\n",
    "analyse_table(dic_l,f=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### G4 D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start= 0 ---- 0 ----terminator: False\n",
      "Start= 0 ---- 1 ----terminator: False\n",
      "Start= 0 ---- 2 ----terminator: False\n",
      "Start= 0 ---- 3 ----terminator: False\n",
      "Start= 0 ---- 4 ----terminator: False\n",
      "Start= 0 ---- 5 ----terminator: False\n"
     ]
    }
   ],
   "source": [
    "graphname=\"G4\"\n",
    "G=Graph([(\"0\",\"1\"),(\"1\",\"2\"),(\"2\",\"3\"),(\"3\",\"0\")], multiedges=True)\n",
    "\n",
    "data=unpickle(graphname) #Size=6\n",
    "\n",
    "# Are we picking the index of the break case properly? #Y ind_breaks=0\n",
    "# data=unpickle(graphname)\n",
    "# for i in data:\n",
    "#     print(i)\n",
    "\n",
    "dic_l=analyse_graphname(G,data,ind_breaks=0)\n",
    "\n",
    "#Store list of dictionaries\n",
    "pickle_dic_l(graphname,dic_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of wsc 6\n",
      "Number of wsc that do/do not satisfy graph poly == tree poly: {True: 6}\n",
      "Number of polytopes of a given (dimension:number of at dim): {3: 6}\n",
      "Number of wsc that are/are not generated by phi_rep: {True: 6}\n",
      "Number of wsc that are/are not generated by phi_av: {True: 6}\n",
      "Number of wsc that are/are not generated by phi_can: None\n",
      "Number of wsc that are/are not generated by phi_av_translated1: None\n",
      "Number of wsc that are/are not generated by phi_av_translated2: None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "analyse_table(dic_l,f=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### G5 D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start= 0 ---- 0 ----terminator: False\n",
      "Start= 0 ---- 1 ----terminator: False\n",
      "Start= 0 ---- 2 ----terminator: False\n",
      "Start= 0 ---- 3 ----terminator: False\n",
      "Start= 0 ---- 4 ----terminator: False\n",
      "Start= 0 ---- 5 ----terminator: False\n",
      "Start= 0 ---- 6 ----terminator: False\n",
      "Start= 0 ---- 7 ----terminator: False\n",
      "Start= 0 ---- 8 ----terminator: False\n",
      "Start= 0 ---- 9 ----terminator: False\n",
      "Start= 0 ---- 10 ----terminator: False\n",
      "Start= 0 ---- 11 ----terminator: False\n",
      "Start= 0 ---- 12 ----terminator: False\n",
      "Start= 0 ---- 13 ----terminator: False\n",
      "Start= 0 ---- 14 ----terminator: False\n",
      "Start= 0 ---- 15 ----terminator: False\n",
      "Start= 0 ---- 16 ----terminator: False\n",
      "Start= 0 ---- 17 ----terminator: False\n",
      "Start= 0 ---- 18 ----terminator: False\n",
      "Start= 0 ---- 19 ----terminator: False\n",
      "Start= 0 ---- 20 ----terminator: False\n",
      "Start= 0 ---- 21 ----terminator: False\n",
      "Start= 0 ---- 22 ----terminator: False\n",
      "Start= 0 ---- 23 ----terminator: False\n"
     ]
    }
   ],
   "source": [
    "graphname=\"G5\"\n",
    "G=Graph([(\"0\",\"1\"),(\"1\",\"2\"),(\"2\",\"3\"),(\"3\",\"4\"),(\"4\",\"0\")], multiedges=True)\n",
    "\n",
    "data=unpickle(graphname) #Size=24\n",
    "\n",
    "#Are we picking the index of the break case properly? #Y ind_breaks=0\n",
    "# data=unpickle(graphname)\n",
    "# for i in data:\n",
    "#     print(i)\n",
    "\n",
    "dic_l=analyse_graphname(G,data,ind_breaks=0)\n",
    "\n",
    "#Store list of dictionaries\n",
    "pickle_dic_l(graphname,dic_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of wsc 24\n",
      "Number of wsc that do/do not satisfy graph poly == tree poly: {True: 24}\n",
      "Number of polytopes of a given (dimension:number of at dim): {4: 24}\n",
      "Number of wsc that are/are not generated by phi_rep: {True: 24}\n",
      "Number of wsc that are/are not generated by phi_av: {True: 24}\n",
      "Number of wsc that are/are not generated by phi_can: None\n",
      "Number of wsc that are/are not generated by phi_av_translated1: None\n",
      "Number of wsc that are/are not generated by phi_av_translated2: None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "analyse_table(dic_l,f=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Genus 2 graphs with middle edges $ <a name=\"s12\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### $k_1=1,k_2=1,k_3$ <a name=\"s121\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### G3M1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start= 0 ---- 0 ----terminator: False\n",
      "Start= 0 ---- 1 ----terminator: False\n"
     ]
    }
   ],
   "source": [
    "graphname=\"G3M1\" \n",
    "G=Graph([(\"0\",\"1\",\"e11\"),(\"1\",\"2\",\"e2\"),(\"2\",\"0\",\"e3\"),(\"0\",\"1\",\"e12\")], multiedges=True)\n",
    "# spanning_trees_e=[tree for tree in GM1e.spanning_trees(labels=True)]\n",
    "\n",
    "data=unpickle(graphname) #Size=2\n",
    "\n",
    "#Are we picking the index of the break case properly? #Y ind_breaks=0\n",
    "# data=unpickle(graphname)\n",
    "# for i in data:\n",
    "#     print(i)\n",
    "\n",
    "dic_l=analyse_graphname(G,data,ind_breaks=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of wsc 2\n",
      "Number of wsc that do/do not satisfy graph poly == tree poly: {True: 2}\n",
      "Number of polytopes of a given (dimension:number of at dim): {2: 2}\n",
      "Number of wsc that are/are not generated by phi_rep: {True: 2}\n",
      "Number of wsc that are/are not generated by phi_av: {True: 2}\n",
      "Number of wsc that are/are not generated by phi_can: {True: 1, False: 1}\n",
      "Number of wsc that are/are not generated by phi_av_translated1: {True: 2}\n",
      "Number of wsc that are/are not generated by phi_av_translated2: {True: 2}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# analyse_table(dic_l,f=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle_dic_l(graphname,dic_l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### G4M1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start= 0 ---- 0 ----terminator: False\n",
      "Start= 0 ---- 1 ----terminator: False\n",
      "Start= 0 ---- 2 ----terminator: False\n",
      "Start= 0 ---- 3 ----terminator: False\n",
      "Start= 0 ---- 4 ----terminator: False\n",
      "Start= 0 ---- 5 ----terminator: False\n"
     ]
    }
   ],
   "source": [
    "graphname=\"G4M1\" \n",
    "G=Graph([(\"0\",\"1\",\"e11\"),(\"1\",\"2\",\"e2\"),(\"2\",\"3\",\"e3\"),(\"3\",\"0\",\"e4\"),(\"0\",\"1\",\"e12\")], multiedges=True)\n",
    "\n",
    "data=unpickle(graphname) #Size=6\n",
    "\n",
    "# # Are we picking the index of the break case properly? #Y ind_breaks=0\n",
    "# data=unpickle(graphname)\n",
    "# for i in data:\n",
    "#     print(i)\n",
    "\n",
    "dic_l=analyse_graphname(G,data,ind_breaks=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of wsc 6\n",
      "Number of wsc that do/do not satisfy graph poly == tree poly: {True: 6}\n",
      "Number of polytopes of a given (dimension:number of at dim): {3: 6}\n",
      "Number of wsc that are/are not generated by phi_rep: {True: 6}\n",
      "Number of wsc that are/are not generated by phi_av: {True: 6}\n",
      "Number of wsc that are/are not generated by phi_can: {True: 1, False: 5}\n",
      "Number of wsc that are/are not generated by phi_av_translated1: {True: 6}\n",
      "Number of wsc that are/are not generated by phi_av_translated2: {True: 6}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "analyse_table(dic_l,f=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_dic_l(graphname,dic_l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### G5M1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start= 0 ---- 0 ----terminator: False\n",
      "Start= 0 ---- 1 ----terminator: False\n",
      "Start= 0 ---- 2 ----terminator: False\n",
      "Start= 0 ---- 3 ----terminator: False\n",
      "Start= 0 ---- 4 ----terminator: False\n",
      "Start= 0 ---- 5 ----terminator: False\n",
      "Start= 0 ---- 6 ----terminator: False\n",
      "Start= 0 ---- 7 ----terminator: False\n",
      "Start= 0 ---- 8 ----terminator: False\n",
      "Start= 0 ---- 9 ----terminator: False\n",
      "Start= 0 ---- 10 ----terminator: False\n",
      "Start= 0 ---- 11 ----terminator: False\n",
      "Start= 0 ---- 12 ----terminator: False\n",
      "Start= 0 ---- 13 ----terminator: False\n",
      "Start= 0 ---- 14 ----terminator: False\n",
      "Start= 0 ---- 15 ----terminator: False\n",
      "Start= 0 ---- 16 ----terminator: False\n",
      "Start= 0 ---- 17 ----terminator: False\n",
      "Start= 0 ---- 18 ----terminator: False\n",
      "Start= 0 ---- 19 ----terminator: False\n",
      "Start= 0 ---- 20 ----terminator: False\n",
      "Start= 0 ---- 21 ----terminator: False\n",
      "Start= 0 ---- 22 ----terminator: False\n",
      "Start= 0 ---- 23 ----terminator: False\n"
     ]
    }
   ],
   "source": [
    "graphname=\"G5M1\" \n",
    "G=Graph([(\"0\",\"1\",\"e11\"),(\"1\",\"2\",\"e2\"),(\"2\",\"3\",\"e3\"),(\"3\",\"4\",\"e4\"),(\"4\",\"0\",\"e5\"),(\"0\",\"1\",\"e12\")], multiedges=True)\n",
    "\n",
    "data=unpickle(graphname) #Size=24\n",
    "\n",
    "#Are we picking the index of the break case properly? #Y ind_breaks=0\n",
    "# data=unpickle(graphname)\n",
    "# for i in data:\n",
    "#     print(i)\n",
    "\n",
    "dic_l=analyse_graphname(G,data,ind_breaks=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of wsc 24\n",
      "Number of wsc that do/do not satisfy graph poly == tree poly: {True: 24}\n",
      "Number of polytopes of a given (dimension:number of at dim): {4: 24}\n",
      "Number of wsc that are/are not generated by phi_rep: {True: 24}\n",
      "Number of wsc that are/are not generated by phi_av: {True: 24}\n",
      "Number of wsc that are/are not generated by phi_can: {True: 1, False: 23}\n",
      "Number of wsc that are/are not generated by phi_av_translated1: {True: 24}\n",
      "Number of wsc that are/are not generated by phi_av_translated2: {True: 24}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "analyse_table(dic_l,f=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_dic_l(graphname,dic_l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "### $k_1=1,k_2,k_3$ <a name=\"s122\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### G4M2 D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start= 0 ---- 0 ----terminator: False\n",
      "Start= 0 ---- 1 ----terminator: False\n",
      "Start= 0 ---- 2 ----terminator: False\n",
      "Start= 0 ---- 3 ----terminator: False\n",
      "Start= 0 ---- 4 ----terminator: False\n",
      "Start= 0 ---- 5 ----terminator: False\n"
     ]
    }
   ],
   "source": [
    "graphname=\"G4M2\" \n",
    "G=Graph([(\"0\",\"1\"),(\"1\",\"2\"),(\"2\",\"3\"),(\"3\",\"0\"),(\"0\",\"2\")], multiedges=True)\n",
    "\n",
    "data=unpickle(graphname) #Size=6\n",
    "\n",
    "#Are we picking the index of the break case properly? #Y ind_breaks=0\n",
    "# data=unpickle(graphname)\n",
    "# for i in data:\n",
    "#     print(i)\n",
    "\n",
    "dic_l=analyse_graphname(G,data,ind_breaks=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Store list of dictionaries\n",
    "# pickle_dic_l(graphname,dic_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of wsc 6\n",
      "Number of polytopes of a given (dimension:number of at dim): {3: 6}\n",
      "Number of wsc that are/are not generated by phi_av: {True: 6}\n",
      "Number of wsc that are/are not generated by phi_can: {True: 1, False: 5}\n",
      "Number of wsc that are/are not generated by phi_av_translated1: {False: 6}\n",
      "Number of wsc that are/are not generated by phi_av_translated2: {False: 1, True: 5}\n",
      "Number of wsc that are/are not generated by phi_av_translated3: {True: 5, False: 1}\n",
      "Number of wsc that are/are not generated by phi_av_translated4: {True: 1, False: 5}\n",
      "Number of wsc that are/are not generated by phi_av_translated5: {False: 6}\n",
      "Number of wsc that are/are not generated by phi_av_translated6: {False: 6}\n",
      "Number of wsc that are/are not generated by phi_av_translated7: {False: 6}\n",
      "Number of wsc that are/are not generated by phi_av_translated8: {False: 6}        \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "analyse_table(dic_l,f=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### G5M2 D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start= 0 ---- 0 ----terminator: False\n",
      "Start= 0 ---- 1 ----terminator: False\n",
      "Start= 0 ---- 2 ----terminator: False\n",
      "Start= 0 ---- 3 ----terminator: False\n",
      "Start= 0 ---- 4 ----terminator: False\n",
      "Start= 0 ---- 5 ----terminator: False\n",
      "Start= 0 ---- 6 ----terminator: False\n",
      "Start= 0 ---- 7 ----terminator: False\n",
      "Start= 0 ---- 8 ----terminator: False\n",
      "Start= 0 ---- 9 ----terminator: False\n",
      "Start= 0 ---- 10 ----terminator: False\n",
      "Start= 0 ---- 11 ----terminator: False\n",
      "Start= 0 ---- 12 ----terminator: False\n",
      "Start= 0 ---- 13 ----terminator: False\n",
      "Start= 0 ---- 14 ----terminator: False\n",
      "Start= 0 ---- 15 ----terminator: False\n",
      "Start= 0 ---- 16 ----terminator: False\n",
      "Start= 0 ---- 17 ----terminator: False\n",
      "Start= 0 ---- 18 ----terminator: False\n",
      "Start= 0 ---- 19 ----terminator: False\n",
      "Start= 0 ---- 20 ----terminator: False\n",
      "Start= 0 ---- 21 ----terminator: False\n",
      "Start= 0 ---- 22 ----terminator: False\n",
      "Start= 0 ---- 23 ----terminator: False\n"
     ]
    }
   ],
   "source": [
    "graphname=\"G5M2\"\n",
    "G=Graph([(\"0\",\"1\"),(\"1\",\"2\"),(\"2\",\"3\"),(\"3\",\"4\"),(\"4\",\"0\"),(\"0\",\"2\")], multiedges=True)\n",
    "\n",
    "data=unpickle(graphname) #Size=24\n",
    "\n",
    "#Are we picking the index of the break case properly? #Y ind_breaks=0\n",
    "# data=unpickle(graphname)\n",
    "# for i in data:\n",
    "#     print(i)\n",
    "\n",
    "dic_l=analyse_graphname(G,data,ind_breaks=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Store list of dictionaries\n",
    "pickle_dic_l(graphname,dic_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of wsc 24\n",
      "Number of wsc that do/do not satisfy graph poly == tree poly: {True: 24}\n",
      "Number of polytopes of a given (dimension:number of at dim): {4: 24}\n",
      "Number of wsc that are/are not generated by phi_rep: {True: 24}\n",
      "Number of wsc that are/are not generated by phi_av: {True: 24}\n",
      "Number of wsc that are/are not generated by phi_can: {True: 1, False: 23}\n",
      "Number of wsc that are/are not generated by phi_av_translated1: {True: 16, False: 8}\n",
      "Number of wsc that are/are not generated by phi_av_translated2: {False: 8, True: 16}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "analyse_table(dic_l,f=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### G6M2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start= 0 ---- 0 ----terminator: 1\n",
      "Start= 0 ---- 1 ----terminator: 1\n"
     ]
    }
   ],
   "source": [
    "graphname=\"G6M2\"\n",
    "G=Graph([(\"0\",\"1\"),(\"1\",\"2\"),(\"2\",\"3\"),(\"3\",\"4\"),(\"4\",\"5\"),(\"5\",\"0\"),(\"0\",\"2\")], multiedges=True)\n",
    "\n",
    "data=unpickle(graphname) #Size=120\n",
    "\n",
    "# #Are we picking the index of the break case properly? #Y ind_breaks=0\n",
    "# data=unpickle(graphname)\n",
    "# for i in data:\n",
    "#     print(i)\n",
    "\n",
    "#first non-trivial case where average fails.\n",
    "# dic_l=analyse_graphname(G,data,terminator=1,ind_breaks=0)\n",
    "\n",
    "dic_l=analyse_graphname(G,data,ind_breaks=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'tree-poly equals graph-poly': True,\n",
       "  'Dimension of graph-poly': 5,\n",
       "  'phi_rep': [0.667, 0.167, 0.667, 0.167, 0.167, 0.167],\n",
       "  'frac_phi_rep': (2/3, 1/6, 2/3, 1/6, 1/6, 1/6),\n",
       "  'phi_rep generates wsc-assignments?': True,\n",
       "  'phi_av': [Fraction(1, 2),\n",
       "   Fraction(5, 14),\n",
       "   Fraction(1, 2),\n",
       "   Fraction(3, 14),\n",
       "   Fraction(3, 14),\n",
       "   Fraction(3, 14)],\n",
       "  'frac_phi_av': ['1/2', '5/14', '1/2', '3/14', '3/14', '3/14'],\n",
       "  'phi_av generates wsc-assignments?': False,\n",
       "  'phi_can': [5/7, 1/7, 5/7, 1/7, 1/7, 1/7],\n",
       "  'phi_can generates wsc-assignments?': True,\n",
       "  'phi_av_trans1': [0.7143, 0.1429, 0.7143, 0.1429, 0.1429, 0.1429],\n",
       "  'phi_av_trans1 generates wsc-assignments?': True,\n",
       "  'phi_av_trans2': [0.2857, 0.5714, 0.2857, 0.2857, 0.2857, 0.2857],\n",
       "  'phi_av_trans2 generates wsc-assignments?': False}]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dic_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Store list of dictionaries\n",
    "pickle_dic_l(graphname,dic_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyse_table(dic_l,f=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### G6M3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "graphname=\"G6M3\"  \n",
    "G=Graph([(\"0\",\"1\"),(\"1\",\"2\"),(\"2\",\"3\"),(\"3\",\"4\"),(\"4\",\"5\"),(\"5\",\"0\"),(\"0\",\"3\")], multiedges=True)\n",
    "\n",
    "\n",
    "data=unpickle(graphname) #Size=120\n",
    "\n",
    "#Are we picking the index of the break case properly? #Y ind_breaks=0\n",
    "# data=unpickle(graphname)\n",
    "# for i in data:\n",
    "#     print(i)\n",
    "\n",
    "dic_l=analyse_graphname(G,data,ind_breaks=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Store list of dictionaries\n",
    "pickle_dic_l(graphname,dic_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyse_table(dic_l,f=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "## Higher genus graphs <a name=\"s13\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### G4M02M13 D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start= 0 ---- 0 ----terminator: False\n",
      "Start= 0 ---- 1 ----terminator: False\n",
      "Start= 0 ---- 2 ----terminator: False\n",
      "Start= 0 ---- 3 ----terminator: False\n",
      "Start= 0 ---- 4 ----terminator: False\n",
      "Start= 0 ---- 5 ----terminator: False\n",
      "Start= 0 ---- 6 ----terminator: False\n",
      "Start= 0 ---- 7 ----terminator: False\n",
      "Start= 0 ---- 8 ----terminator: False\n",
      "Start= 0 ---- 9 ----terminator: False\n"
     ]
    }
   ],
   "source": [
    "graphname=\"G4M02M13\"\n",
    "G=Graph([(\"0\",\"1\"),(\"1\",\"2\"),(\"2\",\"3\"),(\"3\",\"0\"),(\"0\",\"2\"),(\"1\",\"3\")], multiedges=True)\n",
    "\n",
    "data=unpickle(graphname) #Size=10\n",
    "\n",
    "# #Are we picking the index of the break case properly? #Y ind_breaks=0\n",
    "# data=unpickle(graphname)\n",
    "# for i in data:\n",
    "#     print(i)\n",
    "\n",
    "dic_l=analyse_graphname(G,data,ind_breaks=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Store list of dictionaries\n",
    "pickle_dic_l(graphname,dic_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of wsc 10\n",
      "Number of wsc that do/do not satisfy graph poly == tree poly: {True: 10}\n",
      "Number of polytopes of a given (dimension:number of at dim): {3: 10}\n",
      "Number of wsc that are/are not generated by phi_rep: {True: 10}\n",
      "Number of wsc that are/are not generated by phi_av: {True: 10}\n",
      "Number of wsc that are/are not generated by phi_can: {True: 1, False: 9}\n",
      "Number of wsc that are/are not generated by phi_av_translated1: {True: 10}\n",
      "Number of wsc that are/are not generated by phi_av_translated2: {True: 10}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "analyse_table(dic_l,f=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### G5M02M03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "graphname=\"G5M02M03\"\n",
    "G=Graph([(\"0\",\"1\"),(\"1\",\"2\"),(\"2\",\"3\"),(\"3\",\"4\"),(\"4\",\"0\"),(\"0\",\"2\"),(\"0\",\"3\")], multiedges=True)\n",
    "\n",
    "data=unpickle(graphname) #Size=24\n",
    "\n",
    "#Are we picking the index of the break case properly? #Y ind_breaks=0\n",
    "# data=unpickle(graphname)\n",
    "# for i in data:\n",
    "#     print(i)\n",
    "\n",
    "dic_l=analyse_graphname(G,data,ind_breaks=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Store list of dictionaries\n",
    "pickle_dic_l(graphname,dic_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyse_table(dic_l,f=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### G5M02M03M14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "graphname=\"G5M02M03M14\"\n",
    "G=Graph([(\"0\",\"1\"),(\"1\",\"2\"),(\"2\",\"3\"),(\"3\",\"4\"),(\"4\",\"0\"),(\"0\",\"2\"),(\"0\",\"3\"),(\"1\",\"4\")], multiedges=True)\n",
    "\n",
    "data=unpickle(graphname) #Size=82\n",
    "\n",
    "#Are we picking the index of the break case properly? #Y ind_breaks=0\n",
    "# data=unpickle(graphname)\n",
    "# for i in data:\n",
    "#     print(i)\n",
    "\n",
    "dic_l=analyse_graphname(G,data,ind_breaks=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Store list of dictionaries\n",
    "pickle_dic_l(graphname,dic_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyse_table(dic_l,f=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I3 example (load in stability conditions from good moves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphname=\"G3\"\n",
    "g=Graph([(\"0\",\"1\"),(\"1\",\"2\"),(\"2\",\"0\")], multiedges=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = r\"..\\CSR_good_moves\\examples\\I3.pkl\"\n",
    "with open(filename, 'rb') as f:\n",
    "    unpickled_list = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[([[-1, 0, 1], [-1, 1, 0], [0, 0, 0]],\n",
       "  array([[-1,  1,  1],\n",
       "         [ 0,  0,  1],\n",
       "         [ 0,  1,  0]], dtype=int32),\n",
       "  [(Graph on 3 vertices, [-1, 0, 1]),\n",
       "   (Graph on 3 vertices, [-1, 1, 0]),\n",
       "   (Graph on 3 vertices, [0, 0, 0])],\n",
       "  None)]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=unpickled_list\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start= 0 ---- 0 ----terminator: False\n"
     ]
    }
   ],
   "source": [
    "#previous version.\n",
    "\n",
    "# [([[0, 0, 0], [0, 0, 0], [0, 0, 0]], array([[0, 0, 1],\n",
    "#        [0, 1, 0],\n",
    "#        [1, 0, 0]], dtype=int32),\n",
    "#   [(Graph on 3 vertices, [0, 0, 0]), (Graph on 3 vertices, [0, 0, 0]), (Graph on 3 vertices, [0, 0, 0])],\n",
    "#   [(Multi-graph on 3 vertices, (1, 3, 2), Multi-graph on 3 vertices)]), \n",
    " \n",
    "#  ([[0, 0, 0], [0, 1, -1], [1, 0, -1]],\n",
    "  \n",
    "#   array([[ 0,  1,  0],\n",
    "#        [ 1,  0,  0],\n",
    "#        [ 1,  1, -1]], dtype=int32),\n",
    "  \n",
    "#   [(Graph on 3 vertices, [0, 0, 0]), (Graph on 3 vertices, [0, 1, -1]), (Graph on 3 vertices, [1, 0, -1])],\n",
    "#   [(Multi-graph on 3 vertices, (1, 2, 3), Multi-graph on 3 vertices)])]\n",
    "\n",
    "#Dont need\n",
    "#Are we picking the index of the break case properly? #Y ind_breaks=0\n",
    "# data=unpickle(graphname)\n",
    "# for i in data:\n",
    "#     print(i)\n",
    "\n",
    "dic_l=analyse_graphname(g,data,ind_breaks=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Dimension of tree-poly': 2,\n",
       "  'phi_av': [Fraction(-1, 3), Fraction(2, 3), Fraction(2, 3)],\n",
       "  'frac_phi_av': ['-1/3', '2/3', '2/3'],\n",
       "  'phi_av generates wsc-assignments?': True}]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Store list of dictionaries\n",
    "# pickle_dic_l(graphname,dic_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyse_table(dic_l,f=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### wheel_graph_family:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphname=\"Wheel_4\"\n",
    "g=Graph([('0', '1'), ('0', '2'), ('0', '3'), ('1', '2'), ('1', '3'), ('2', '3')], multiedges=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = r\"..\\CSR_good_moves\\examples\\wheel_graph_family\\Wheel_4.pkl\"\n",
    "with open(filename, 'rb') as f:\n",
    "    unpickled_list = pickle.load(f)\n",
    "    \n",
    "data=unpickled_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[([[-1, 0, 0, 1],\n",
       "   [-1, 0, 1, 0],\n",
       "   [-1, 1, 0, 0],\n",
       "   [-1, 0, 0, 1],\n",
       "   [-1, 0, 1, 0],\n",
       "   [-1, 1, 0, 0],\n",
       "   [-1, 0, 0, 1],\n",
       "   [-1, 0, 1, 0],\n",
       "   [-1, 1, 0, 0],\n",
       "   [0, 0, 0, 0],\n",
       "   [0, 0, 0, 0],\n",
       "   [0, 0, 0, 0],\n",
       "   [0, 0, 0, 0],\n",
       "   [0, 0, 0, 0],\n",
       "   [0, 0, 0, 0],\n",
       "   [0, 0, 0, 0]],\n",
       "  array([[-1,  1,  1,  2],\n",
       "         [-1,  1,  2,  1],\n",
       "         [-1,  2,  1,  1],\n",
       "         [ 0,  0,  1,  2],\n",
       "         [ 0,  0,  2,  1],\n",
       "         [ 0,  1,  0,  2],\n",
       "         [ 0,  1,  1,  1],\n",
       "         [ 0,  1,  2,  0],\n",
       "         [ 0,  2,  0,  1],\n",
       "         [ 0,  2,  1,  0],\n",
       "         [ 1,  0,  0,  2],\n",
       "         [ 1,  0,  1,  1],\n",
       "         [ 1,  0,  2,  0],\n",
       "         [ 1,  1,  0,  1],\n",
       "         [ 1,  1,  1,  0],\n",
       "         [ 1,  2,  0,  0]], dtype=int32),\n",
       "  [(Graph on 4 vertices, [-1, 0, 0, 1]),\n",
       "   (Graph on 4 vertices, [-1, 0, 1, 0]),\n",
       "   (Graph on 4 vertices, [-1, 1, 0, 0]),\n",
       "   (Graph on 4 vertices, [-1, 0, 0, 1]),\n",
       "   (Graph on 4 vertices, [-1, 0, 1, 0]),\n",
       "   (Graph on 4 vertices, [-1, 1, 0, 0]),\n",
       "   (Graph on 4 vertices, [-1, 0, 0, 1]),\n",
       "   (Graph on 4 vertices, [-1, 0, 1, 0]),\n",
       "   (Graph on 4 vertices, [-1, 1, 0, 0]),\n",
       "   (Graph on 4 vertices, [0, 0, 0, 0]),\n",
       "   (Graph on 4 vertices, [0, 0, 0, 0]),\n",
       "   (Graph on 4 vertices, [0, 0, 0, 0]),\n",
       "   (Graph on 4 vertices, [0, 0, 0, 0]),\n",
       "   (Graph on 4 vertices, [0, 0, 0, 0]),\n",
       "   (Graph on 4 vertices, [0, 0, 0, 0]),\n",
       "   (Graph on 4 vertices, [0, 0, 0, 0])],\n",
       "  None),\n",
       " ([[1, -1, 0, 0],\n",
       "   [1, -1, 0, 0],\n",
       "   [0, -1, 0, 1],\n",
       "   [0, -1, 0, 1],\n",
       "   [0, -1, 1, 0],\n",
       "   [0, -1, 1, 0],\n",
       "   [1, -1, 0, 0],\n",
       "   [0, -1, 0, 1],\n",
       "   [0, -1, 1, 0],\n",
       "   [0, 0, 0, 0],\n",
       "   [0, 0, 0, 0],\n",
       "   [0, 0, 0, 0],\n",
       "   [0, 0, 0, 0],\n",
       "   [0, 0, 0, 0],\n",
       "   [0, 0, 0, 0],\n",
       "   [0, 0, 0, 0]],\n",
       "  array([[ 0,  0,  1,  2],\n",
       "         [ 0,  0,  2,  1],\n",
       "         [ 0,  1,  0,  2],\n",
       "         [ 0,  1,  1,  1],\n",
       "         [ 0,  1,  2,  0],\n",
       "         [ 1, -1,  1,  2],\n",
       "         [ 1, -1,  2,  1],\n",
       "         [ 1,  0,  0,  2],\n",
       "         [ 1,  0,  1,  1],\n",
       "         [ 1,  0,  2,  0],\n",
       "         [ 1,  1,  0,  1],\n",
       "         [ 1,  1,  1,  0],\n",
       "         [ 2, -1,  1,  1],\n",
       "         [ 2,  0,  0,  1],\n",
       "         [ 2,  0,  1,  0],\n",
       "         [ 2,  1,  0,  0]], dtype=int32),\n",
       "  [(Graph on 4 vertices, [1, -1, 0, 0]),\n",
       "   (Graph on 4 vertices, [1, -1, 0, 0]),\n",
       "   (Graph on 4 vertices, [0, -1, 0, 1]),\n",
       "   (Graph on 4 vertices, [0, -1, 0, 1]),\n",
       "   (Graph on 4 vertices, [0, -1, 1, 0]),\n",
       "   (Graph on 4 vertices, [0, -1, 1, 0]),\n",
       "   (Graph on 4 vertices, [1, -1, 0, 0]),\n",
       "   (Graph on 4 vertices, [0, -1, 0, 1]),\n",
       "   (Graph on 4 vertices, [0, -1, 1, 0]),\n",
       "   (Graph on 4 vertices, [0, 0, 0, 0]),\n",
       "   (Graph on 4 vertices, [0, 0, 0, 0]),\n",
       "   (Graph on 4 vertices, [0, 0, 0, 0]),\n",
       "   (Graph on 4 vertices, [0, 0, 0, 0]),\n",
       "   (Graph on 4 vertices, [0, 0, 0, 0]),\n",
       "   (Graph on 4 vertices, [0, 0, 0, 0]),\n",
       "   (Graph on 4 vertices, [0, 0, 0, 0])],\n",
       "  None),\n",
       " ([[1, 0, -1, 0],\n",
       "   [0, 0, -1, 1],\n",
       "   [1, 0, -1, 0],\n",
       "   [0, 0, -1, 1],\n",
       "   [0, 1, -1, 0],\n",
       "   [0, 1, -1, 0],\n",
       "   [1, 0, -1, 0],\n",
       "   [0, 0, -1, 1],\n",
       "   [0, 1, -1, 0],\n",
       "   [0, 0, 0, 0],\n",
       "   [0, 0, 0, 0],\n",
       "   [0, 0, 0, 0],\n",
       "   [0, 0, 0, 0],\n",
       "   [0, 0, 0, 0],\n",
       "   [0, 0, 0, 0],\n",
       "   [0, 0, 0, 0]],\n",
       "  array([[ 0,  0,  1,  2],\n",
       "         [ 0,  1,  0,  2],\n",
       "         [ 0,  1,  1,  1],\n",
       "         [ 0,  2,  0,  1],\n",
       "         [ 0,  2,  1,  0],\n",
       "         [ 1,  0,  0,  2],\n",
       "         [ 1,  0,  1,  1],\n",
       "         [ 1,  1, -1,  2],\n",
       "         [ 1,  1,  0,  1],\n",
       "         [ 1,  1,  1,  0],\n",
       "         [ 1,  2, -1,  1],\n",
       "         [ 1,  2,  0,  0],\n",
       "         [ 2,  0,  0,  1],\n",
       "         [ 2,  0,  1,  0],\n",
       "         [ 2,  1, -1,  1],\n",
       "         [ 2,  1,  0,  0]], dtype=int32),\n",
       "  [(Graph on 4 vertices, [1, 0, -1, 0]),\n",
       "   (Graph on 4 vertices, [0, 0, -1, 1]),\n",
       "   (Graph on 4 vertices, [1, 0, -1, 0]),\n",
       "   (Graph on 4 vertices, [0, 0, -1, 1]),\n",
       "   (Graph on 4 vertices, [0, 1, -1, 0]),\n",
       "   (Graph on 4 vertices, [0, 1, -1, 0]),\n",
       "   (Graph on 4 vertices, [1, 0, -1, 0]),\n",
       "   (Graph on 4 vertices, [0, 0, -1, 1]),\n",
       "   (Graph on 4 vertices, [0, 1, -1, 0]),\n",
       "   (Graph on 4 vertices, [0, 0, 0, 0]),\n",
       "   (Graph on 4 vertices, [0, 0, 0, 0]),\n",
       "   (Graph on 4 vertices, [0, 0, 0, 0]),\n",
       "   (Graph on 4 vertices, [0, 0, 0, 0]),\n",
       "   (Graph on 4 vertices, [0, 0, 0, 0]),\n",
       "   (Graph on 4 vertices, [0, 0, 0, 0]),\n",
       "   (Graph on 4 vertices, [0, 0, 0, 0])],\n",
       "  None),\n",
       " ([[1, 0, 0, -1],\n",
       "   [0, 0, 1, -1],\n",
       "   [0, 1, 0, -1],\n",
       "   [1, 0, 0, -1],\n",
       "   [0, 0, 1, -1],\n",
       "   [0, 1, 0, -1],\n",
       "   [1, 0, 0, -1],\n",
       "   [0, 0, 1, -1],\n",
       "   [0, 1, 0, -1],\n",
       "   [0, 0, 0, 0],\n",
       "   [0, 0, 0, 0],\n",
       "   [0, 0, 0, 0],\n",
       "   [0, 0, 0, 0],\n",
       "   [0, 0, 0, 0],\n",
       "   [0, 0, 0, 0],\n",
       "   [0, 0, 0, 0]],\n",
       "  array([[ 0,  0,  2,  1],\n",
       "         [ 0,  1,  1,  1],\n",
       "         [ 0,  1,  2,  0],\n",
       "         [ 0,  2,  0,  1],\n",
       "         [ 0,  2,  1,  0],\n",
       "         [ 1,  0,  1,  1],\n",
       "         [ 1,  0,  2,  0],\n",
       "         [ 1,  1,  0,  1],\n",
       "         [ 1,  1,  1,  0],\n",
       "         [ 1,  1,  2, -1],\n",
       "         [ 1,  2,  0,  0],\n",
       "         [ 1,  2,  1, -1],\n",
       "         [ 2,  0,  0,  1],\n",
       "         [ 2,  0,  1,  0],\n",
       "         [ 2,  1,  0,  0],\n",
       "         [ 2,  1,  1, -1]], dtype=int32),\n",
       "  [(Graph on 4 vertices, [1, 0, 0, -1]),\n",
       "   (Graph on 4 vertices, [0, 0, 1, -1]),\n",
       "   (Graph on 4 vertices, [0, 1, 0, -1]),\n",
       "   (Graph on 4 vertices, [1, 0, 0, -1]),\n",
       "   (Graph on 4 vertices, [0, 0, 1, -1]),\n",
       "   (Graph on 4 vertices, [0, 1, 0, -1]),\n",
       "   (Graph on 4 vertices, [1, 0, 0, -1]),\n",
       "   (Graph on 4 vertices, [0, 0, 1, -1]),\n",
       "   (Graph on 4 vertices, [0, 1, 0, -1]),\n",
       "   (Graph on 4 vertices, [0, 0, 0, 0]),\n",
       "   (Graph on 4 vertices, [0, 0, 0, 0]),\n",
       "   (Graph on 4 vertices, [0, 0, 0, 0]),\n",
       "   (Graph on 4 vertices, [0, 0, 0, 0]),\n",
       "   (Graph on 4 vertices, [0, 0, 0, 0]),\n",
       "   (Graph on 4 vertices, [0, 0, 0, 0]),\n",
       "   (Graph on 4 vertices, [0, 0, 0, 0])],\n",
       "  None)]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start= 0 ---- 0 ----terminator: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.7/fractions.py:378: DeprecationWarning: Fraction.__float__ returned non-float (type numpy.float64).  The ability to return an instance of a strict subclass of float is deprecated, and may be removed in a future version of Python.\n",
      "  return fallback_operator(float(a), b)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start= 0 ---- 1 ----terminator: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.7/fractions.py:378: DeprecationWarning: Fraction.__float__ returned non-float (type numpy.float64).  The ability to return an instance of a strict subclass of float is deprecated, and may be removed in a future version of Python.\n",
      "  return fallback_operator(float(a), b)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start= 0 ---- 2 ----terminator: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.7/fractions.py:378: DeprecationWarning: Fraction.__float__ returned non-float (type numpy.float64).  The ability to return an instance of a strict subclass of float is deprecated, and may be removed in a future version of Python.\n",
      "  return fallback_operator(float(a), b)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start= 0 ---- 3 ----terminator: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.7/fractions.py:378: DeprecationWarning: Fraction.__float__ returned non-float (type numpy.float64).  The ability to return an instance of a strict subclass of float is deprecated, and may be removed in a future version of Python.\n",
      "  return fallback_operator(float(a), b)\n"
     ]
    }
   ],
   "source": [
    "dic_l=analyse_graphname(g,data,ind_breaks=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of wsc 4\n",
      "Number of polytopes of a given (dimension:number of at dim): {3: 4}\n",
      "Number of wsc that are/are not generated by phi_av: {True: 4}\n",
      "Number of wsc that are/are not generated by phi_can: None\n",
      "Number of wsc that are/are not generated by phi_av_translated1: None\n",
      "Number of wsc that are/are not generated by phi_av_translated2: None\n",
      "Number of wsc that are/are not generated by phi_av_translated3: None\n",
      "Number of wsc that are/are not generated by phi_av_translated4: None\n",
      "Number of wsc that are/are not generated by phi_av_translated5: None\n",
      "Number of wsc that are/are not generated by phi_av_translated6: None\n",
      "Number of wsc that are/are not generated by phi_av_translated7: None\n",
      "Number of wsc that are/are not generated by phi_av_translated8: None        \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "analyse_table(dic_l,f=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphname=\"Wheel_5\"\n",
    "g=Graph([('0', '1'), ('0', '2'), ('0', '3'), ('0', '4'), ('1', '2'), ('1', '4'), ('2', '3'), ('3', '4')], multiedges=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = r\"..\\CSR_good_moves\\examples\\wheel_graph_family\\Wheel_5.pkl\"\n",
    "with open(filename, 'rb') as f:\n",
    "    unpickled_list = pickle.load(f)\n",
    "    \n",
    "data=unpickled_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start= 0 ---- 0 ----terminator: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.7/fractions.py:378: DeprecationWarning: Fraction.__float__ returned non-float (type numpy.float64).  The ability to return an instance of a strict subclass of float is deprecated, and may be removed in a future version of Python.\n",
      "  return fallback_operator(float(a), b)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start= 0 ---- 1 ----terminator: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.7/fractions.py:378: DeprecationWarning: Fraction.__float__ returned non-float (type numpy.float64).  The ability to return an instance of a strict subclass of float is deprecated, and may be removed in a future version of Python.\n",
      "  return fallback_operator(float(a), b)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start= 0 ---- 2 ----terminator: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.7/fractions.py:378: DeprecationWarning: Fraction.__float__ returned non-float (type numpy.float64).  The ability to return an instance of a strict subclass of float is deprecated, and may be removed in a future version of Python.\n",
      "  return fallback_operator(float(a), b)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start= 0 ---- 3 ----terminator: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.7/fractions.py:378: DeprecationWarning: Fraction.__float__ returned non-float (type numpy.float64).  The ability to return an instance of a strict subclass of float is deprecated, and may be removed in a future version of Python.\n",
      "  return fallback_operator(float(a), b)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start= 0 ---- 4 ----terminator: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.7/fractions.py:378: DeprecationWarning: Fraction.__float__ returned non-float (type numpy.float64).  The ability to return an instance of a strict subclass of float is deprecated, and may be removed in a future version of Python.\n",
      "  return fallback_operator(float(a), b)\n"
     ]
    }
   ],
   "source": [
    "dic_l=analyse_graphname(g,data,ind_breaks=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of wsc 5\n",
      "Number of polytopes of a given (dimension:number of at dim): {4: 5}\n",
      "Number of wsc that are/are not generated by phi_av: {True: 1, False: 4}\n",
      "Number of wsc that are/are not generated by phi_can: None\n",
      "Number of wsc that are/are not generated by phi_av_translated1: None\n",
      "Number of wsc that are/are not generated by phi_av_translated2: None\n",
      "Number of wsc that are/are not generated by phi_av_translated3: None\n",
      "Number of wsc that are/are not generated by phi_av_translated4: None\n",
      "Number of wsc that are/are not generated by phi_av_translated5: None\n",
      "Number of wsc that are/are not generated by phi_av_translated6: None\n",
      "Number of wsc that are/are not generated by phi_av_translated7: None\n",
      "Number of wsc that are/are not generated by phi_av_translated8: None        \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "analyse_table(dic_l,f=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphname=\"Wheel_6\"\n",
    "g=Graph([('0', '1'), ('0', '2'), ('0', '3'), ('0', '4'), ('0', '5'), ('1', '2'), ('1', '5'), ('2', '3'), ('3', '4'), ('4', '5')], multiedges=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = r\"..\\CSR_good_moves\\examples\\wheel_graph_family\\Wheel_6.pkl\"\n",
    "with open(filename, 'rb') as f:\n",
    "    unpickled_list = pickle.load(f)\n",
    "    \n",
    "data=unpickled_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start= 0 ---- 0 ----terminator: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.7/fractions.py:378: DeprecationWarning: Fraction.__float__ returned non-float (type numpy.float64).  The ability to return an instance of a strict subclass of float is deprecated, and may be removed in a future version of Python.\n",
      "  return fallback_operator(float(a), b)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start= 0 ---- 1 ----terminator: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.7/fractions.py:378: DeprecationWarning: Fraction.__float__ returned non-float (type numpy.float64).  The ability to return an instance of a strict subclass of float is deprecated, and may be removed in a future version of Python.\n",
      "  return fallback_operator(float(a), b)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start= 0 ---- 2 ----terminator: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.7/fractions.py:378: DeprecationWarning: Fraction.__float__ returned non-float (type numpy.float64).  The ability to return an instance of a strict subclass of float is deprecated, and may be removed in a future version of Python.\n",
      "  return fallback_operator(float(a), b)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start= 0 ---- 3 ----terminator: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.7/fractions.py:378: DeprecationWarning: Fraction.__float__ returned non-float (type numpy.float64).  The ability to return an instance of a strict subclass of float is deprecated, and may be removed in a future version of Python.\n",
      "  return fallback_operator(float(a), b)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start= 0 ---- 4 ----terminator: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.7/fractions.py:378: DeprecationWarning: Fraction.__float__ returned non-float (type numpy.float64).  The ability to return an instance of a strict subclass of float is deprecated, and may be removed in a future version of Python.\n",
      "  return fallback_operator(float(a), b)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start= 0 ---- 5 ----terminator: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.7/fractions.py:378: DeprecationWarning: Fraction.__float__ returned non-float (type numpy.float64).  The ability to return an instance of a strict subclass of float is deprecated, and may be removed in a future version of Python.\n",
      "  return fallback_operator(float(a), b)\n"
     ]
    }
   ],
   "source": [
    "dic_l=analyse_graphname(g,data,ind_breaks=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of wsc 6\n",
      "Number of polytopes of a given (dimension:number of at dim): {5: 6}\n",
      "Number of wsc that are/are not generated by phi_av: {False: 6}\n",
      "Number of wsc that are/are not generated by phi_can: None\n",
      "Number of wsc that are/are not generated by phi_av_translated1: None\n",
      "Number of wsc that are/are not generated by phi_av_translated2: None\n",
      "Number of wsc that are/are not generated by phi_av_translated3: None\n",
      "Number of wsc that are/are not generated by phi_av_translated4: None\n",
      "Number of wsc that are/are not generated by phi_av_translated5: None\n",
      "Number of wsc that are/are not generated by phi_av_translated6: None\n",
      "Number of wsc that are/are not generated by phi_av_translated7: None\n",
      "Number of wsc that are/are not generated by phi_av_translated8: None        \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "analyse_table(dic_l,f=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphname=\"Wheel_7\"\n",
    "g=Graph([('0', '1'), ('0', '2'), ('0', '3'), ('0', '4'), ('0', '5'), ('1', '2'), ('1', '5'), ('2', '3'), ('3', '4'), ('4', '5')], multiedges=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = r\"..\\CSR_good_moves\\examples\\wheel_graph_family\\Wheel_7.pkl\"\n",
    "with open(filename, 'rb') as f:\n",
    "    unpickled_list = pickle.load(f)\n",
    "    \n",
    "data=unpickled_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start= 0 ---- 0 ----terminator: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/sagemath-9.2/local/lib/python3.7/site-packages/sage/geometry/polyhedron/backend_cdd.py:151: UserWarning: This polyhedron data is numerically complicated; cdd could not convert between the inexact V and H representation without loss of data. The resulting object might show inconsistencies.\n",
      "  warn(\"This polyhedron data is numerically complicated; cdd could not convert between the inexact V and H representation without loss of data. The resulting object might show inconsistencies.\")\n",
      "/opt/sagemath-9.2/local/lib/python3.7/site-packages/sage/geometry/polyhedron/backend_cdd.py:151: UserWarning: This polyhedron data is numerically complicated; cdd could not convert between the inexact V and H representation without loss of data. The resulting object might show inconsistencies.\n",
      "  warn(\"This polyhedron data is numerically complicated; cdd could not convert between the inexact V and H representation without loss of data. The resulting object might show inconsistencies.\")\n",
      "/opt/sagemath-9.2/local/lib/python3.7/site-packages/sage/geometry/polyhedron/backend_cdd.py:151: UserWarning: This polyhedron data is numerically complicated; cdd could not convert between the inexact V and H representation without loss of data. The resulting object might show inconsistencies.\n",
      "  warn(\"This polyhedron data is numerically complicated; cdd could not convert between the inexact V and H representation without loss of data. The resulting object might show inconsistencies.\")\n",
      "/opt/sagemath-9.2/local/lib/python3.7/site-packages/sage/geometry/polyhedron/backend_cdd.py:151: UserWarning: This polyhedron data is numerically complicated; cdd could not convert between the inexact V and H representation without loss of data. The resulting object might show inconsistencies.\n",
      "  warn(\"This polyhedron data is numerically complicated; cdd could not convert between the inexact V and H representation without loss of data. The resulting object might show inconsistencies.\")\n",
      "/opt/sagemath-9.2/local/lib/python3.7/site-packages/sage/geometry/polyhedron/backend_cdd.py:151: UserWarning: This polyhedron data is numerically complicated; cdd could not convert between the inexact V and H representation without loss of data. The resulting object might show inconsistencies.\n",
      "  warn(\"This polyhedron data is numerically complicated; cdd could not convert between the inexact V and H representation without loss of data. The resulting object might show inconsistencies.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start= 0 ---- 1 ----terminator: False\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-71-3e5d1a97790a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdic_l\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0manalyse_graphname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mind_breaks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mInteger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-70-8f882a0f3e92>\u001b[0m in \u001b[0;36manalyse_graphname\u001b[0;34m(G, data, start, terminator, ind_breaks)\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mdiv_l\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mterm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mInteger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#lbm [[0, 0, 1], [0, 1, 0], [1, 0, 0]]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0mtree_poly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_intersection_tree_poly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0massignments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;34m\"We see this is always true so we done check\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-45-a70ae6feffcf>\u001b[0m in \u001b[0;36mget_intersection_tree_poly\u001b[0;34m(G, assignments)\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdivisor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mass\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mInteger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mass\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mInteger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m         \u001b[0mP\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_tree_poly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdivisor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0mpoly_l\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-45-a70ae6feffcf>\u001b[0m in \u001b[0;36mget_tree_poly\u001b[0;34m(G, T, divisor)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m     \u001b[0;31m#build a polytope.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m     \u001b[0mtree_poly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPolyhedron\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mieqs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhyperp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtree_poly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/sagemath-9.2/local/lib/python3.7/site-packages/sage/misc/lazy_import.pyx\u001b[0m in \u001b[0;36msage.misc.lazy_import.LazyImport.__call__ (build/cythonized/sage/misc/lazy_import.c:4027)\u001b[0;34m()\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m         \"\"\"\n\u001b[0;32m--> 361\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/sagemath-9.2/local/lib/python3.7/site-packages/sage/geometry/polyhedron/constructor.py\u001b[0m in \u001b[0;36mPolyhedron\u001b[0;34m(vertices, rays, lines, ieqs, eqns, ambient_dim, base_ring, minimize, verbose, backend)\u001b[0m\n\u001b[1;32m    660\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mgot_Vrep\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m         \u001b[0mVrep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mvertices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 662\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVrep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHrep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/sagemath-9.2/local/lib/python3.7/site-packages/sage/structure/parent.pyx\u001b[0m in \u001b[0;36msage.structure.parent.Parent.__call__ (build/cythonized/sage/structure/parent.c:9364)\u001b[0;34m()\u001b[0m\n\u001b[1;32m    900\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    901\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 902\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_with_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    903\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_LazyString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_lazy_format\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"No conversion defined from %s to %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/sagemath-9.2/local/lib/python3.7/site-packages/sage/structure/coerce_maps.pyx\u001b[0m in \u001b[0;36msage.structure.coerce_maps.DefaultConvertMap_unique._call_with_args (build/cythonized/sage/structure/coerce_maps.c:5042)\u001b[0;34m()\u001b[0m\n\u001b[1;32m    173\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_element_constructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_element_constructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mprint_warnings\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/sagemath-9.2/local/lib/python3.7/site-packages/sage/geometry/polyhedron/parent.py\u001b[0m in \u001b[0;36m_element_constructor_\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    596\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mconvert\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mVrep\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m                 \u001b[0mVrep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mconvert_base_ring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mVrep\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0melement_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVrep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHrep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnargs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_Polyhedron\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m             \u001b[0mpolyhedron\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/sagemath-9.2/local/lib/python3.7/site-packages/sage/geometry/polyhedron/backend_cdd.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, parent, Vrep, Hrep, **kwds)\u001b[0m\n\u001b[1;32m    518\u001b[0m             \u001b[0msage\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTestSuite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m         \"\"\"\n\u001b[0;32m--> 520\u001b[0;31m         \u001b[0mPolyhedron_cdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVrep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHrep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_init_from_Vrepresentation_and_Hrepresentation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVrep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHrep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/sagemath-9.2/local/lib/python3.7/site-packages/sage/geometry/polyhedron/base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, parent, Vrep, Hrep, Vrep_minimal, Hrep_minimal, pref_rep, **kwds)\u001b[0m\n\u001b[1;32m    252\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mHrep\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m             \u001b[0mieqs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meqns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHrep\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 254\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_from_Hrepresentation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mieqs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meqns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    255\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_empty_polyhedron\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/sagemath-9.2/local/lib/python3.7/site-packages/sage/geometry/polyhedron/backend_cdd.py\u001b[0m in \u001b[0;36m_init_from_Hrepresentation\u001b[0;34m(self, ieqs, eqns, verbose)\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcdd_Hrepresentation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cdd_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mieqs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meqns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_cdd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'--redcheck'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_cdd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'--repall'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_from_cdd_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_ring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_exact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/sagemath-9.2/local/lib/python3.7/site-packages/sage/geometry/polyhedron/backend_cdd.py\u001b[0m in \u001b[0;36m_run_cdd\u001b[0;34m(self, cdd_input_string, cmdline_arg, verbose)\u001b[0m\n\u001b[1;32m    159\u001b[0m         cdd_proc = Popen([self._cdd_executable, cmdline_arg],\n\u001b[1;32m    160\u001b[0m                          \u001b[0mstdin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPIPE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstdout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPIPE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPIPE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m                          encoding='latin-1')\n\u001b[0m\u001b[1;32m    162\u001b[0m         \u001b[0mans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcdd_proc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommunicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcdd_input_string\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, encoding, errors, text)\u001b[0m\n\u001b[1;32m    798\u001b[0m                                 \u001b[0mc2pread\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc2pwrite\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m                                 \u001b[0merrread\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrwrite\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 800\u001b[0;31m                                 restore_signals, start_new_session)\n\u001b[0m\u001b[1;32m    801\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    802\u001b[0m             \u001b[0;31m# Cleanup if the child failed starting.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36m_execute_child\u001b[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, start_new_session)\u001b[0m\n\u001b[1;32m   1480\u001b[0m                             \u001b[0merrread\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrwrite\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1481\u001b[0m                             \u001b[0merrpipe_read\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrpipe_write\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1482\u001b[0;31m                             restore_signals, start_new_session, preexec_fn)\n\u001b[0m\u001b[1;32m   1483\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_child_created\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1484\u001b[0m                 \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32msrc/cysignals/signals.pyx\u001b[0m in \u001b[0;36mcysignals.signals.python_check_interrupt\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dic_l=analyse_graphname(g,data,ind_breaks=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyse_table(dic_l,f=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### complete_bipartite_graph_family:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphname=\"K24\"\n",
    "g=Graph([('0', '2'), ('0', '3'), ('0', '4'), ('0', '5'), ('1', '2'), ('1', '3'), ('1', '4'), ('1', '5')], multiedges=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = r\"..\\CSR_good_moves\\examples\\complete_bipartite_graph_family\\K24.pkl\"\n",
    "with open(filename, 'rb') as f:\n",
    "    unpickled_list = pickle.load(f)\n",
    "    \n",
    "data=unpickled_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start= 0 ---- 0 ----terminator: False\n",
      "Start= 0 ---- 1 ----terminator: False\n",
      "Start= 0 ---- 2 ----terminator: False\n",
      "Start= 0 ---- 3 ----terminator: False\n",
      "Start= 0 ---- 4 ----terminator: False\n",
      "Start= 0 ---- 5 ----terminator: False\n"
     ]
    }
   ],
   "source": [
    "dic_l=analyse_graphname(g,data,ind_breaks=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of wsc 6\n",
      "Number of polytopes of a given (dimension:number of at dim): {5: 6}\n",
      "Number of wsc that are/are not generated by phi_av: {False: 6}\n",
      "Number of wsc that are/are not generated by phi_can: None\n",
      "Number of wsc that are/are not generated by phi_av_translated1: None\n",
      "Number of wsc that are/are not generated by phi_av_translated2: None\n",
      "Number of wsc that are/are not generated by phi_av_translated3: None\n",
      "Number of wsc that are/are not generated by phi_av_translated4: None\n",
      "Number of wsc that are/are not generated by phi_av_translated5: None\n",
      "Number of wsc that are/are not generated by phi_av_translated6: None\n",
      "Number of wsc that are/are not generated by phi_av_translated7: None\n",
      "Number of wsc that are/are not generated by phi_av_translated8: None        \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "analyse_table(dic_l,f=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphname=\"K25\"\n",
    "g=Graph([('0', '2'), ('0', '3'), ('0', '4'), ('0', '5'), ('0', '6'), ('1', '2'), ('1', '3'), ('1', '4'), ('1', '5'), ('1', '6')], multiedges=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = r\"..\\CSR_good_moves\\examples\\complete_bipartite_graph_family\\K25.pkl\"\n",
    "with open(filename, 'rb') as f:\n",
    "    unpickled_list = pickle.load(f)\n",
    "    \n",
    "data=unpickled_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start= 0 ---- 0 ----terminator: False\n",
      "Start= 0 ---- 1 ----terminator: False\n",
      "Start= 0 ---- 2 ----terminator: False\n",
      "Start= 0 ---- 3 ----terminator: False\n",
      "Start= 0 ---- 4 ----terminator: False\n",
      "Start= 0 ---- 5 ----terminator: False\n",
      "Start= 0 ---- 6 ----terminator: False\n"
     ]
    }
   ],
   "source": [
    "dic_l=analyse_graphname(g,data,ind_breaks=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of wsc 7\n",
      "Number of polytopes of a given (dimension:number of at dim): {6: 7}\n",
      "Number of wsc that are/are not generated by phi_av: {False: 7}\n",
      "Number of wsc that are/are not generated by phi_can: None\n",
      "Number of wsc that are/are not generated by phi_av_translated1: None\n",
      "Number of wsc that are/are not generated by phi_av_translated2: None\n",
      "Number of wsc that are/are not generated by phi_av_translated3: None\n",
      "Number of wsc that are/are not generated by phi_av_translated4: None\n",
      "Number of wsc that are/are not generated by phi_av_translated5: None\n",
      "Number of wsc that are/are not generated by phi_av_translated6: None\n",
      "Number of wsc that are/are not generated by phi_av_translated7: None\n",
      "Number of wsc that are/are not generated by phi_av_translated8: None        \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "analyse_table(dic_l,f=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphname=\"K33\"\n",
    "g=Graph([('0', '3'), ('0', '4'), ('0', '5'), ('1', '3'), ('1', '4'), ('1', '5'), ('2', '3'), ('2', '4'), ('2', '5')], multiedges=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = r\"..\\CSR_good_moves\\examples\\complete_bipartite_graph_family\\K33.pkl\"\n",
    "with open(filename, 'rb') as f:\n",
    "    unpickled_list = pickle.load(f)\n",
    "    \n",
    "data=unpickled_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start= 0 ---- 0 ----terminator: False\n",
      "Start= 0 ---- 1 ----terminator: False\n",
      "Start= 0 ---- 2 ----terminator: False\n",
      "Start= 0 ---- 3 ----terminator: False\n",
      "Start= 0 ---- 4 ----terminator: False\n",
      "Start= 0 ---- 5 ----terminator: False\n"
     ]
    }
   ],
   "source": [
    "dic_l=analyse_graphname(g,data,ind_breaks=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of wsc 6\n",
      "Number of polytopes of a given (dimension:number of at dim): {5: 6}\n",
      "Number of wsc that are/are not generated by phi_av: {True: 6}\n",
      "Number of wsc that are/are not generated by phi_can: None\n",
      "Number of wsc that are/are not generated by phi_av_translated1: None\n",
      "Number of wsc that are/are not generated by phi_av_translated2: None\n",
      "Number of wsc that are/are not generated by phi_av_translated3: None\n",
      "Number of wsc that are/are not generated by phi_av_translated4: None\n",
      "Number of wsc that are/are not generated by phi_av_translated5: None\n",
      "Number of wsc that are/are not generated by phi_av_translated6: None\n",
      "Number of wsc that are/are not generated by phi_av_translated7: None\n",
      "Number of wsc that are/are not generated by phi_av_translated8: None        \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "analyse_table(dic_l,f=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphname=\"K34\"\n",
    "g=Graph([('0', '3'), ('0', '4'), ('0', '5'), ('0', '6'), ('1', '3'), ('1', '4'), ('1', '5'), ('1', '6'), ('2', '3'), ('2', '4'), ('2', '5'), ('2', '6')], multiedges=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = r\"..\\CSR_good_moves\\examples\\complete_bipartite_graph_family\\K34.pkl\"\n",
    "with open(filename, 'rb') as f:\n",
    "    unpickled_list = pickle.load(f)\n",
    "    \n",
    "data=unpickled_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start= 0 ---- 0 ----terminator: False\n",
      "Start= 0 ---- 1 ----terminator: False\n",
      "Start= 0 ---- 2 ----terminator: False\n",
      "Start= 0 ---- 3 ----terminator: False\n",
      "Start= 0 ---- 4 ----terminator: False\n",
      "Start= 0 ---- 5 ----terminator: False\n",
      "Start= 0 ---- 6 ----terminator: False\n"
     ]
    }
   ],
   "source": [
    "dic_l=analyse_graphname(g,data,ind_breaks=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of wsc 7\n",
      "Number of polytopes of a given (dimension:number of at dim): {6: 7}\n",
      "Number of wsc that are/are not generated by phi_av: {True: 3, False: 4}\n",
      "Number of wsc that are/are not generated by phi_can: None\n",
      "Number of wsc that are/are not generated by phi_av_translated1: None\n",
      "Number of wsc that are/are not generated by phi_av_translated2: None\n",
      "Number of wsc that are/are not generated by phi_av_translated3: None\n",
      "Number of wsc that are/are not generated by phi_av_translated4: None\n",
      "Number of wsc that are/are not generated by phi_av_translated5: None\n",
      "Number of wsc that are/are not generated by phi_av_translated6: None\n",
      "Number of wsc that are/are not generated by phi_av_translated7: None\n",
      "Number of wsc that are/are not generated by phi_av_translated8: None        \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "analyse_table(dic_l,f=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### complete_graph_family:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphname=\"K5\"\n",
    "g=Graph([('0', '1'), ('0', '2'), ('0', '3'), ('0', '4'), ('1', '2'), ('1', '3'), ('1', '4'), ('2', '3'), ('2', '4'), ('3', '4')], multiedges=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = r\"..\\CSR_good_moves\\examples\\complete_graph_family\\K5.pkl\"\n",
    "with open(filename, 'rb') as f:\n",
    "    unpickled_list = pickle.load(f)\n",
    "    \n",
    "data=unpickled_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start= 0 ---- 0 ----terminator: False\n",
      "Start= 0 ---- 1 ----terminator: False\n",
      "Start= 0 ---- 2 ----terminator: False\n",
      "Start= 0 ---- 3 ----terminator: False\n",
      "Start= 0 ---- 4 ----terminator: False\n"
     ]
    }
   ],
   "source": [
    "dic_l=analyse_graphname(g,data,ind_breaks=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of wsc 5\n",
      "Number of polytopes of a given (dimension:number of at dim): {4: 5}\n",
      "Number of wsc that are/are not generated by phi_av: {True: 5}\n",
      "Number of wsc that are/are not generated by phi_can: None\n",
      "Number of wsc that are/are not generated by phi_av_translated1: None\n",
      "Number of wsc that are/are not generated by phi_av_translated2: None\n",
      "Number of wsc that are/are not generated by phi_av_translated3: None\n",
      "Number of wsc that are/are not generated by phi_av_translated4: None\n",
      "Number of wsc that are/are not generated by phi_av_translated5: None\n",
      "Number of wsc that are/are not generated by phi_av_translated6: None\n",
      "Number of wsc that are/are not generated by phi_av_translated7: None\n",
      "Number of wsc that are/are not generated by phi_av_translated8: None        \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "analyse_table(dic_l,f=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# graphname=\"K6\"\n",
    "# g=Graph([('0', '1'), ('0', '2'), ('0', '3'), ('0', '4'), ('0', '5'), ('1', '2'), ('1', '3'), ('1', '4'), ('1', '5'), ('2', '3'), ('2', '4'), ('2', '5'), ('3', '4'), ('3', '5'), ('4', '5')], multiedges=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Larger graphs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphname=\"MoserSpindle\"\n",
    "g=Graph([('0', '1'), ('0', '4'), ('0', '6'), ('1', '2'), ('1', '5'), ('2', '3'), ('2', '5'), ('3', '4'), ('3', '5'), ('3', '6'), ('4', '6')], multiedges=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = r\"..\\CSR_good_moves\\examples\\MoserSpindle.pkl\"\n",
    "with open(filename, 'rb') as f:\n",
    "    unpickled_list = pickle.load(f)\n",
    "    \n",
    "data=unpickled_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start= 0 ---- 0 ----terminator: False\n",
      "Start= 0 ---- 1 ----terminator: False\n",
      "Start= 0 ---- 2 ----terminator: False\n",
      "Start= 0 ---- 3 ----terminator: False\n",
      "Start= 0 ---- 4 ----terminator: False\n",
      "Start= 0 ---- 5 ----terminator: False\n",
      "Start= 0 ---- 6 ----terminator: False\n"
     ]
    }
   ],
   "source": [
    "dic_l=analyse_graphname(g,data,ind_breaks=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of wsc 7\n",
      "Number of polytopes of a given (dimension:number of at dim): {6: 7}\n",
      "Number of wsc that are/are not generated by phi_av: {False: 7}\n",
      "Number of wsc that are/are not generated by phi_can: None\n",
      "Number of wsc that are/are not generated by phi_av_translated1: None\n",
      "Number of wsc that are/are not generated by phi_av_translated2: None\n",
      "Number of wsc that are/are not generated by phi_av_translated3: None\n",
      "Number of wsc that are/are not generated by phi_av_translated4: None\n",
      "Number of wsc that are/are not generated by phi_av_translated5: None\n",
      "Number of wsc that are/are not generated by phi_av_translated6: None\n",
      "Number of wsc that are/are not generated by phi_av_translated7: None\n",
      "Number of wsc that are/are not generated by phi_av_translated8: None        \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "analyse_table(dic_l,f=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# graphname=\"petersen_family_1\"\n",
    "# g=Graph([('0', '1'), ('0', '4'), ('0', '5'), ('1', '2'), ('1', '6'), ('2', '3'), ('2', '7'), ('3', '4'), ('3', '8'), ('4', '9'), ('5', '7'), ('5', '8'), ('6', '8'), ('6', '9'), ('7', '9')], multiedges=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "G=Graph([(\"0\", \"3\"), (\"0\", \"4\"), (\"0\", \"5\"), (\"1\", \"3\"), (\"1\", \"4\"), (\"1\", \"5\"), (\"2\", \"3\"), (\"2\", \"4\"), (\"2\", \"5\")], multiedges=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "graphname_k33=\"K33\"\n",
    "\n",
    "filename=f\"examples/{graphname_k33}/{graphname_k33}/{graphname_k33}.pkl\"\n",
    "with open(filename, 'rb') as f:\n",
    "    unpickled_list = pickle.load(f)\n",
    "\n",
    "    dataK33=unpickled_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphname_K33_breaks=\"K33_breaks\"\n",
    "\n",
    "filename=f\"examples/{graphname_k33}/{graphname_K33_breaks}/{graphname_K33_breaks}.pkl\"\n",
    "with open(filename, 'rb') as f:\n",
    "    unpickled_list = pickle.load(f)\n",
    "\n",
    "    dataK33_breaks=unpickled_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assignments only\n",
    "ass_trivial=dataK33_breaks[0][0]\n",
    "ass_non_trivial=dataK33[0][0]\n",
    "\n",
    "#top part\n",
    "lbm_triv=dataK33_breaks[0][1]\n",
    "lbm_non_triv=dataK33[0][1]\n",
    "\n",
    "#Lets assume the trees of K33 are in the standard ordering. \n",
    "# We should get phi_can to work for the break divisor case then to check\n",
    "\n",
    "#Get assignments with trees\n",
    "spanning_trees=[tree for tree in G.spanning_trees()]\n",
    "ass_trivial_w_trees=list(zip(spanning_trees,ass_trivial))\n",
    "ass_non_trivial_w_trees=list(zip(spanning_trees,ass_non_trivial))\n",
    "\n",
    "#Back in the correct format.\n",
    "# data=dataK33_breaks+dataK33 #Size=2\n",
    "data=[[[None],lbm_triv,ass_trivial_w_trees],[[None],lbm_non_triv,ass_non_trivial_w_trees]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start= 0 ---- 0 ----terminator: False\n",
      "Start= 0 ---- 1 ----terminator: False\n"
     ]
    }
   ],
   "source": [
    "dic_l=analyse_graphname(G,data,ind_breaks=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Store list of dictionaries\n",
    "pickle_dic_l(graphname_k33,dic_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of wsc 2\n",
      "Number of wsc that do/do not satisfy graph poly == tree poly: {True: 2}\n",
      "Number of polytopes of a given (dimension:number of at dim): {5: 2}\n",
      "Number of wsc that are/are not generated by phi_rep: {True: 2}\n",
      "Number of wsc that are/are not generated by phi_av: {True: 1, False: 1}\n",
      "Number of wsc that are/are not generated by phi_can: {True: 1, False: 1}\n",
      "Number of wsc that are/are not generated by phi_av_translated1: {True: 1, False: 1}\n",
      "Number of wsc that are/are not generated by phi_av_translated2: {True: 1, False: 1}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "analyse_table(dic_l,f=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### V_222"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "graphname=\"V_222\"\n",
    "G=Graph([(\"0\",\"1\"),(\"1\",\"2\"),(\"2\",\"3\"),(\"3\",\"0\"),(\"0\",\"4\"),(\"4\",\"2\")], multiedges=True)\n",
    "\n",
    "data=unpickle(graphname) #Size=38\n",
    "\n",
    "#Are we picking the index of the break case properly? #Y ind_breaks=0\n",
    "# data=unpickle(graphname)\n",
    "# for i in data:\n",
    "#     print(i)\n",
    "\n",
    "dic_l=analyse_graphname(G,data,ind_breaks=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Store list of dictionaries\n",
    "pickle_dic_l(graphname,dic_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyse_table(dic_l,f=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### V_223 D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start= 0 ---- 0 ----terminator: False\n",
      "Start= 0 ---- 1 ----terminator: False\n",
      "Start= 0 ---- 2 ----terminator: False\n",
      "Start= 0 ---- 3 ----terminator: False\n",
      "Start= 0 ---- 4 ----terminator: False\n",
      "Start= 0 ---- 5 ----terminator: False\n",
      "Start= 0 ---- 6 ----terminator: False\n",
      "Start= 0 ---- 7 ----terminator: False\n",
      "Start= 0 ---- 8 ----terminator: False\n",
      "Start= 0 ---- 9 ----terminator: False\n",
      "Start= 0 ---- 10 ----terminator: False\n",
      "Start= 0 ---- 11 ----terminator: False\n",
      "Start= 0 ---- 12 ----terminator: False\n",
      "Start= 0 ---- 13 ----terminator: False\n",
      "Start= 0 ---- 14 ----terminator: False\n",
      "Start= 0 ---- 15 ----terminator: False\n",
      "Start= 0 ---- 16 ----terminator: False\n",
      "Start= 0 ---- 17 ----terminator: False\n",
      "Start= 0 ---- 18 ----terminator: False\n",
      "Start= 0 ---- 19 ----terminator: False\n",
      "Start= 0 ---- 20 ----terminator: False\n",
      "Start= 0 ---- 21 ----terminator: False\n",
      "Start= 0 ---- 22 ----terminator: False\n",
      "Start= 0 ---- 23 ----terminator: False\n",
      "Start= 0 ---- 24 ----terminator: False\n",
      "Start= 0 ---- 25 ----terminator: False\n",
      "Start= 0 ---- 26 ----terminator: False\n",
      "Start= 0 ---- 27 ----terminator: False\n",
      "Start= 0 ---- 28 ----terminator: False\n",
      "Start= 0 ---- 29 ----terminator: False\n",
      "Start= 0 ---- 30 ----terminator: False\n",
      "Start= 0 ---- 31 ----terminator: False\n",
      "Start= 0 ---- 32 ----terminator: False\n",
      "Start= 0 ---- 33 ----terminator: False\n",
      "Start= 0 ---- 34 ----terminator: False\n",
      "Start= 0 ---- 35 ----terminator: False\n",
      "Start= 0 ---- 36 ----terminator: False\n",
      "Start= 0 ---- 37 ----terminator: False\n",
      "Start= 0 ---- 38 ----terminator: False\n",
      "Start= 0 ---- 39 ----terminator: False\n",
      "Start= 0 ---- 40 ----terminator: False\n",
      "Start= 0 ---- 41 ----terminator: False\n",
      "Start= 0 ---- 42 ----terminator: False\n",
      "Start= 0 ---- 43 ----terminator: False\n",
      "Start= 0 ---- 44 ----terminator: False\n",
      "Start= 0 ---- 45 ----terminator: False\n",
      "Start= 0 ---- 46 ----terminator: False\n",
      "Start= 0 ---- 47 ----terminator: False\n",
      "Start= 0 ---- 48 ----terminator: False\n",
      "Start= 0 ---- 49 ----terminator: False\n",
      "Start= 0 ---- 50 ----terminator: False\n",
      "Start= 0 ---- 51 ----terminator: False\n",
      "Start= 0 ---- 52 ----terminator: False\n",
      "Start= 0 ---- 53 ----terminator: False\n",
      "Start= 0 ---- 54 ----terminator: False\n",
      "Start= 0 ---- 55 ----terminator: False\n",
      "Start= 0 ---- 56 ----terminator: False\n",
      "Start= 0 ---- 57 ----terminator: False\n",
      "Start= 0 ---- 58 ----terminator: False\n",
      "Start= 0 ---- 59 ----terminator: False\n",
      "Start= 0 ---- 60 ----terminator: False\n",
      "Start= 0 ---- 61 ----terminator: False\n",
      "Start= 0 ---- 62 ----terminator: False\n",
      "Start= 0 ---- 63 ----terminator: False\n",
      "Start= 0 ---- 64 ----terminator: False\n",
      "Start= 0 ---- 65 ----terminator: False\n",
      "Start= 0 ---- 66 ----terminator: False\n",
      "Start= 0 ---- 67 ----terminator: False\n",
      "Start= 0 ---- 68 ----terminator: False\n",
      "Start= 0 ---- 69 ----terminator: False\n",
      "Start= 0 ---- 70 ----terminator: False\n",
      "Start= 0 ---- 71 ----terminator: False\n",
      "Start= 0 ---- 72 ----terminator: False\n",
      "Start= 0 ---- 73 ----terminator: False\n",
      "Start= 0 ---- 74 ----terminator: False\n",
      "Start= 0 ---- 75 ----terminator: False\n",
      "Start= 0 ---- 76 ----terminator: False\n",
      "Start= 0 ---- 77 ----terminator: False\n",
      "Start= 0 ---- 78 ----terminator: False\n",
      "Start= 0 ---- 79 ----terminator: False\n",
      "Start= 0 ---- 80 ----terminator: False\n",
      "Start= 0 ---- 81 ----terminator: False\n",
      "Start= 0 ---- 82 ----terminator: False\n",
      "Start= 0 ---- 83 ----terminator: False\n",
      "Start= 0 ---- 84 ----terminator: False\n",
      "Start= 0 ---- 85 ----terminator: False\n",
      "Start= 0 ---- 86 ----terminator: False\n",
      "Start= 0 ---- 87 ----terminator: False\n",
      "Start= 0 ---- 88 ----terminator: False\n",
      "Start= 0 ---- 89 ----terminator: False\n",
      "Start= 0 ---- 90 ----terminator: False\n",
      "Start= 0 ---- 91 ----terminator: False\n",
      "Start= 0 ---- 92 ----terminator: False\n",
      "Start= 0 ---- 93 ----terminator: False\n",
      "Start= 0 ---- 94 ----terminator: False\n",
      "Start= 0 ---- 95 ----terminator: False\n",
      "Start= 0 ---- 96 ----terminator: False\n",
      "Start= 0 ---- 97 ----terminator: False\n",
      "Start= 0 ---- 98 ----terminator: False\n",
      "Start= 0 ---- 99 ----terminator: False\n",
      "Start= 0 ---- 100 ----terminator: False\n",
      "Start= 0 ---- 101 ----terminator: False\n",
      "Start= 0 ---- 102 ----terminator: False\n",
      "Start= 0 ---- 103 ----terminator: False\n",
      "Start= 0 ---- 104 ----terminator: False\n",
      "Start= 0 ---- 105 ----terminator: False\n",
      "Start= 0 ---- 106 ----terminator: False\n",
      "Start= 0 ---- 107 ----terminator: False\n",
      "Start= 0 ---- 108 ----terminator: False\n",
      "Start= 0 ---- 109 ----terminator: False\n",
      "Start= 0 ---- 110 ----terminator: False\n",
      "Start= 0 ---- 111 ----terminator: False\n",
      "Start= 0 ---- 112 ----terminator: False\n",
      "Start= 0 ---- 113 ----terminator: False\n",
      "Start= 0 ---- 114 ----terminator: False\n",
      "Start= 0 ---- 115 ----terminator: False\n",
      "Start= 0 ---- 116 ----terminator: False\n",
      "Start= 0 ---- 117 ----terminator: False\n",
      "Start= 0 ---- 118 ----terminator: False\n",
      "Start= 0 ---- 119 ----terminator: False\n",
      "Start= 0 ---- 120 ----terminator: False\n",
      "Start= 0 ---- 121 ----terminator: False\n",
      "Start= 0 ---- 122 ----terminator: False\n",
      "Start= 0 ---- 123 ----terminator: False\n",
      "Start= 0 ---- 124 ----terminator: False\n",
      "Start= 0 ---- 125 ----terminator: False\n",
      "Start= 0 ---- 126 ----terminator: False\n",
      "Start= 0 ---- 127 ----terminator: False\n",
      "Start= 0 ---- 128 ----terminator: False\n",
      "Start= 0 ---- 129 ----terminator: False\n",
      "Start= 0 ---- 130 ----terminator: False\n",
      "Start= 0 ---- 131 ----terminator: False\n",
      "Start= 0 ---- 132 ----terminator: False\n",
      "Start= 0 ---- 133 ----terminator: False\n",
      "Start= 0 ---- 134 ----terminator: False\n",
      "Start= 0 ---- 135 ----terminator: False\n",
      "Start= 0 ---- 136 ----terminator: False\n",
      "Start= 0 ---- 137 ----terminator: False\n",
      "Start= 0 ---- 138 ----terminator: False\n",
      "Start= 0 ---- 139 ----terminator: False\n",
      "Start= 0 ---- 140 ----terminator: False\n",
      "Start= 0 ---- 141 ----terminator: False\n",
      "Start= 0 ---- 142 ----terminator: False\n",
      "Start= 0 ---- 143 ----terminator: False\n",
      "Start= 0 ---- 144 ----terminator: False\n",
      "Start= 0 ---- 145 ----terminator: False\n",
      "Start= 0 ---- 146 ----terminator: False\n",
      "Start= 0 ---- 147 ----terminator: False\n",
      "Start= 0 ---- 148 ----terminator: False\n",
      "Start= 0 ---- 149 ----terminator: False\n",
      "Start= 0 ---- 150 ----terminator: False\n",
      "Start= 0 ---- 151 ----terminator: False\n",
      "Start= 0 ---- 152 ----terminator: False\n",
      "Start= 0 ---- 153 ----terminator: False\n",
      "Start= 0 ---- 154 ----terminator: False\n",
      "Start= 0 ---- 155 ----terminator: False\n",
      "Start= 0 ---- 156 ----terminator: False\n",
      "Start= 0 ---- 157 ----terminator: False\n",
      "Start= 0 ---- 158 ----terminator: False\n",
      "Start= 0 ---- 159 ----terminator: False\n",
      "Start= 0 ---- 160 ----terminator: False\n",
      "Start= 0 ---- 161 ----terminator: False\n",
      "Start= 0 ---- 162 ----terminator: False\n",
      "Start= 0 ---- 163 ----terminator: False\n",
      "Start= 0 ---- 164 ----terminator: False\n",
      "Start= 0 ---- 165 ----terminator: False\n",
      "Start= 0 ---- 166 ----terminator: False\n",
      "Start= 0 ---- 167 ----terminator: False\n",
      "Start= 0 ---- 168 ----terminator: False\n",
      "Start= 0 ---- 169 ----terminator: False\n",
      "Start= 0 ---- 170 ----terminator: False\n",
      "Start= 0 ---- 171 ----terminator: False\n",
      "Start= 0 ---- 172 ----terminator: False\n",
      "Start= 0 ---- 173 ----terminator: False\n",
      "Start= 0 ---- 174 ----terminator: False\n",
      "Start= 0 ---- 175 ----terminator: False\n",
      "Start= 0 ---- 176 ----terminator: False\n",
      "Start= 0 ---- 177 ----terminator: False\n",
      "Start= 0 ---- 178 ----terminator: False\n",
      "Start= 0 ---- 179 ----terminator: False\n",
      "Start= 0 ---- 180 ----terminator: False\n",
      "Start= 0 ---- 181 ----terminator: False\n",
      "Start= 0 ---- 182 ----terminator: False\n",
      "Start= 0 ---- 183 ----terminator: False\n",
      "Start= 0 ---- 184 ----terminator: False\n",
      "Start= 0 ---- 185 ----terminator: False\n",
      "Start= 0 ---- 186 ----terminator: False\n",
      "Start= 0 ---- 187 ----terminator: False\n",
      "Start= 0 ---- 188 ----terminator: False\n",
      "Start= 0 ---- 189 ----terminator: False\n",
      "Start= 0 ---- 190 ----terminator: False\n",
      "Start= 0 ---- 191 ----terminator: False\n",
      "Start= 0 ---- 192 ----terminator: False\n",
      "Start= 0 ---- 193 ----terminator: False\n",
      "Start= 0 ---- 194 ----terminator: False\n",
      "Start= 0 ---- 195 ----terminator: False\n",
      "Start= 0 ---- 196 ----terminator: False\n",
      "Start= 0 ---- 197 ----terminator: False\n",
      "Start= 0 ---- 198 ----terminator: False\n",
      "Start= 0 ---- 199 ----terminator: False\n",
      "Start= 0 ---- 200 ----terminator: False\n",
      "Start= 0 ---- 201 ----terminator: False\n",
      "Start= 0 ---- 202 ----terminator: False\n",
      "Start= 0 ---- 203 ----terminator: False\n",
      "Start= 0 ---- 204 ----terminator: False\n",
      "Start= 0 ---- 205 ----terminator: False\n",
      "Start= 0 ---- 206 ----terminator: False\n",
      "Start= 0 ---- 207 ----terminator: False\n",
      "Start= 0 ---- 208 ----terminator: False\n",
      "Start= 0 ---- 209 ----terminator: False\n",
      "Start= 0 ---- 210 ----terminator: False\n",
      "Start= 0 ---- 211 ----terminator: False\n",
      "Start= 0 ---- 212 ----terminator: False\n",
      "Start= 0 ---- 213 ----terminator: False\n",
      "Start= 0 ---- 214 ----terminator: False\n",
      "Start= 0 ---- 215 ----terminator: False\n",
      "Start= 0 ---- 216 ----terminator: False\n",
      "Start= 0 ---- 217 ----terminator: False\n",
      "Start= 0 ---- 218 ----terminator: False\n",
      "Start= 0 ---- 219 ----terminator: False\n",
      "Start= 0 ---- 220 ----terminator: False\n",
      "Start= 0 ---- 221 ----terminator: False\n",
      "Start= 0 ---- 222 ----terminator: False\n",
      "Start= 0 ---- 223 ----terminator: False\n",
      "Start= 0 ---- 224 ----terminator: False\n",
      "Start= 0 ---- 225 ----terminator: False\n",
      "Start= 0 ---- 226 ----terminator: False\n",
      "Start= 0 ---- 227 ----terminator: False\n",
      "Start= 0 ---- 228 ----terminator: False\n",
      "Start= 0 ---- 229 ----terminator: False\n",
      "Start= 0 ---- 230 ----terminator: False\n",
      "Start= 0 ---- 231 ----terminator: False\n",
      "Start= 0 ---- 232 ----terminator: False\n",
      "Start= 0 ---- 233 ----terminator: False\n",
      "Start= 0 ---- 234 ----terminator: False\n",
      "Start= 0 ---- 235 ----terminator: False\n",
      "Start= 0 ---- 236 ----terminator: False\n",
      "Start= 0 ---- 237 ----terminator: False\n",
      "Start= 0 ---- 238 ----terminator: False\n",
      "Start= 0 ---- 239 ----terminator: False\n",
      "Start= 0 ---- 240 ----terminator: False\n",
      "Start= 0 ---- 241 ----terminator: False\n",
      "Start= 0 ---- 242 ----terminator: False\n",
      "Start= 0 ---- 243 ----terminator: False\n",
      "Start= 0 ---- 244 ----terminator: False\n",
      "Start= 0 ---- 245 ----terminator: False\n",
      "Start= 0 ---- 246 ----terminator: False\n",
      "Start= 0 ---- 247 ----terminator: False\n",
      "Start= 0 ---- 248 ----terminator: False\n",
      "Start= 0 ---- 249 ----terminator: False\n",
      "Start= 0 ---- 250 ----terminator: False\n",
      "Start= 0 ---- 251 ----terminator: False\n",
      "Start= 0 ---- 252 ----terminator: False\n",
      "Start= 0 ---- 253 ----terminator: False\n",
      "Start= 0 ---- 254 ----terminator: False\n",
      "Start= 0 ---- 255 ----terminator: False\n",
      "Start= 0 ---- 256 ----terminator: False\n",
      "Start= 0 ---- 257 ----terminator: False\n",
      "Start= 0 ---- 258 ----terminator: False\n",
      "Start= 0 ---- 259 ----terminator: False\n",
      "Start= 0 ---- 260 ----terminator: False\n",
      "Start= 0 ---- 261 ----terminator: False\n",
      "Start= 0 ---- 262 ----terminator: False\n",
      "Start= 0 ---- 263 ----terminator: False\n"
     ]
    }
   ],
   "source": [
    "graphname=\"V_223\"\n",
    "G=Graph([(\"0\",\"1\"),(\"1\",\"2\"),(\"2\",\"3\"),(\"3\",\"4\"),(\"4\",\"0\"),(\"0\",\"5\"),(\"5\",\"2\")], multiedges=True)\n",
    "\n",
    "data=unpickle(graphname) #Size=264\n",
    "\n",
    "#Are we picking the index of the break case properly? #Y ind_breaks=0\n",
    "# data=unpickle(graphname)\n",
    "# for i in data:\n",
    "#     print(i)\n",
    "\n",
    "dic_l=analyse_graphname(G,data,ind_breaks=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Store list of dictionaries\n",
    "pickle_dic_l(graphname,dic_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of wsc 264\n",
      "Number of wsc that do/do not satisfy graph poly == tree poly: {True: 264}\n",
      "Number of polytopes of a given (dimension:number of at dim): {5: 264}\n",
      "Number of wsc that are/are not generated by phi_rep: {True: 264}\n",
      "Number of wsc that are/are not generated by phi_av: {False: 228, True: 36}\n",
      "Number of wsc that are/are not generated by phi_can: {True: 1, False: 263}\n",
      "Number of wsc that are/are not generated by phi_av_translated1: {True: 38, False: 226}\n",
      "Number of wsc that are/are not generated by phi_av_translated2: {False: 226, True: 38}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "analyse_table(dic_l,f=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### V_224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "graphname=\"V_224\"\n",
    "G=Graph([(\"0\",\"1\"),(\"1\",\"2\"),(\"2\",\"3\"),(\"3\",\"4\"),(\"4\",\"5\"),(\"5\",\"0\"),(\"0\",\"6\"),(\"6\",\"2\")], multiedges=True)\n",
    "\n",
    "# data=unpickle(graphname)\n",
    "\n",
    "data=unpickle(graphname) #Size=2040\n",
    "\n",
    "#Are we picking the index of the break case properly? #Y ind_breaks=0\n",
    "# data=unpickle(graphname)\n",
    "# for i in data:\n",
    "#     print(i)\n",
    "\n",
    "dic_l=analyse_graphname(G,data,ind_breaks=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Store list of dictionaries\n",
    "pickle_dic_l(graphname,dic_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyse_table(dic_l,f=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### V_233"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "graphname=\"V_233\"\n",
    "G=Graph([(\"0\",\"1\"),(\"1\",\"2\"),(\"2\",\"3\"),(\"3\",\"4\"),(\"4\",\"5\"),(\"5\",\"0\"),(\"0\",\"6\"),(\"6\",\"3\")], multiedges=True)\n",
    "\n",
    "data=unpickle(graphname) #Size=2856\n",
    "\n",
    "#Are we picking the index of the break case properly? #Y ind_breaks=0\n",
    "# data=unpickle(graphname)\n",
    "# for i in data:\n",
    "#     print(i)\n",
    "\n",
    "dic_l=analyse_graphname(G,data,ind_breaks=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Store list of dictionaries\n",
    "pickle_dic_l(graphname,dic_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "analyse_table(dic_l,f=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instead of using phi to reconstruct the assignments of the wsc.\n",
    "# We can just ask whether the phi is in tree_poly.\n",
    "\n",
    "# P1 = Polyhedron(vertices = [[-5,2], [4,4], [3,0], [1,0], [2,-4], [-3,-1], [-5,-3]])\n",
    "# P1\n",
    "# # print([0,10] in P1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyse_graphname(G,data,start=0,terminator=False,ind_breaks=0): \n",
    "    \"\"\"\n",
    "    Obj: Create a table of results\n",
    "\n",
    "    #inputs:\n",
    "    #     start: the ith term 1,...,k you want to start the computation from.\n",
    "    #     ind_breaks= the index of the wsc in data which contains the break divisor case.(find by inspection usuall is 0th)\n",
    "    #     terminator = is a number 1,...,k, the nth to which we calculate upo to so not to have to calc all cases (used for examples).\n",
    "    #     data=is the wsc data I have stored in examples\n",
    "    #     G=Graph([(\"0\",\"1\"),(\"1\",\"2\"),(\"2\",\"0\")], multiedges=True)\n",
    "    \n",
    "    Return:True or false if polys are equal, dimesion of polytope and repsentative phi in fraction form.\n",
    "    \n",
    "    Returns: a list of dictionaries.\n",
    "    \"\"\"\n",
    "    \n",
    "    g=get_first_betti_number(G)\n",
    "    break_wsc=data[ind_breaks]\n",
    "    breaks=break_wsc[1] #the list of break divisors of G.\n",
    "\n",
    "    dic_l=[]\n",
    "    for term,wsc in enumerate(data):\n",
    "        \n",
    "        #Use start to skip to the case you want to study.\n",
    "        if term<start-1:\n",
    "            continue\n",
    "        \n",
    "        print(\"Start=\",start,\"----\",term,\"----terminator:\",terminator)\n",
    "        \n",
    "        # data is the set of a weak stability condityions for the graph up to translation.\n",
    "        #wsc is the packet of data for athe term'th weak stability condition \n",
    "        \n",
    "        if terminator!=False:\n",
    "            if term > terminator-1:\n",
    "                break\n",
    "        \n",
    "    \n",
    "        #for Tree_poly\n",
    "        assignments=wsc[2] #[(Graph on 3 vertices, [0, 0, 0]),(Graph on 3 vertices, [0, 0, 0]),(Graph on 3 vertices, [0, 0, 0])]\n",
    "\n",
    "        #for Graph_poly\n",
    "        div_l=data[term][1].tolist() #lbm [[0, 0, 1], [0, 1, 0], [1, 0, 0]]\n",
    "        \n",
    "        tree_poly=get_intersection_tree_poly(G,assignments)\n",
    "        \n",
    "        \"We see this is always true so we done check\"\n",
    "        #!! (when checking ) Remove for now due to time taken add back later #Are they equal?\n",
    "        # graph_poly,tree_poly,S=check_graph_equals_tree_poly(G,assignments,div_l)\n",
    "        \n",
    "\n",
    "        #Phi terms in polytope\n",
    "\n",
    "        #av\n",
    "        phi_av=get_phi_av(div_l)\n",
    "        frac_phi_av=phi_av_frac(phi_av)  #phi_av_frac(phi_av) ['1/3', '1/3', '1/3']\n",
    "        ##checks\n",
    "#         ass_l_phi_av=get_all_assignment_phi(phi_av,G)\n",
    "        \n",
    "#         phi_av_check=compare_assignment_l(assignments,ass_l_phi_av)\n",
    "        \n",
    "        phi_av_check=phi_av in tree_poly\n",
    "\n",
    "\n",
    "\n",
    "        #av_trans\n",
    "        if g>1:\n",
    "            phi_can=get_phi_can(G)\n",
    "            # phi_av #[Fraction(5, 8), Fraction(3, 8), Fraction(5, 8), Fraction(3, 8)]\n",
    "            phi_av_breaks=get_phi_av_breaks(breaks)# phi_av_breaks #[Fraction(5, 8), Fraction(3, 8), Fraction(5, 8), Fraction(3, 8)]\n",
    "\n",
    "            #main obj here: check both cases\n",
    "            #All possible phi_av_trans cases\n",
    "#             phi_1,phi_2,phi_3,phi_4,phi_5,phi_6,phi_7,phi_8=get_phi_av_trans_all(phi_can,phi_av,phi_av_breaks)\n",
    "\n",
    "\n",
    "#             ##Checks: phi_can\n",
    "#             phi_can_check=phi_can in tree_poly\n",
    "            \n",
    "#             ##checks phi_transalated\n",
    "#             phi_1_check=phi_1 in tree_poly\n",
    "\n",
    "#             phi_2_check=phi_2 in tree_poly\n",
    "\n",
    "#             phi_3_check=phi_3 in tree_poly\n",
    "\n",
    "#             phi_4_check=phi_4 in tree_poly\n",
    "\n",
    "#             phi_5_check=phi_5 in tree_poly\n",
    "\n",
    "#             phi_6_check=phi_6 in tree_poly\n",
    "\n",
    "#             phi_7_check=phi_7 in tree_poly\n",
    "\n",
    "#             phi_8_check=phi_8 in tree_poly\n",
    "            \n",
    "            \n",
    "            dic={\"Dimension of tree-poly\":dim(tree_poly),\n",
    "                 \n",
    "                \"phi_av\":phi_av,\n",
    "                \"frac_phi_av\":frac_phi_av,\n",
    "                \"phi_av generates wsc-assignments?\":phi_av_check,\n",
    "                 \n",
    "#                 \"phi_can\":phi_can,\n",
    "#                 \"phi_can generates wsc-assignments?\":phi_can_check,\n",
    "\n",
    "#                 \"phi_av_trans_1\": phi_1,\n",
    "#                 \"phi_av_trans_1 generates wsc-assignments?\": phi_1_check,\n",
    "\n",
    "#                 \"phi_av_trans_2\": phi_2,\n",
    "#                 \"phi_av_trans_2 generates wsc-assignments?\": phi_2_check,\n",
    "\n",
    "#                 \"phi_av_trans_3\": phi_3,\n",
    "#                 \"phi_av_trans_3 generates wsc-assignments?\": phi_3_check,\n",
    "\n",
    "#                 \"phi_av_trans_4\": phi_4,\n",
    "#                 \"phi_av_trans_4 generates wsc-assignments?\": phi_4_check,\n",
    "\n",
    "#                 \"phi_av_trans_5\": phi_5,\n",
    "#                 \"phi_av_trans_5 generates wsc-assignments?\": phi_5_check,\n",
    "\n",
    "#                 \"phi_av_trans_6\": phi_6,\n",
    "#                 \"phi_av_trans_6 generates wsc-assignments?\": phi_6_check,\n",
    "\n",
    "#                 \"phi_av_trans_7\": phi_7,\n",
    "#                 \"phi_av_trans_7 generates wsc-assignments?\": phi_7_check,\n",
    "\n",
    "#                 \"phi_av_trans_8\": phi_8,\n",
    "#                 \"phi_av_trans_8 generates wsc-assignments?\": phi_8_check\n",
    "\n",
    "                }\n",
    "            \n",
    "#                 \"frac_phi_av_trans\":frac_phi_av_trans,\n",
    "\n",
    "\n",
    "        else:\n",
    "            dic={\"Dimension of tree-poly\":dim(tree_poly),\n",
    "                 \n",
    "                \"phi_av\":phi_av,\n",
    "                \"frac_phi_av\":frac_phi_av,\n",
    "                \"phi_av generates wsc-assignments?\":phi_av_check}\n",
    "\n",
    "        dic_l.append(dic)\n",
    "        \n",
    "    return dic_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyse_table(dic_l,f=False):\n",
    "    \n",
    "    \"\"\"\n",
    "    Input: \n",
    "    \n",
    "    f: a flag for whether we are in genus 1 or not.\n",
    "    \n",
    "    list of\n",
    "            dic={\"Dimension of tree-poly\":dim(tree_poly),\n",
    "\n",
    "                \"phi_av\":phi_av,\n",
    "                \"frac_phi_av\":frac_phi_av,\n",
    "                \"phi_av generates wsc-assignments?\":phi_av_check,\n",
    "                 \n",
    "                \"phi_can\":phi_can,\n",
    "                \"phi_can generates wsc-assignments?\":phi_can_check,\n",
    "\n",
    "                \"phi_av_trans_1\":phi_1,\n",
    "                \"phi_av_trans_1 generates wsc-assignments?\":phi_1_check,...\n",
    "                \n",
    "                }\n",
    "            \n",
    "    Return:Summary of results\n",
    "    \"\"\"\n",
    "    \n",
    "    num_wsc=[]\n",
    "    \n",
    "    dim_value_counts=[]\n",
    "    \n",
    "    phi_av_polynum=[]\n",
    "    \n",
    "    phi_can_polynum=[]\n",
    "\n",
    "    phi_av_trans1_polynum=[]\n",
    "    phi_av_trans2_polynum=[]\n",
    "    phi_av_trans3_polynum=[]\n",
    "    phi_av_trans4_polynum=[]\n",
    "    phi_av_trans5_polynum=[]\n",
    "    phi_av_trans6_polynum=[]\n",
    "    phi_av_trans7_polynum=[]\n",
    "    phi_av_trans8_polynum=[]\n",
    "    \n",
    "    \n",
    "    for dic in dic_l:\n",
    "    \n",
    "        num_wsc.append(dic[\"Dimension of tree-poly\"])\n",
    "        \n",
    "    \n",
    "        dim_value_counts.append(dic[\"Dimension of tree-poly\"])\n",
    "    \n",
    "        phi_av_polynum.append(dic[\"phi_av generates wsc-assignments?\"])\n",
    "        \n",
    "        if f==True:\n",
    "            phi_can_polynum.append(dic[\"phi_can generates wsc-assignments?\"])\n",
    "            phi_av_trans1_polynum.append(dic[\"phi_av_trans_1 generates wsc-assignments?\"])\n",
    "            phi_av_trans2_polynum.append(dic[\"phi_av_trans_2 generates wsc-assignments?\"])\n",
    "            phi_av_trans3_polynum.append(dic[\"phi_av_trans_3 generates wsc-assignments?\"])\n",
    "            phi_av_trans4_polynum.append(dic[\"phi_av_trans_4 generates wsc-assignments?\"])\n",
    "            phi_av_trans5_polynum.append(dic[\"phi_av_trans_5 generates wsc-assignments?\"])\n",
    "            phi_av_trans6_polynum.append(dic[\"phi_av_trans_6 generates wsc-assignments?\"])\n",
    "            phi_av_trans7_polynum.append(dic[\"phi_av_trans_7 generates wsc-assignments?\"])\n",
    "            phi_av_trans8_polynum.append(dic[\"phi_av_trans_8 generates wsc-assignments?\"])            \n",
    "\n",
    "    dim_value_counts_dict=dict(Counter(dim_value_counts))    \n",
    "    \n",
    "    phi_av_TF=dict(Counter(phi_av_polynum))\n",
    "    \n",
    "    \n",
    "    phi_can_polynum_TF=None\n",
    "    phi_av_trans1_polynum_TF=None\n",
    "    phi_av_trans2_polynum_TF=None\n",
    "    phi_av_trans3_polynum_TF=None\n",
    "    phi_av_trans4_polynum_TF=None\n",
    "    phi_av_trans5_polynum_TF=None\n",
    "    phi_av_trans6_polynum_TF=None\n",
    "    phi_av_trans7_polynum_TF=None\n",
    "    phi_av_trans8_polynum_TF=None\n",
    "\n",
    "    if f==True:\n",
    "        phi_can_polynum_TF=dict(Counter(phi_can_polynum))\n",
    "        \n",
    "        phi_av_trans1_polynum_TF=dict(Counter(phi_av_trans1_polynum))\n",
    "        phi_av_trans2_polynum_TF=dict(Counter(phi_av_trans2_polynum))\n",
    "        phi_av_trans3_polynum_TF=dict(Counter(phi_av_trans3_polynum))\n",
    "        phi_av_trans4_polynum_TF=dict(Counter(phi_av_trans4_polynum))\n",
    "        phi_av_trans5_polynum_TF=dict(Counter(phi_av_trans5_polynum))\n",
    "        phi_av_trans6_polynum_TF=dict(Counter(phi_av_trans6_polynum))\n",
    "        phi_av_trans7_polynum_TF=dict(Counter(phi_av_trans7_polynum))\n",
    "        phi_av_trans8_polynum_TF=dict(Counter(phi_av_trans8_polynum))\n",
    "\n",
    "    print(textwrap.dedent(f'''\\\n",
    "        Total number of wsc {len(num_wsc)}\n",
    "        Number of polytopes of a given (dimension:number of at dim): {dim_value_counts_dict}\n",
    "        Number of wsc that are/are not generated by phi_av: {phi_av_TF}\n",
    "        Number of wsc that are/are not generated by phi_can: {phi_can_polynum_TF}\n",
    "        Number of wsc that are/are not generated by phi_av_translated1: {phi_av_trans1_polynum_TF}\n",
    "        Number of wsc that are/are not generated by phi_av_translated2: {phi_av_trans2_polynum_TF}\n",
    "        Number of wsc that are/are not generated by phi_av_translated3: {phi_av_trans3_polynum_TF}\n",
    "        Number of wsc that are/are not generated by phi_av_translated4: {phi_av_trans4_polynum_TF}\n",
    "        Number of wsc that are/are not generated by phi_av_translated5: {phi_av_trans5_polynum_TF}\n",
    "        Number of wsc that are/are not generated by phi_av_translated6: {phi_av_trans6_polynum_TF}\n",
    "        Number of wsc that are/are not generated by phi_av_translated7: {phi_av_trans7_polynum_TF}\n",
    "        Number of wsc that are/are not generated by phi_av_translated8: {phi_av_trans8_polynum_TF}        \n",
    "        \n",
    "    '''))\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def analyse_graphname(G,data,start=0,terminator=False,ind_breaks=0): #old\n",
    "#     \"\"\"\n",
    "#     Obj: Create a table of results\n",
    "\n",
    "#     #inputs:\n",
    "#     #     start: the ith term 1,...,k you want to start the computation from.\n",
    "#     #     ind_breaks= the index of the wsc in data which contains the break divisor case.(find by inspection usuall is 0th)\n",
    "#     #     terminator = is a number 1,...,k, the nth to which we calculate upo to so not to have to calc all cases (used for examples).\n",
    "#     #     data=is the wsc data I have stored in examples\n",
    "#     #     G=Graph([(\"0\",\"1\"),(\"1\",\"2\"),(\"2\",\"0\")], multiedges=True)\n",
    "    \n",
    "#     Return:True or false if polys are equal, dimesion of polytope and repsentative phi in fraction form.\n",
    "    \n",
    "#     Returns: a list of dictionaries.\n",
    "#     \"\"\"\n",
    "    \n",
    "#     g=get_first_betti_number(G)\n",
    "#     break_wsc=data[ind_breaks]\n",
    "#     breaks=break_wsc[1] #the list of break divisors of G.\n",
    "\n",
    "#     dic_l=[]\n",
    "#     for term,wsc in enumerate(data):\n",
    "        \n",
    "#         #Use start to skip to the case you want to study.\n",
    "#         if term<start-1:\n",
    "#             continue\n",
    "        \n",
    "#         print(\"Start=\",start,\"----\",term,\"----terminator:\",terminator)\n",
    "        \n",
    "#         # data is the set of a weak stability condityions for the graph up to translation.\n",
    "#         #wsc is the packet of data for athe term'th weak stability condition \n",
    "        \n",
    "#         if terminator!=False:\n",
    "#             if term > terminator-1:\n",
    "#                 break\n",
    "        \n",
    "    \n",
    "#         #for Tree_poly\n",
    "#         assignments=wsc[2] #[(Graph on 3 vertices, [0, 0, 0]),(Graph on 3 vertices, [0, 0, 0]),(Graph on 3 vertices, [0, 0, 0])]\n",
    "\n",
    "#         #for Graph_poly\n",
    "#         div_l=data[term][1].tolist() #lbm [[0, 0, 1], [0, 1, 0], [1, 0, 0]]\n",
    "        \n",
    "\n",
    "#         #!! (when checking ) Remove for now due to time taken add back later #Are they equal?\n",
    "#         graph_poly,tree_poly,S=check_graph_equals_tree_poly(G,assignments,div_l)\n",
    "        \n",
    "#         #Keep only this lines if checking.\n",
    "#         # graph_poly=get_graph_poly(G,div_l)\n",
    "#         # S=\"LATER\"\n",
    "\n",
    "\n",
    "\n",
    "#         #Phi terms in polytope\n",
    "        \n",
    "#         #rep\n",
    "#         phi_rep=get_a_phi(graph_poly)\n",
    "#         frac_phi_rep=get_phi_frac(phi_rep,limit=10)\n",
    "#         ## checks\n",
    "#         ass_l_phi_rep=get_all_assignment_phi(phi_rep,G)\n",
    "        \n",
    "# #         print(\"assignments\",assignments)\n",
    "# #         print(\"ass_l_phi_rep\",ass_l_phi_rep)\n",
    "        \n",
    "#         phi_rep_check=compare_assignment_l(assignments,ass_l_phi_rep)\n",
    "\n",
    "#         #av\n",
    "#         phi_av=get_phi_av(div_l)\n",
    "#         frac_phi_av=phi_av_frac(phi_av)  #phi_av_frac(phi_av) ['1/3', '1/3', '1/3']\n",
    "#         ##checks\n",
    "#         ass_l_phi_av=get_all_assignment_phi(phi_av,G)\n",
    "#         phi_av_check=compare_assignment_l(assignments,ass_l_phi_av)\n",
    "                \n",
    "\n",
    "#         #av_trans\n",
    "#         if g>1:\n",
    "#             phi_can=get_phi_can(G)\n",
    "#             # phi_av #[Fraction(5, 8), Fraction(3, 8), Fraction(5, 8), Fraction(3, 8)]\n",
    "#             phi_av_breaks=get_phi_av_breaks(breaks)# phi_av_breaks #[Fraction(5, 8), Fraction(3, 8), Fraction(5, 8), Fraction(3, 8)]\n",
    "\n",
    "#             #main obj here: check both cases\n",
    "#             phi_av_trans1=get_phi_av_trans1(phi_can,phi_av,phi_av_breaks)\n",
    "#             phi_av_trans2=get_phi_av_trans2(phi_can,phi_av,phi_av_breaks)\n",
    "\n",
    "#             ##Checks: phi_can\n",
    "#             ass_l_phi_can=get_all_assignment_phi(phi_can,G)\n",
    "#             phi_can_check=compare_assignment_l(assignments,ass_l_phi_can)\n",
    "            \n",
    "#             ##Checks: phi_av_trans1\n",
    "#             ass_l_phi_trans1=get_all_assignment_phi(phi_av_trans1,G)\n",
    "#             phi_av_trans1_check=compare_assignment_l(assignments,ass_l_phi_trans1)\n",
    "            \n",
    "#             ##Checks: phi_av_trans2\n",
    "#             ass_l_phi_trans2=get_all_assignment_phi(phi_av_trans2,G)\n",
    "#             phi_av_trans2_check=compare_assignment_l(assignments,ass_l_phi_trans2)\n",
    "            \n",
    "            \n",
    "#             dic={\"tree-poly equals graph-poly\":S,\n",
    "#                  \"Dimension of graph-poly\":dim(graph_poly),\n",
    "\n",
    "#                 \"phi_rep\":phi_rep,\n",
    "#                 \"frac_phi_rep\":frac_phi_rep,\n",
    "#                 \"phi_rep generates wsc-assignments?\":phi_rep_check,\n",
    "                 \n",
    "#                 \"phi_av\":phi_av,\n",
    "#                 \"frac_phi_av\":frac_phi_av,\n",
    "#                 \"phi_av generates wsc-assignments?\":phi_av_check,\n",
    "                 \n",
    "#                 \"phi_can\":phi_can,\n",
    "#                 \"phi_can generates wsc-assignments?\":phi_can_check,\n",
    "\n",
    "#                 \"phi_av_trans1\":phi_av_trans1,\n",
    "#                 \"phi_av_trans1 generates wsc-assignments?\":phi_av_trans1_check,\n",
    "                \n",
    "#                 \"phi_av_trans2\":phi_av_trans2,\n",
    "#                 \"phi_av_trans2 generates wsc-assignments?\":phi_av_trans2_check\n",
    "                \n",
    "#                 }\n",
    "            \n",
    "# #                 \"frac_phi_av_trans\":frac_phi_av_trans,\n",
    "\n",
    "\n",
    "#         else:\n",
    "#             dic={\"tree-poly equals graph-poly\":S,\n",
    "#                  \"Dimension of graph-poly\":dim(graph_poly),\n",
    "\n",
    "#                 \"phi_rep\":phi_rep,\n",
    "#                 \"frac_phi_rep\":frac_phi_rep,\n",
    "#                 \"phi_rep generates wsc-assignments?\":phi_rep_check,\n",
    "                 \n",
    "#                 \"phi_av\":phi_av,\n",
    "#                 \"frac_phi_av\":frac_phi_av,\n",
    "#                 \"phi_av generates wsc-assignments?\":phi_av_check}\n",
    "\n",
    "#         dic_l.append(dic)\n",
    "        \n",
    "# #     df = pd.DataFrame(dic_l)\n",
    "\n",
    "#     return dic_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def analyse_table(dic_l,f=False): #old\n",
    "    \n",
    "#     \"\"\"\n",
    "#     Input: \n",
    "    \n",
    "#     f: a flag for whether we are in genus 1 or not.\n",
    "    \n",
    "#     list of\n",
    "#             dic={\"tree-poly equals graph-poly\":S,\n",
    "#                  \"Dimension of graph-poly\":dim(graph_poly),\n",
    "\n",
    "#                 \"phi_rep\":phi_rep,\n",
    "#                 \"frac_phi_rep\":frac_phi_rep,\n",
    "#                 \"phi_rep generates wsc-assignments?\":phi_rep_check,\n",
    "                 \n",
    "#                 \"phi_av\":phi_av,\n",
    "#                 \"frac_phi_av\":frac_phi_av,\n",
    "#                 \"phi_av generates wsc-assignments?\":phi_av_check,\n",
    "                 \n",
    "#                 \"phi_can\":phi_can,\n",
    "#                 \"phi_can generates wsc-assignments?\":phi_can_check,\n",
    "\n",
    "#                 \"phi_av_trans1\":phi_av_trans1,\n",
    "#                 \"phi_av_trans1 generates wsc-assignments?\":phi_av_trans1_check,\n",
    "                \n",
    "#                 \"phi_av_trans2\":phi_av_trans2,\n",
    "#                 \"phi_av_trans2 generates wsc-assignments?\":phi_av_trans2_check\n",
    "                \n",
    "#                 }\n",
    "            \n",
    "#     Return:Summary of results\n",
    "#     \"\"\"\n",
    "    \n",
    "#     num_wsc=[]\n",
    "    \n",
    "#     tree_graph_poly_TF=[]\n",
    "#     dim_value_counts=[]\n",
    "    \n",
    "#     phi_rep_polynum=[]\n",
    "#     phi_av_polynum=[]\n",
    "    \n",
    "#     phi_can_polynum=[]\n",
    "#     phi_av_trans1_polynum=[]\n",
    "#     phi_av_trans2_polynum=[]\n",
    "    \n",
    "    \n",
    "#     for dic in dic_l:\n",
    "    \n",
    "#         num_wsc.append(dic[\"tree-poly equals graph-poly\"])\n",
    "        \n",
    "#         tree_graph_poly_TF.append(dic[\"tree-poly equals graph-poly\"])\n",
    "    \n",
    "#         dim_value_counts.append(dic[\"Dimension of graph-poly\"])\n",
    "    \n",
    "#         phi_rep_polynum.append(dic[\"phi_rep generates wsc-assignments?\"])\n",
    "#         phi_av_polynum.append(dic[\"phi_av generates wsc-assignments?\"])\n",
    "        \n",
    "#         if f==True:\n",
    "#             phi_can_polynum.append(dic[\"phi_can generates wsc-assignments?\"])\n",
    "#             phi_av_trans1_polynum.append(dic[\"phi_av_trans1 generates wsc-assignments?\"])\n",
    "#             phi_av_trans2_polynum.append(dic[\"phi_av_trans2 generates wsc-assignments?\"])\n",
    "\n",
    "\n",
    "#     dim_value_counts_dict=dict(Counter(dim_value_counts))\n",
    "    \n",
    "#     tree_graph_poly_TF_dict=dict(Counter(tree_graph_poly_TF))\n",
    "    \n",
    "#     phi_rep_TF=dict(Counter(phi_rep_polynum))\n",
    "    \n",
    "#     phi_av_TF=dict(Counter(phi_av_polynum))\n",
    "    \n",
    "    \n",
    "#     phi_can_polynum_TF=None\n",
    "#     phi_av_trans1_polynum_TF=None\n",
    "#     phi_av_trans2_polynum_TF=None\n",
    "    \n",
    "#     if f==True:\n",
    "#         phi_can_polynum_TF=dict(Counter(phi_can_polynum))\n",
    "#         phi_av_trans1_polynum_TF=dict(Counter(phi_av_trans1_polynum))\n",
    "\n",
    "#         phi_av_trans2_polynum_TF=dict(Counter(phi_av_trans2_polynum))\n",
    "\n",
    "#     print(textwrap.dedent(f'''\\\n",
    "#         Total number of wsc {len(num_wsc)}\n",
    "#         Number of wsc that do/do not satisfy graph poly == tree poly: {tree_graph_poly_TF_dict}\n",
    "#         Number of polytopes of a given (dimension:number of at dim): {dim_value_counts_dict}\n",
    "#         Number of wsc that are/are not generated by phi_rep: {phi_rep_TF}\n",
    "#         Number of wsc that are/are not generated by phi_av: {phi_av_TF}\n",
    "#         Number of wsc that are/are not generated by phi_can: {phi_can_polynum_TF}\n",
    "#         Number of wsc that are/are not generated by phi_av_translated1: {phi_av_trans1_polynum_TF}\n",
    "#         Number of wsc that are/are not generated by phi_av_translated2: {phi_av_trans2_polynum_TF}\n",
    "#     '''))\n",
    "#     return "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "title"
    ]
   },
   "source": [
    "# Specific $\\phi$ <a name=\"spec\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we construct different possible $\\phi$ terms which we believe allow for $\\sigma_{\\Gamma}=\\sigma_{\\Gamma}^{\\phi}$, that is they are the $\\phi$ for the weak stability condition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Examples of phi terms <a name=\"spec1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #I3 trivial case\n",
    "# G=Graph([(\"0\",\"1\"),(\"1\",\"2\"),(\"2\",\"0\")], multiedges=True)\n",
    "# div_l=[[0,1,0],[1,0,0],[0,0,1]]\n",
    "\n",
    "# #representative point\n",
    "\n",
    "# # graph_poly=get_graph_poly(G,div_l)\n",
    "# phi_rep=get_a_phi(graph_poly)\n",
    "# # print(\"phi_rep:\",phi_rep)# phi_rep: [0.333, 0.333, 0.333]\n",
    "# # print(\"frac_phi_rep:\",get_phi_frac(phi_rep))# frac_phi_rep: (1/3, 1/3, 1/3)\n",
    "\n",
    "# # take phi_av\n",
    "# phi_av=get_phi_av(div_l)\n",
    "# #For table:\n",
    "# print(\"phi_av_dec:\",phi_av_dec) #phi_av_dec: [0.333, 0.333, 0.333]\n",
    "# print(\"phi_av_frac(phi_av)\",phi_av_frac(phi_av)) #phi_av_frac(phi_av) ['1/3', '1/3', '1/3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # graphname=\"G4M2\"\n",
    "# G=Graph([(\"0\",\"1\"),(\"1\",\"2\"),(\"2\",\"3\"),(\"3\",\"0\"),(\"0\",\"2\")], multiedges=True)\n",
    "\n",
    "# # phi_can=get_phi_can(G)\n",
    "# # print(\"phi_can:\",phi_can)#[4/5, 1/5, 4/5, 1/5]\n",
    "\n",
    "# #Need to know average of breaks case. Need to find that wsc first.\n",
    "\n",
    "# breaks_div_l=[[2,0,0,0],[1,1,0,0],[1,0,1,0],[0,1,1,0],[0,0,2,0],[0,1,0,1],[1,0,0,1],[0,0,1,1]]\n",
    "# phi_av_breaks=get_phi_av_breaks(breaks_div_l)\n",
    "# # phi_av_breaks #[Fraction(5, 8), Fraction(3, 8), Fraction(5, 8), Fraction(3, 8)]\n",
    "\n",
    "# #av_trans\n",
    "# div_l=breaks_div_l\n",
    "# phi_av=get_phi_av(div_l) #D# phi_av #[Fraction(5, 8), Fraction(3, 8), Fraction(5, 8), Fraction(3, 8)]\n",
    "# phi_av_trans1=get_phi_av_trans1(phi_can,phi_av,phi_av_breaks)#[0.8, 0.2, 0.8, 0.2]\n",
    "\n",
    "# phi_av_trans2=get_phi_av_trans2(phi_can,phi_av,phi_av_breaks)\n",
    "# # print(phi_av_trans2) #[0.8, 0.2, 0.8, 0.2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Inspecting phi_av for GNkM1 <a name=\"spec2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Investigate phi terms for change in multiedge for the same cycle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### G3 example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "\n",
    "graphname=\"132_G3kM1\"\n",
    "data=unpickle(graphname)\n",
    "\n",
    "# extend_graphname=\"G31M1\"\n",
    "G1=Graph([(\"0\",\"1\",\"e11\"),(\"1\",\"2\",\"e2\"),(\"2\",\"0\",\"e3\"),], multiedges=True)\n",
    "\n",
    "# extend_graphname=\"G32M1\"\n",
    "G2=Graph([(\"0\",\"1\",\"e11\"),(\"1\",\"2\",\"e2\"),(\"2\",\"0\",\"e3\"),(\"0\",\"1\",\"e12\")], multiedges=True)\n",
    "\n",
    "# extend_graphname=\"G33M1\"\n",
    "G3=Graph([(\"0\",\"1\",\"e11\"),(\"1\",\"2\",\"e2\"),(\"2\",\"0\",\"e3\"),(\"0\",\"1\",\"e12\"),(\"0\",\"1\",\"e13\")], multiedges=True)\n",
    "\n",
    "# extend_graphname=\"G34M1\"\n",
    "G4=Graph([(\"0\",\"1\",\"e11\"),(\"1\",\"2\",\"e2\"),(\"2\",\"0\",\"e3\"),(\"0\",\"1\",\"e12\"),(\"0\",\"1\",\"e13\"),(\"0\",\"1\",\"e14\")], multiedges=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for Tree_poly\n",
    "wsc=data[1]\n",
    "wsc\n",
    "# wsc[2][0][0].edges()\n",
    "\n",
    "assignments=wsc[2] #[(Graph on 3 vertices, [0, 0, 0]),(Graph on 3 vertices, [0, 0, 0]),(Graph on 3 vertices, [0, 0, 0])]\n",
    "\n",
    "#for Graph_poly\n",
    "div_l=wsc[1].tolist() #lbm [[0, 0, 1], [0, 1, 0], [1, 0, 0]]\n",
    "\n",
    "\n",
    "#!! (when checking ) Remove for now due to time taken add back later #Are they equal?\n",
    "graph_poly,tree_poly,S=check_graph_equals_tree_poly(G,assignments,div_l)\n",
    "\n",
    "#Keep only this lines if checking.\n",
    "# graph_poly=get_graph_poly(G,div_l)\n",
    "# S=\"LATER\"\n",
    "\n",
    "print(dim(graph_poly),dim(tree_poly),S)\n",
    "\n",
    "#Phi terms in polytope\n",
    "\n",
    "#rep\n",
    "phi_rep=get_a_phi(graph_poly)\n",
    "phi_rep\n",
    "\n",
    "frac_phi_rep=get_phi_frac(phi_rep,limit=10)\n",
    "## checks\n",
    "ass_l_phi_rep=get_all_assignment_phi(phi_rep,G)\n",
    "\n",
    "#         print(\"assignments\",assignments)\n",
    "#         print(\"ass_l_phi_rep\",ass_l_phi_rep)\n",
    "ass_l_phi_rep\n",
    "\n",
    "phi_rep_check=compare_assignment_l(assignments,ass_l_phi_rep)\n",
    "\n",
    "#av\n",
    "phi_av=get_phi_av(div_l)\n",
    "frac_phi_av=phi_av_frac(phi_av)  #phi_av_frac(phi_av) ['1/3', '1/3', '1/3']\n",
    "##checks\n",
    "ass_l_phi_av=get_all_assignment_phi(phi_av,G)\n",
    "phi_av_check=compare_assignment_l(assignments,ass_l_phi_av)\n",
    "\n",
    "\n",
    "#av_trans\n",
    "\n",
    "phi_can=get_phi_can(G)\n",
    "# phi_av #[Fraction(5, 8), Fraction(3, 8), Fraction(5, 8), Fraction(3, 8)]\n",
    "phi_av_breaks=get_phi_av_breaks(breaks)# phi_av_breaks #[Fraction(5, 8), Fraction(3, 8), Fraction(5, 8), Fraction(3, 8)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### G4 example "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extend_graphname=\"G41M1\" \n",
    "G1=Graph([(\"0\",\"1\",\"e11\"),(\"1\",\"2\",\"e2\"),(\"2\",\"3\",\"e3\"),(\"3\",\"0\",\"e4\")], multiedges=True)\n",
    "\n",
    "# extend_graphname=\"G42M1\" \n",
    "G2=Graph([(\"0\",\"1\",\"e11\"),(\"1\",\"2\",\"e2\"),(\"2\",\"3\",\"e3\"),(\"3\",\"0\",\"e4\"),(\"0\",\"1\",\"e12\")], multiedges=True)\n",
    "\n",
    "# extend_graphname=\"G43M1\" \n",
    "G3=Graph([(\"0\",\"1\",\"e11\"),(\"1\",\"2\",\"e2\"),(\"2\",\"3\",\"e3\"),(\"3\",\"0\",\"e4\"),(\"0\",\"1\",\"e12\"),(\"0\",\"1\",\"e13\")], multiedges=True)\n",
    "\n",
    "# extend_graphname=\"G44M1\" \n",
    "G4=Graph([(\"0\",\"1\",\"e11\"),(\"1\",\"2\",\"e2\"),(\"2\",\"3\",\"e3\"),(\"3\",\"0\",\"e4\"),(\"0\",\"1\",\"e12\"),(\"0\",\"1\",\"e13\"),(\"0\",\"1\",\"e14\")], multiedges=True)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": [
     "Function"
    ]
   },
   "outputs": [],
   "source": [
    "def get_a_phi(poly):\n",
    "    \n",
    "    \"\"\"\n",
    "    Objective:Picks a representative phi from the polyope.\n",
    "    Input:\n",
    "    Return\n",
    "    \"\"\"\n",
    "    \n",
    "#     phi=poly.center()\n",
    "    phi=poly.representative_point()\n",
    "    phi=[round(i,3) for i in phi]\n",
    "    return phi\n",
    "\n",
    "def get_phi_frac(phi,limit=10):\n",
    "    \n",
    "    \"\"\"\n",
    "    Objective:\n",
    "    Input:\n",
    "    Return: A list of strings of fraction.\n",
    "    \"\"\"\n",
    "    \n",
    "    phi=tuple([i.n() for i in phi])\n",
    "\n",
    "    phi=tuple([i.nearby_rational(max_error=0.001) for i in phi]) # change from real to rational;\n",
    "    \n",
    "    #Turn phi into a fraction.\n",
    "    # frac_phi = tuple([str(i) for i in phi])\n",
    "    frac_phi = tuple([i for i in phi])\n",
    "\n",
    "    return frac_phi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_phi_av(lbm):\n",
    "    \n",
    "    \"\"\"\n",
    "    Objective: Gets the average of sigma_{gamma}(gamma) in fraction form.\n",
    "    Input:\n",
    "    Return:\n",
    "    \"\"\" \n",
    "    \n",
    "    num=len(lbm)\n",
    "    \n",
    "    #lbm=given[[0,1,0],[1,0,0],[1,1,-1]] return the average [2/3,2/3,-1/3]\n",
    "    arr=np.array(lbm).transpose()\n",
    "    \n",
    "    phi=arr.sum(axis=1)\n",
    "\n",
    "    phi_av=[Fraction(i,num) for i in list(phi)]\n",
    "    \n",
    "    return phi_av\n",
    "\n",
    "def phi_av_frac(phi_av):\n",
    "    \n",
    "    formatted_fractions = []\n",
    "\n",
    "    for fraction in phi_av:\n",
    "        formatted_fraction = f\"{fraction.numerator}/{fraction.denominator}\"\n",
    "        formatted_fractions.append(formatted_fraction)\n",
    "\n",
    "\n",
    "    return formatted_fractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_phi_can(G):\n",
    "    \n",
    "    \"\"\"\n",
    "    Objective: only works for g>1\n",
    "    Input:\n",
    "    Return: canonical phi  for break divisor case.\n",
    "    \"\"\"\n",
    "    \n",
    "    vert_num=len(G.vertices())\n",
    "    g=get_first_betti_number(G)\n",
    "\n",
    "    if g<2:\n",
    "        return False\n",
    "    \n",
    "    phi_can=[]\n",
    "    for i in G.vertices():\n",
    "\n",
    "        deg=G.degree(vertices=i)  # number of edges meeting at vertex\n",
    "\n",
    "        numer=g+vert_num\n",
    "        demoner= (2*(g+vert_num))-2\n",
    "        frac=numer/demoner    \n",
    "        mult=frac*deg\n",
    "        phi_i= mult -1\n",
    "\n",
    "        phi_can.append(phi_i)\n",
    "\n",
    "    return phi_can\n",
    "\n",
    "def get_phi_av_breaks(l):\n",
    "\n",
    "    \"\"\"\n",
    "    Objective: takes the average of break divisors for the graph. case where assignm,ents are all 0.\n",
    "    Input:\n",
    "    Returns: phi _average for this case.\n",
    "    \"\"\"\n",
    "#     div_l=wsc[1] # The order i have stored the top part of the wsc.\n",
    "    \n",
    "    t_phi_av_breaks=get_phi_av(l)\n",
    "\n",
    "    #av lbm.\n",
    "    return t_phi_av_breaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_phi_av_trans_all(phi_can,phi_av,phi_av_breaks): \n",
    "    \n",
    "    \"\"\"\n",
    "    Objective: return all possible translations of the phi_av when we translate by the by phi_can and phi_av_breaks\n",
    "    \n",
    "    Input:\n",
    "    \n",
    "    phi_can: the canconical phi which always works for wsc with all zero assignments for g>1 graphs.\n",
    "    \n",
    "    phi_av: the phi average for the current wsc.\n",
    "    \n",
    "    phi_av_breaks: the phi average for the wsc with all zero assignments.\n",
    "    \n",
    "    Return: list of appropriate phi we think should work.\n",
    "    \"\"\"\n",
    "    \n",
    "    phi_1=np.array(phi_av)+np.array(phi_av_breaks)+np.array(phi_can)\n",
    "    phi_1=[round(i,4) for i in list(phi_1)]\n",
    "    \n",
    "    phi_2=np.array(phi_av)+np.array(phi_av_breaks)-np.array(phi_can)\n",
    "    phi_2=[round(i,4) for i in list(phi_2)]\n",
    "    \n",
    "    phi_3=np.array(phi_av)-np.array(phi_av_breaks)+np.array(phi_can)\n",
    "    phi_3=[round(i,4) for i in list(phi_3)]\n",
    "    \n",
    "    phi_4=-np.array(phi_av)+np.array(phi_av_breaks)+np.array(phi_can)\n",
    "    phi_4=[round(i,4) for i in list(phi_4)]\n",
    "    \n",
    "    phi_5=np.array(phi_av)-np.array(phi_av_breaks)-np.array(phi_can)\n",
    "    phi_5=[round(i,4) for i in list(phi_5)]\n",
    "    \n",
    "    phi_6=-np.array(phi_av)+np.array(phi_av_breaks)-np.array(phi_can)\n",
    "    phi_6=[round(i,4) for i in list(phi_6)]\n",
    "    \n",
    "    phi_7=-np.array(phi_av)-np.array(phi_av_breaks)+np.array(phi_can)\n",
    "    phi_7=[round(i,4) for i in list(phi_7)]\n",
    "    \n",
    "    phi_8=-np.array(phi_av)-np.array(phi_av_breaks)-np.array(phi_can)\n",
    "    phi_8=[round(i,4) for i in list(phi_8)]\n",
    "    \n",
    "    return phi_1,phi_2,phi_3,phi_4,phi_5,phi_6,phi_7,phi_8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#old\n",
    "\n",
    "def get_phi_av_trans1(phi_can,phi_av,phi_av_breaks): \n",
    "    \n",
    "    \"\"\"\n",
    "    Objective: return a translation of the average by the canconial phi where we translate by\n",
    "    \n",
    "    phi_can-phi_av_breaks\n",
    "    \n",
    "    Input:\n",
    "    \n",
    "    phi_can: the canconical phi which always works for wsc with all zero assignments for g>1 graphs.\n",
    "    \n",
    "    phi_av: the phi average for the current wsc.\n",
    "    \n",
    "    phi_av_breaks: the phi average for the wsc with all zero assignments.\n",
    "    \n",
    "    Return: appropriate phi we think should work.\n",
    "    \"\"\"\n",
    "    \n",
    "    trans=np.array(phi_can)-np.array(phi_av_breaks)\n",
    "    \n",
    "    test_phi=np.array(phi_av)+trans\n",
    "    \n",
    "    test_phi=list(test_phi)\n",
    "    test_phi=[round(i,4) for i in test_phi]\n",
    "    \n",
    "    return test_phi\n",
    "\n",
    "def get_phi_av_trans2(phi_can,phi_av,phi_av_breaks): \n",
    "    \n",
    "    \"\"\"SWAPPED\n",
    "    Objective: return a translation of the average by the canconial phi where we translate by\n",
    "    \n",
    "    phi_av_breaks-phi_can\n",
    "    \n",
    "    Input:\n",
    "    \n",
    "    phi_can: the canconical phi which always works for wsc with all zero assignments for g>1 graphs.\n",
    "    \n",
    "    phi_av: the phi average for the current wsc.\n",
    "    \n",
    "    phi_av_breaks: the phi average for the wsc with all zero assignments.\n",
    "    \n",
    "    Return: appropriate phi we think should work.\n",
    "    \"\"\"\n",
    "    \n",
    "    trans=np.array(phi_av_breaks)-np.array(phi_can)\n",
    "    \n",
    "    test_phi=np.array(phi_av)+trans\n",
    "    \n",
    "    test_phi=list(test_phi)\n",
    "    test_phi=[round(i,4) for i in test_phi]\n",
    "    \n",
    "    return test_phi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "title"
    ],
    "toc-hr-collapsed": true
   },
   "source": [
    "# Given $\\phi$ get assignments <a name=\"phi\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given $\\phi \\in V^{d}(\\Gamma)$ we can construct $\\sigma_{\\Gamma}^{\\phi}$ in particular describe the assignments on trees,  by use of"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\left|\\frac{\\left|E\\left(\\Gamma^{\\prime} \\cap \\overline{\\Gamma^{\\prime c}} \\cap \\Gamma_{0}^{c}\\right)\\right|}{2}+\\sum_{v \\in V\\left(\\Gamma^{\\prime}\\right)}\\vec{d}(v)+|E(\\Gamma_0^{c} \\cap \\Gamma^{'})|-\\sum_{v \\in V\\left(\\Gamma^{\\prime}\\right)}\\phi(v)\\right| < \\frac{\\left|E\\left(\\Gamma^{\\prime} \\cap \\overline{\\Gamma^{\\prime c}} \\cap \\Gamma_{0}\\right)\\right|}{2}.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $B=\\frac{\\left|E\\left(\\Gamma^{\\prime} \\cap \\overline{\\Gamma^{\\prime c}} \\cap \\Gamma_{0}^{c}\\right)\\right|}{2}+|E(\\Gamma_0^{c} \\cap \\Gamma^{'})|-\\sum_{v \\in V\\left(\\Gamma^{\\prime}\\right)}\\phi(v)$ and rearranged for $\\sum_{v \\in V\\left(\\Gamma^{\\prime}\\right)}\\vec{d}(v)$ we have,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \n",
    "-\\frac{\\left|E\\left(\\Gamma^{\\prime} \\cap \\overline{\\Gamma^{\\prime c}} \\cap \\Gamma_{0}\\right)\\right|}{2}-B<\\sum_{v \\in V\\left(\\Gamma^{\\prime}\\right)}\\vec{d}(v)< \\frac{\\left|E\\left(\\Gamma^{\\prime} \\cap \\overline{\\Gamma^{\\prime c}} \\cap \\Gamma_{0}\\right)\\right|}{2}-B.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If $\\phi$ is chosen generally this will give a unique assignemtn for each tree, we can then compare these assignments with assignments we know for weak stability conditions to show the weak stability condition comes from a $\\phi$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Given $\\phi$ get bounds for $\\sum_{I} d_I$ where $I$ is given by the set of vertices for complete subgraphs used above.\n",
    "- Change upper and lower\n",
    "- Store as a dictionary of form: dic = {\"1\":[0,1,3], \"2\":[0,-1], \"12\":[0,4]}\n",
    "- Pass dictionary to solver to get unique $\\vec{d}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## D- Example (get_assignment_phi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# graphname=\"G3\"\n",
    "G=Graph([(\"0\",\"1\"),(\"1\",\"2\"),(\"2\",\"0\")], multiedges=True)\n",
    "spanning_trees=[tree for tree in G.spanning_trees()]\n",
    "# plot(G, figsize=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.3333333333333333, 0.3333333333333333, 0.3333333333333333)\n",
      "[0, 0, 0]\n",
      "[0, 0, 0]\n",
      "[0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "#Trivial I3 example\n",
    "\n",
    "assignments=[(spanning_trees[0],[0,0,0]),(spanning_trees[1],[0,0,0]),(spanning_trees[2],[0,0,0])]\n",
    "inter_triv=get_intersection_tree_poly(G,assignments)\n",
    "\n",
    "phi=get_a_phi(inter_triv)\n",
    "print(phi)#(0.3333333333333333, 0.3333333333333333, 0.3333333333333333)\n",
    "#We now do the inverse with phi to reobtain assignments.\n",
    "print(get_assignment_phi(G,spanning_trees[0],phi))#[0, 0, 0]\n",
    "print(get_assignment_phi(G,spanning_trees[1],phi))#[0, 0, 0]\n",
    "print(get_assignment_phi(G,spanning_trees[2],phi))#[0, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.6666666666666666, 0.6666666666666666, -0.3333333333333333)\n",
      "[0, 0, 0]\n",
      "[0, 1, -1]\n",
      "[1, 0, -1]\n"
     ]
    }
   ],
   "source": [
    "#Non-trivial I3 example\n",
    "assignments=[(spanning_trees[0],[0,0,0]),(spanning_trees[1],[0,1,-1]),(spanning_trees[2],[1,0,-1])]\n",
    "inter_nontriv=get_intersection_tree_poly(G,assignments)\n",
    "# print(dim(inter_nontriv))\n",
    "\n",
    "phi=get_a_phi(inter_nontriv)\n",
    "print(phi)#(0.6666666666666666, 0.6666666666666666, -0.3333333333333333)\n",
    "#We now do the inverse with phi to reobtain assignments.\n",
    "ass_l1=get_all_assignment_phi(phi,G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compare against non-trivial.\n",
    "ass_l2=[(spanning_trees[0],[0,0,0]),(spanning_trees[1],[0,1,-1]),(spanning_trees[2],[1,0,-1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_assignment_l(ass_l1,ass_l2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We modify lower-part, upper-part, phi-tree-formatted-hyperplanes (where we where previously looking for $\\phi$) to the context where the target is $\\vec{d}$.(Note we dont need to generate a polytope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "tags": [
     "Function"
    ]
   },
   "outputs": [],
   "source": [
    "def get_lower_threshold(indexor,phi,num_e_in_tree,num_e_notin_tree,gamma0_missing_edges):\n",
    "    \n",
    "    \"\"\"\n",
    "    Objective: get lower constant bounding sum d_i\n",
    "    Input:\n",
    "    Returns: constant\n",
    "    \"\"\"\n",
    "\n",
    "    #get b term\n",
    "    T_term=num_e_in_tree*0.5\n",
    "    T_comp_term=num_e_notin_tree*0.5\n",
    "    phi_comp_sum=sum_comps(phi,indexor)\n",
    "    \n",
    "    B= T_comp_term+gamma0_missing_edges-phi_comp_sum\n",
    "    \n",
    "    lower_term=-T_term - B #See phi_tree_inequality_doc\n",
    "    \n",
    "        \n",
    "    return lower_term\n",
    "\n",
    "def get_upper_threshold(indexor,phi,num_e_in_tree,num_e_notin_tree,gamma0_missing_edges):\n",
    "    \n",
    "    \"\"\"\n",
    "    Objective: Get upper constant\n",
    "    Input:\n",
    "    Returns:constant\n",
    "    \"\"\"\n",
    "\n",
    "    #get b term\n",
    "    T_term=num_e_in_tree*0.5\n",
    "    T_comp_term=num_e_notin_tree*0.5\n",
    "    phi_comp_sum=sum_comps(phi,indexor)\n",
    "    \n",
    "    B= T_comp_term+gamma0_missing_edges-phi_comp_sum\n",
    "    \n",
    "    upper_term=T_term - B #See phi_tree_inequality_doc\n",
    "    \n",
    "        \n",
    "    return upper_term\n",
    "\n",
    "def divisor_bounds(G,phi_G, phi,int_range=10):\n",
    "    \n",
    "    \"\"\"\n",
    "        Obj: Returns bounds on elements of vec{d} and the relations to be passed to solve to find the unique assignment on T.   \n",
    "        Get the ranges for d_i +...+d_j where i ranges over complete subg of cut.\n",
    "\n",
    "        Inputs:\n",
    "        int_range:Simulates the integers increase size if fails.\n",
    "        phi_G =  A dictionary that records indexs of cuts as keys, and value=[num_e_in_tree,num_e_notin_tree]\n",
    "    \n",
    "        Returns: a dictionary of the form dic = {\"1\":[1], \"2\":[0],\"3\":[0],\"12\":[1],\"13\":[1],\"23\":[0]}\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    # Generate a list of integers from 1 to 200\n",
    "    integers = range(-int_range-1, int_range+1)\n",
    "    \n",
    "    S=[] #Stored (key,values)\n",
    "\n",
    "    \n",
    "    #Add the sum to zero requirement: \n",
    "    #length of phi:\n",
    "    n=len(phi)\n",
    "    s = \"\".join([str(i) for i in range(n)])\n",
    "    # # We add the total degree equation to inequals for phi\n",
    "    # deg=0 #will be 0 for trees.\n",
    "    # tot_equ1=[-deg,]+ [1]*n\n",
    "    # tot_equ2=[deg,]+ [-1]*n\n",
    "    S.append((s,0))\n",
    "        \n",
    "    for indexor in list(phi_G.keys()):\n",
    "\n",
    "        num_e_in_tree,num_e_notin_tree,gamma0_missing_edges=phi_G[indexor] #value=[num_e_in_tree,num_e_notin_tree]    \n",
    "\n",
    "        upper_threshold=get_upper_threshold(indexor,phi,num_e_in_tree,num_e_notin_tree,gamma0_missing_edges)\n",
    "\n",
    "        lower_threshold=get_lower_threshold(indexor,phi,num_e_in_tree,num_e_notin_tree,gamma0_missing_edges)\n",
    "\n",
    "        # Use a list comprehension to filter out integers above the threshold\n",
    "        integers_between_threshold = [x for x in integers if upper_threshold>x > lower_threshold]\n",
    "\n",
    "        \n",
    "        S.append((indexor,integers_between_threshold))\n",
    "\n",
    "\n",
    "     #Turn S into dictionary.  \n",
    "    dic=dict(S)\n",
    "        \n",
    "    return dic\n",
    "\n",
    "def solver(dic):\n",
    "    \"\"\"\n",
    "    Objective: get \\vec{d} ass on trees from range of values of d_i and relations.\n",
    "    Input:dictionary for all values of vec{d} with relations which will determine d_i for singlton i.\n",
    "    Returns: vec{d} main\n",
    "    \"\"\"\n",
    "    \n",
    "    # Extract the values of d1 to d6 from the input dictionary\n",
    "    d_values = [dic[key] for key in sorted(dic.keys()) if len(key) == 1]\n",
    "\n",
    "    # Extract the sets of sums from the input dictionary\n",
    "    sum_sets = {}\n",
    "    for key in dic.keys():\n",
    "        if len(key) >1:\n",
    "            value = dic[key]\n",
    "            if isinstance(value, (list, tuple)):\n",
    "                sum_sets[key] = set(value)\n",
    "            else:\n",
    "                sum_sets[key] = set([value])\n",
    "#     print(\"sum_sets\",sum_sets)\n",
    "\n",
    "    # Initialize a list to store the values of d1 to d6 that satisfy the conditions\n",
    "    solutions = []\n",
    "\n",
    "    # Iterate through all possible combinations of d1 to d6\n",
    "    for d in itertools.product(*d_values):\n",
    "        \n",
    "#         print(d)\n",
    "        \n",
    "        # Check if all sums are in their respective sets\n",
    "        valid = True\n",
    "        for key, s in sum_sets.items():\n",
    "            indices = [int(i) for i in key]\n",
    "            if sum([d[i] for i in indices]) not in s:\n",
    "#                 print(\"key\",key,\"s\",s)\n",
    "                \n",
    "                valid = False\n",
    "                break\n",
    "        # If all sums are valid, add the solution\n",
    "        if valid:\n",
    "            solutions.append(d)\n",
    "\n",
    "    # Print the solutions\n",
    "    if len(solutions) == 0:\n",
    "        print(False,\"No solutions found\")\n",
    "        return False,\"No solutions found\"\n",
    "    if len(solutions) >1 :\n",
    "        return False,\"More than one solution found\"\n",
    "    else: #1 solution found\n",
    "        \n",
    "#         for d in solutions:\n",
    "#             print(\" \".join([f\"d{i} = {d[i-1]}\" for i in range(1, len(d_values)+1)]))\n",
    "        [d_tuple]=solutions\n",
    "        return list(d_tuple),\"Exactly one divisor\"\n",
    "\n",
    "def get_assignment_phi(G,T,phi):\n",
    "    \n",
    "    \"\"\"\n",
    "    Objective: by checking inequalities gt unique d_i components for vec{d}.\n",
    "    Input:\n",
    "    Returns: unique assignment divisor\n",
    "    \"\"\"\n",
    "    \n",
    "    #get data for inequalities for divisor_bounds\n",
    "    phi_G=phi_tree_inequalities_data(G,T)\n",
    "    \n",
    "    # bounds for vec{d}\n",
    "    dic=divisor_bounds(G,phi_G, phi,int_range=10)\n",
    "#     print(dic)\n",
    "    \n",
    "    \n",
    "    #Get divisor satisfying equations of dic\n",
    "    divisor=solver(dic)[0]\n",
    "    \n",
    "    return divisor\n",
    "\n",
    "def get_all_assignment_phi(phi,G):\n",
    "\n",
    "    \"\"\"\n",
    "    Objective:\n",
    "    Input:\n",
    "    Returns: list of assignments for all trees i.e [(T,ass) for each T in G]\n",
    "    \"\"\"\n",
    "    spanning_trees=[tree for tree in G.spanning_trees(labels=true)] #incase have GM1 double edge graph\n",
    "\n",
    "    ass_l=[]\n",
    "    for T in spanning_trees:\n",
    "        \n",
    "        #Get unique assignment on tre\n",
    "        ass=get_assignment_phi(G,T,phi)\n",
    "        \n",
    "        #record\n",
    "        ass_l.append((T,ass))\n",
    "    \n",
    "    return ass_l\n",
    "\n",
    "def compare_assignment_l(ass_l1,ass_l2):\n",
    "\n",
    "    \"\"\"\n",
    "    Objective: Given a two lists of assignments asks is are equal by comparing ass for each tree.\n",
    "    Input:\n",
    "    Returns: True or False\n",
    "    \"\"\"\n",
    "    \n",
    "    #Make spanning trees in (T,ass) immutable\n",
    "    ass_l1=[(T.copy(immutable=True),ass) for (T,ass) in ass_l1]\n",
    "    ass_l2=[(T.copy(immutable=True),ass) for (T,ass) in ass_l2]\n",
    "    \n",
    "    #Put ass_l1,ass_l2 into the correct order.\n",
    "\n",
    "    # Create dictionaries to store the values in the lists\n",
    "    dict1 = dict(ass_l1)\n",
    "    dict2 = dict(ass_l2)\n",
    "\n",
    "    # Check if the values for each key in both dictionaries are the same\n",
    "    for key in dict1:\n",
    "        if key in dict2:\n",
    "            if dict1[key] == dict2[key]:\n",
    "                continue\n",
    "            else:\n",
    "                return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": [
     "title"
    ],
    "toc-hr-collapsed": true
   },
   "source": [
    "# Construct Graph-Poly<a name=\"Graph-Poly\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fraction phi = ('1/3', '1/3', '1/3')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('1/3', '1/3', '1/3')"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#I3 trivial case\n",
    "G=Graph([(\"0\",\"1\"),(\"1\",\"2\"),(\"2\",\"0\")], multiedges=True)\n",
    "div_l=[[0,1,0],[1,0,0],[0,0,1]]\n",
    "graph_poly=get_graph_poly(G,div_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Polyhedra_RDF_cdd_with_category.element_class' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-116-7cebb22a376b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdiv_l\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mInteger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mInteger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mInteger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mInteger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mInteger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mInteger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mInteger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mInteger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mInteger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mgraph_poly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_graph_poly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdiv_l\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mphi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_a_phi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph_poly\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-115-51574bd00aea>\u001b[0m in \u001b[0;36mget_graph_poly\u001b[0;34m(G, div_l)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m#         P=\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mpoly_l\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree_poly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdiv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;31m#Take intersection of polytopes for tgraph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'Polyhedra_RDF_cdd_with_category.element_class' object is not callable"
     ]
    }
   ],
   "source": [
    "#I3 non-trivial case\n",
    "G=Graph([(\"0\",\"1\"),(\"1\",\"2\"),(\"2\",\"0\")], multiedges=True)\n",
    "div_l=[[0,1,0],[1,0,0],[1,1,-1]]\n",
    "graph_poly=get_graph_poly(G,div_l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": [
     "Function"
    ]
   },
   "outputs": [],
   "source": [
    "def get_graph_poly(G,div_l): #Done\n",
    "\n",
    "    \"\"\"\n",
    "    Objective: Construct the Graph polytope R_{sigma_gamma}.\n",
    "    Input:\n",
    "    div_l:= list of divisors in sigma_gamma(gamma)\n",
    "    Return: graph_poly\n",
    "    \"\"\"\n",
    "    \n",
    "    T=G #Gamma_0 is G here\n",
    "    \n",
    "    \n",
    "    # phi_tree_formatted_hyperplanes\n",
    "\n",
    "    #Build and record polytopes.\n",
    "    poly_l=[]\n",
    "    for div in div_l:\n",
    "        \n",
    "        P=get_tree_poly(G,T,div)\n",
    "        \n",
    "        poly_l.append(P)\n",
    "\n",
    "    #Take intersection of polytopes for tgraph\n",
    "    graph_poly=poly_l[0]\n",
    "    for P in poly_l[1:]:\n",
    "        graph_poly=graph_poly.intersection(P)\n",
    "\n",
    "    \n",
    "    return graph_poly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": [
     "title"
    ],
    "toc-hr-collapsed": true
   },
   "source": [
    "# Construct Tree-Poly <a name=\"ConstructTree-Poly\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given $\\sigma_\\Gamma \\in \\Sigma_\\Gamma$ we first construct $R_{\\sigma_\\Gamma}^{T}$ by determining the boundary hyperplanes. As we know $\\vec{d} \\in \\sigma_\\Gamma(T)$, we rearrange the following (note $\\Gamma_0:=T$ and we correct for total degree),"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\left|\\frac{\\left|E\\left(\\Gamma^{\\prime} \\cap \\overline{\\Gamma^{\\prime c}} \\cap \\Gamma_{0}^{c}\\right)\\right|}{2}+\\sum_{v \\in V\\left(\\Gamma^{\\prime}\\right)}\\vec{d}(v)+|E(\\Gamma_0^{c} \\cap \\Gamma^{'})|-\\sum_{v \\in V\\left(\\Gamma^{\\prime}\\right)}\\phi(v)\\right| < \\frac{\\left|E\\left(\\Gamma^{\\prime} \\cap \\overline{\\Gamma^{\\prime c}} \\cap \\Gamma_{0}\\right)\\right|}{2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "expanding out the modulus we get,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \n",
    "-\\frac{\\left|E\\left(\\Gamma^{\\prime} \\cap \\overline{\\Gamma^{\\prime c}} \\cap \\Gamma_{0}\\right)\\right|}{2}<\\frac{\\left|E\\left(\\Gamma^{\\prime} \\cap \\overline{\\Gamma^{\\prime c}} \\cap \\Gamma_{0}^{c}\\right)\\right|}{2}+\\sum_{v \\in V\\left(\\Gamma^{\\prime}\\right)}\\vec{d}(v)+|E(\\Gamma_0^{c} \\cap \\Gamma^{'})|-\\sum_{v \\in V\\left(\\Gamma^{\\prime}\\right)}\\phi(v) < \\frac{\\left|E\\left(\\Gamma^{\\prime} \\cap \\overline{\\Gamma^{\\prime c}} \\cap \\Gamma_{0}\\right)\\right|}{2}.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $A=\\frac{\\left|E\\left(\\Gamma^{\\prime} \\cap \\overline{\\Gamma^{\\prime c}} \\cap \\Gamma_{0}^{c}\\right)\\right|}{2}+\\sum_{v \\in V\\left(\\Gamma^{\\prime}\\right)}\\vec{d}(v)+|E(\\Gamma_0^{c} \\cap \\Gamma^{'})|$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \n",
    "\\frac{\\left|E\\left(\\Gamma^{\\prime} \\cap \\overline{\\Gamma^{\\prime c}} \\cap \\Gamma_{0}\\right)\\right|}{2} + A>\\sum_{v \\in V\\left(\\Gamma^{\\prime}\\right)}\\phi(v) >-\\frac{\\left|E\\left(\\Gamma^{\\prime} \\cap \\overline{\\Gamma^{\\prime c}} \\cap \\Gamma_{0}\\right)\\right|}{2} + A$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explicitly, we produce all $\\phi$ tree-inequalities for a tree and all complete subgraphs of $\\Gamma$\n",
    "and record the set of inequalities as a dictionary dictionary. Then we construct a polytope for each tree and take the intersection to give tree-poly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# graphname=\"G3\"\n",
    "G=Graph([(\"0\",\"1\"),(\"1\",\"2\"),(\"2\",\"0\")], multiedges=True)\n",
    "spanning_trees=[tree for tree in G.spanning_trees()]\n",
    "# plot(G, figsize=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take the intersection of all phi-tree-polytopes and make sure the space is of dimension 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "#Non-trivial I3 example\n",
    "assignments=[(spanning_trees[0],[0,0,0]),(spanning_trees[1],[0,1,-1]),(spanning_trees[2],[1,0,-1])]\n",
    "inter_nontriv=get_intersection_tree_poly(G,assignments)\n",
    "print(dim(inter_nontriv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'inter_nontriv' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-1676f6fb2e94>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mphi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_a_phi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minter_nontriv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mget_phi_frac\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'inter_nontriv' is not defined"
     ]
    }
   ],
   "source": [
    "phi=get_a_phi(inter_nontriv)\n",
    "print(phi)\n",
    "get_phi_frac(phi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "#Trivial I3 example\n",
    "\n",
    "assignments=[(spanning_trees[0],[0,0,0]),(spanning_trees[1],[0,0,0]),(spanning_trees[2],[0,0,0])]\n",
    "inter_triv=get_intersection_tree_poly(G,assignments)\n",
    "print(dim(inter_triv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.3333333333333333, 0.3333333333333333, 0.3333333333333333)\n",
      "fraction phi = ('1/3', '1/3', '1/3')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('1/3', '1/3', '1/3')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phi=get_a_phi(inter_triv)\n",
    "print(phi)\n",
    "get_phi_frac(phi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "tags": [
     "Function"
    ]
   },
   "outputs": [],
   "source": [
    "def get_pairs_con_subg(G):# for phi_tree_inequalities_data\n",
    "    \n",
    "    \"\"\"\n",
    "    Note: we are not working with multigraphs so connected_subgraph_iterator should give subgraphs with all edges between\n",
    "    \n",
    "    If Issue may be HERE due to this. \n",
    "    \n",
    "    Objective: Used to get cut info and total degree adjustment\n",
    "    Input:\n",
    "    Return: Pairs of complete subgraphs for V and V^{c} such that V scup V^{c}=V(G)\n",
    "    \"\"\"\n",
    "    \n",
    "    vert_G=G.vertices()\n",
    "    edges_G=G.edges()\n",
    "    \n",
    "    #get list of connected subgraphs:\n",
    "    \n",
    "    #Want to get pairs of complete subgraphs for pairs of vertices that is a is disjoint union of all verts\n",
    "    ll=list(G.connected_subgraph_iterator())\n",
    "\n",
    "    # put them into pairs, where vertices are a disjoint union of G.\n",
    "    pairs=[]\n",
    "    for i in ll:\n",
    "        a=i.vertices()\n",
    "        for j in ll:\n",
    "            b=j.vertices()\n",
    "            if sorted(a+b)==vert_G:\n",
    "                #May need to take complete graph here containing a, and for b. \n",
    "                pairs.append((i,j))\n",
    "                \n",
    "#                 \"\"\"\n",
    "#                 We only need one subgraph in the cut, the following step prevents us having both subg in a cut.\n",
    "#                 \"\"\"\n",
    "#                 if (i,j) in pairs:\n",
    "#                     continue\n",
    "#                 if (j,i) in pairs:\n",
    "#                     continue\n",
    "#                 else:\n",
    "#                     pairs.append((i,j))\n",
    "                    \n",
    "#     for i in get_pairs_con_subg(G):\n",
    "#         print(i[0].vertices(),i[1].vertices())\n",
    "    return pairs\n",
    "\n",
    "def get_cut_edges(G,pair): #for phi_tree_inequalities_data\n",
    "    \n",
    "    \"\"\"\n",
    "    Obj:Get list of the edges in a cut for a given pair, \n",
    "    for a pair of connected subgraphs that partitions the vertices of G.\n",
    "    \n",
    "    Return: list of edges in cut for a pair of connected subgraphs that partition the vertices of G \n",
    "    \"\"\"\n",
    "    a_edges=pair[0].edges()\n",
    "    b_edges=pair[1].edges()\n",
    "    total_edges=a_edges+b_edges\n",
    "    \n",
    "    edges_G=G.edges()\n",
    "\n",
    "    #Cut edges.\n",
    "    cut_edges=[ e for e in edges_G if e not in total_edges]\n",
    "    \n",
    "    return cut_edges\n",
    "\n",
    "def edges_cut_inandnotin_tree(cut_edges,tree):#Used in phi_tree_inequalities_data\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    Obj: Consider cut_edges_G and ask if any of the edges of T are in cut_edges_G\n",
    "\n",
    "    Returns: Number of edges in tree, and not in tree\n",
    "    \"\"\"\n",
    "\n",
    "    tree_edges=tree.edges()\n",
    "\n",
    "    e_in_tree=[edge for edge in cut_edges if edge in tree_edges]\n",
    "    # print(\"edges of cut that belong to tree:\",tree_edges_cut)\n",
    "\n",
    "    e_notin_tree=[edge for edge in cut_edges if edge not in tree_edges]\n",
    "    # print(\"edges of cut that do not belong to tree:\",tree_comp_edges_cut)\n",
    "    \n",
    "    num_e_in_tree ,num_e_notin_tree=len(e_in_tree),len(e_notin_tree)\n",
    "    \n",
    "    return num_e_in_tree ,num_e_notin_tree\n",
    "\n",
    "def get_gamma0_missing_edges(G,T,complete_subg):\n",
    "    \"\"\"\n",
    "    Objective:find adjustment to degree of divisors, a number, to correct to the total degree.\n",
    "    given by the number of edges in complete subgrahp which are not in gamm0\n",
    "    Input: gamma0 (the tree), and the complete_subg\n",
    "    Return: number of edges complete_subg has over T (on one side of the  cut).\n",
    "    \n",
    "    \n",
    "    Want |E(gamma0^c) cap E(gamma')| where gamma' is the complete subgraph and gamma0 the connected spanning subg.\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    gamma0_complement=[e for e in G.edges() if e not in T.edges()]\n",
    "    \n",
    "    gamma0_comp_inter_complete_subg=[e for e in gamma0_complement if e in complete_subg.edges()]\n",
    "    \n",
    "    return len(gamma0_comp_inter_complete_subg)\n",
    "\n",
    "def phi_tree_inequalities_data(G,T): #Main\n",
    "    \n",
    "    \"\"\"\n",
    "    Objective: Used in tree_poly\n",
    "    Inputs: \n",
    "    G: graph\n",
    "    T:graph of spanning tree (or any spanning connected subgraph)\n",
    "    \n",
    "    Return:dictionary of data used to define the phi-tree inequalties. \n",
    "    Returns phi_G\n",
    "\n",
    "    Dict contains the vertices of the cut : key\n",
    "    List of [e_in_tree ,e_notin_tree]: value\n",
    "    \n",
    "    Where num_e_in_tree = edges of cut the belong to tree\n",
    "         ,num_e_notin_tree= edges of cut that do not belong to tree\n",
    "         \n",
    "    terms=[num_e_in_tree ,num_e_notin_tree,gamma0_missing_edges]\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    #for main\n",
    "\n",
    "    pairs=get_pairs_con_subg(G)\n",
    "\n",
    "    inequ_data=[]\n",
    "    for pair in pairs: \n",
    "        \n",
    "        #As only care about one complete subg, we get the number of missing edges of T and complete_subg.\n",
    "        complete_subg=pair[0]\n",
    "        gamma0_missing_edges=get_gamma0_missing_edges(G,T,complete_subg)\n",
    "        \n",
    "        \n",
    "        #Would like to know the edges that G has in the cut. i.e. cut_edges_G\n",
    "        cut_edges=get_cut_edges(G,pair)\n",
    "\n",
    "        num_e_in_tree ,num_e_notin_tree=edges_cut_inandnotin_tree(cut_edges,T)\n",
    "\n",
    "        terms=[num_e_in_tree ,num_e_notin_tree,gamma0_missing_edges]\n",
    "        \n",
    "#         print(\"pair[0].vertices():\",pair[0].vertices(),\"pair[1].vertices():\",pair[1].vertices())\n",
    "#         print(\"[num_e_in_tree ,num_e_notin_tree]\",terms)\n",
    "\n",
    "\n",
    "        \"Do we need to add the data for both subg in pair?\"\n",
    "\n",
    "        #get vertices of subg in pair and turn to \"v1v2v3\" format.\n",
    "        subg1_l=pair[0].vertices()\n",
    "        subg1 = ''.join(subg1_l)\n",
    "        inequ_data.append((subg1,terms)) #subg1 is the indexor in phi_tree_formatted_hyperplanes\n",
    "\n",
    "#         print(\"(subg1,terms):\",(subg1,terms))\n",
    "#         subg2_l=pair[1].vertices()\n",
    "#         subg2 = ''.join(subg2_l)\n",
    "#         inequ_data.append((subg2,terms))\n",
    "\n",
    "\n",
    "    #Now join to phi-inequal data dict\n",
    "    phi_tree_iequal_dict = {t[0]: t[1] for t in inequ_data}\n",
    "\n",
    "    return phi_tree_iequal_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "tags": [
     "Function"
    ]
   },
   "outputs": [],
   "source": [
    "def get_first_betti_number(G):\n",
    "    #for if the degree of divisors on trees is 0, the degree of lbm is this.\n",
    "    return len(G.edges())-len(G.vertices())+1\n",
    "\n",
    "def sum_comps(comp,indexor): #Done\n",
    "    \"\"\"returns the sum of the components of comp in the position by indexor\"\"\"\n",
    "    #for d and phi\n",
    "    sum_l=[comp[int(i)] for i in indexor] #Becuase of the vertex labeling of G having v_0....\n",
    "    return sum(sum_l)\n",
    "\n",
    "def lower_part(indexor,n,divisor,num_e_in_tree,num_e_notin_tree,gamma0_missing_edges):\n",
    "\n",
    "    #get b term\n",
    "    T_term=num_e_in_tree*0.5\n",
    "    T_comp_term=num_e_notin_tree*0.5\n",
    "    divisor_comp_sum=sum_comps(divisor,indexor)\n",
    "    totaldeg_divisor_comp_sum=divisor_comp_sum+gamma0_missing_edges#Corrected to total degree\n",
    "    \n",
    "    bterm=[totaldeg_divisor_comp_sum+T_term+T_comp_term] #See phi_tree_inequality_doc\n",
    "    \n",
    "    base=np.zeros(n)\n",
    "    \n",
    "    \"\"\"\n",
    "    It is very important whether its (1,i) or (-1,i) below in l\n",
    "    \"\"\"\n",
    "    l=[(-1,i) for i in indexor] # put -1 in the ith position given be indexor. \n",
    "\n",
    "    for item in l:\n",
    "        ipos = int(item[1]) # ith position\n",
    "        val=item[0]\n",
    "        base[ipos]=val\n",
    "\n",
    "    xyz=base\n",
    "\n",
    "    ineq=bterm+list(xyz) # [b,x,y,z...] want to concat                \n",
    "    return ineq\n",
    "\n",
    "def upper_part(indexor,n,divisor,num_e_in_tree,num_e_notin_tree,gamma0_missing_edges):\n",
    "\n",
    "    #Remember upper part of modulus inequality.\n",
    "\n",
    "    #get b term\n",
    "    T_term=num_e_in_tree*0.5\n",
    "    T_comp_term=num_e_notin_tree*0.5\n",
    "    divisor_comp_sum=sum_comps(divisor,indexor)\n",
    "    totaldeg_divisor_comp_sum=divisor_comp_sum+gamma0_missing_edges#Corrected to total degree\n",
    "\n",
    "    bterm=[-totaldeg_divisor_comp_sum+T_term-T_comp_term] #See phi_tree_inequality_doc\n",
    "\n",
    "    #get x,y,z term\n",
    "    base=np.zeros(n)\n",
    "    l=[(1,i) for i in indexor] # put -1 in the ith position given be indexor.\n",
    "\n",
    "    for item in l:\n",
    "        ipos = int(item[1]) # ith position\n",
    "        val=item[0]\n",
    "        base[ipos]=val\n",
    "\n",
    "    xyz=base\n",
    "\n",
    "    ineq=bterm+list(xyz) # [b,x,y,z...] want to concat\n",
    "\n",
    "    return ineq\n",
    "\n",
    "def phi_tree_formatted_hyperplanes(divisor,phi_G,G):\n",
    "    \n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "    phi_G =  A dictionary that records indexs of cuts as keys, and value=[num_e_in_tree,num_e_notin_tree]\n",
    "    \n",
    "    divisor= divisor in stability condition for tree ie. sigma_{G}(T)\n",
    "    \n",
    "    Purpose: Get list of inquality data to feed into Sages Polyhedron function\n",
    "    https://doc.sagemath.org/html/en/reference/discrete_geometry/sage/geometry/polyhedron/constructor.html\n",
    "    \n",
    "    Polyhedron(ieqs=[(0,1,0),(0,0,1),(1,-1,-1)]).Hrepresentation()\n",
    "    (An inequality (-1, -1) x + 1 >= 0,\n",
    "     An inequality (1, 0) x + 0 >= 0,\n",
    "     An inequality (0, 1) x + 0 >= 0)\n",
    "     \n",
    "    to add the total degree inequality x+y+z..=degree.\n",
    "    \n",
    "    Ax=b\n",
    "    \n",
    "    Further Notes:\n",
    "    Following phi_tree_inqualities_doc. Not the same as phi inequal dicts for lbm.\n",
    "    \n",
    "    Here divisor is a single divisor. Not for all divisors in a set.\n",
    "    \"\"\"\n",
    "    \n",
    "    #length of divisor:\n",
    "    n=len(divisor)\n",
    "    \n",
    "    # We add the total degree equation to inequals for phi\n",
    "    deg=get_first_betti_number(G) #will be 0 for trees.\n",
    "    tot_equ1=[-deg,]+ [1]*n\n",
    "    tot_equ2=[deg,]+ [-1]*n\n",
    "    \n",
    "    #List of inequalities we wish to return\n",
    "    inequals=[tot_equ1,tot_equ2]     \n",
    "        \n",
    "    for indexor in list(phi_G.keys()):\n",
    "\n",
    "        num_e_in_tree,num_e_notin_tree,gamma0_missing_edges=phi_G[indexor] #value=[num_e_in_tree,num_e_notin_tree]    \n",
    "\n",
    "        res_upper=upper_part(indexor,n,divisor,num_e_in_tree,num_e_notin_tree,gamma0_missing_edges)\n",
    "\n",
    "        res_lower=lower_part(indexor,n,divisor,num_e_in_tree,num_e_notin_tree,gamma0_missing_edges)\n",
    "\n",
    "        res_combined= [res_lower,res_upper]\n",
    "\n",
    "        inequals=inequals+res_combined\n",
    "    return inequals\n",
    "\n",
    "#Main \n",
    "def get_tree_poly(G,T,divisor):#Main\n",
    "    \n",
    "    \"\"\"\n",
    "    Obj:# Get the polytope for a tree using the phi-tree-inequalties.\n",
    "    \n",
    "    Returns: Polytope or strip\n",
    "    \"\"\"\n",
    "\n",
    "    # get list of phi_tree_inequalities_data(G,T) for each trees.(dictionary)\n",
    "    phi_G=phi_tree_inequalities_data(G,T)\n",
    "    \n",
    "#     print(\"Total phi_G data:\", phi_G)\n",
    "\n",
    "    #Get hyperplanes\n",
    "    \n",
    "#     if flag==True:\n",
    "#         hyperp=phi_tree_formatted_hyperplanes(divisor,alt_phi_G,G)\n",
    "#     else:#Where we have no\n",
    "\n",
    "    hyperp=phi_tree_formatted_hyperplanes(divisor,phi_G,G)\n",
    "        \n",
    "#     print(\"Using nicola's example:\")\n",
    "#     for i in hyperp:\n",
    "#         print(i)\n",
    "    \n",
    "#     #projecting onto xy by removing last term.\n",
    "#     hyperp=[arr[:-1] for arr in hyperp]\n",
    "    \n",
    "   \n",
    "\n",
    "    #build a polytope.\n",
    "    tree_poly=Polyhedron(ieqs=hyperp)\n",
    "\n",
    "    return tree_poly\n",
    "\n",
    "def get_intersection_tree_poly(G,assignments):\n",
    "\n",
    "    \"\"\"\n",
    "    Objective:\n",
    "    Input: assignments:= a list of pairs (Tree,divisor on said tree).\n",
    "    Returns: $bigcap_{T in mathcal{ST}(Gamma)} R_{sigma_{Gamma}}^{T}$\n",
    "    \"\"\"\n",
    "    \n",
    "    #Build and record polytopes.\n",
    "    poly_l=[]\n",
    "    for ass in assignments:\n",
    "    \n",
    "        T,divisor=ass[0],ass[1]\n",
    "    \n",
    "        P=get_tree_poly(G,T,divisor)\n",
    "        \n",
    "        poly_l.append(P)\n",
    "\n",
    "    #Take intersection of polytopes for trees\n",
    "    inter=poly_l[0]\n",
    "    for P in poly_l[1:]:\n",
    "        inter=inter.intersection(P)\n",
    "\n",
    "    return inter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": [
     "title"
    ],
    "toc-hr-collapsed": true
   },
   "source": [
    "# Check Tree-Poly and Graph-Poly are equal <a name=\"analyse\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Example: I3 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# graphname=\"G3\"\n",
    "G=Graph([(\"0\",\"1\"),(\"1\",\"2\"),(\"2\",\"0\")], multiedges=True)\n",
    "spanning_trees=[tree for tree in G.spanning_trees()]\n",
    "\n",
    "#Trivial I3 example\n",
    "\n",
    "#Tree_poly\n",
    "assignments=[(spanning_trees[0],[0,0,0]),(spanning_trees[1],[0,0,0]),(spanning_trees[2],[0,0,0])]\n",
    "tree_poly=get_intersection_tree_poly(G,assignments)\n",
    "\n",
    "#Graph_poly\n",
    "div_l=[[0,1,0],[1,0,0],[0,0,1]]\n",
    "graph_poly=get_graph_poly(G,div_l)\n",
    "\n",
    "#Are they equal?\n",
    "print(tree_poly==graph_poly)\n",
    "print(check_graph_equals_tree_poly(G,assignments,div_l))\n",
    "\n",
    "#Non-trivia;\n",
    "\n",
    "#Tree_poly\n",
    "\n",
    "assignments=[(spanning_trees[0],[0,0,0]),(spanning_trees[1],[0,1,-1]),(spanning_trees[2],[1,0,-1])]\n",
    "tree_poly=get_intersection_tree_poly(G,assignments)\n",
    "\n",
    "#Graph_poly\n",
    "div_l=[[0,1,0],[1,0,0],[1,1,-1]]\n",
    "graph_poly=get_graph_poly(G,div_l)\n",
    "\n",
    "#Are they equal?\n",
    "print(tree_poly==graph_poly)\n",
    "print(check_graph_equals_tree_poly(G,assignments,div_l))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": [
     "Function",
     "todo"
    ]
   },
   "outputs": [],
   "source": [
    "def check_graph_equals_tree_poly(G,assignments,div_l):\n",
    "    \n",
    "    \"\"\"\n",
    "    Objective:Asks if the generated phi-polytope given by the intersectino of tree-phi-polys is equal to the graph-polytope.\n",
    "    \n",
    "    Input:\n",
    "    G:= graph\n",
    "    \n",
    "    #For tree_poly:\n",
    "    assignments:= [(spanning_trees[0],[0,0,0]),(spanning_trees[1],[0,1,-1]),(spanning_trees[2],[1,0,-1])]\n",
    "    \n",
    "    #For Graph_poly:\n",
    "    div_l=list of lists= divisors for sigma_{gamma}(gamma).\n",
    "    \n",
    "    Returns:True or false \n",
    "    \"\"\"\n",
    "    \n",
    "    #Tree_poly\n",
    "    tree_poly=get_intersection_tree_poly(G,assignments)\n",
    "\n",
    "    #Graph_poly\n",
    "    graph_poly=get_graph_poly(G,div_l)\n",
    "\n",
    "    #Are they equal?\n",
    "    if tree_poly==graph_poly:\n",
    "        return graph_poly,tree_poly,True\n",
    "    else:\n",
    "        return graph_poly,tree_poly,False\n",
    "\n",
    "    # x=tree_poly &graph_poly #Do not contain.\n",
    "    # print(\"Do they contain each other?\",dim(x))\n",
    "    \n",
    "    # return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check_graph_equals_tree_poly:{'get_intersection_tree_poly', 'get_graph_poly'} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# x=[check_graph_equals_tree_poly]\n",
    "# find_functions_used_l(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Used throughout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import itertools\n",
    "import pickle\n",
    "from fractions import Fraction\n",
    "from collections import Counter\n",
    "import textwrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpickle(graphname):\n",
    "    # Unpickle the list\n",
    "    filename=f\"examples/{graphname}/{graphname}.pkl\"\n",
    "    with open(filename, 'rb') as f:\n",
    "        unpickled_list = pickle.load(f)\n",
    "    return unpickled_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pickle_dic_l(graphname,dic_l):\n",
    "    # Pickle the list\n",
    "    filename=f\"examples/{graphname}/phi_analysis/dic_l.pkl\"\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(dic_l, f)\n",
    "    return\n",
    "\n",
    "# def unpickle_dic_l(graphname):\n",
    "#     # Unpickle the list\n",
    "#     filename=f\"examples/{graphname}/phi_analysis/dic_l.pkl\"\n",
    "#     with open(filename, 'rb') as f:\n",
    "#         unpickled_list = pickle.load(f)\n",
    "#     return unpickled_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import inspect\n",
    "\n",
    "def find_functions_used(func):\n",
    "    \n",
    "    \"\"\"Add print Objective.\"\"\"\n",
    "    \n",
    "    functions_used = set()\n",
    "    tree = ast.parse(inspect.getsource(func))\n",
    "    for node in ast.walk(tree):\n",
    "        if isinstance(node, ast.Call) and isinstance(node.func, ast.Name):\n",
    "            functions_used.add(node.func.id)\n",
    "    return functions_used\n",
    "\n",
    "def find_functions_used_l(l):\n",
    "    for func in l:\n",
    "        functions_used = find_functions_used(func)\n",
    "        print(f\"{func.__name__}:{functions_used} \\n\")\n",
    "\n",
    "# l = [f1, f2, f3]\n",
    "# find_functions_used_l(l)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Leftovers "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SageMath 9.2",
   "language": "sage",
   "name": "sagemath"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
