{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e5fc415-1f30-409e-b802-f051fb4f9ed8",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "# Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174c4f90-96d6-4c38-aacb-b3cf8b774d3b",
   "metadata": {},
   "source": [
    "We consider Chapter $5$ of the thesis. In particular we implement the Algorithm of Section $5.1$ and generate $\\tilde{P}_{n}$ for $3 \\le n\\le 6$  from $\\tilde{P}_{n-1}$. We then give a decomposition of $p_n:=|\\tilde{P}_n|$ in terms of $|\\tilde{P}_{n-1}|$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd53259-e079-407a-a7cf-b5a0b8887c7d",
   "metadata": {},
   "source": [
    "Recall that,\n",
    "\n",
    "$$\\tilde{P}_n=\\bigsqcup_{g \\in P_{n-1}} \\rho^{-1}(g)= \\bigsqcup_{g \\in \\tilde{P}_{n-1}}\\{g+\\epsilon_{I} | I \\in \\mathbb{E}(g)\\}.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140edc3c-2562-498d-9dec-14a5378e59ce",
   "metadata": {},
   "source": [
    "The **procedure** to recursively obtain $\\tilde{P}_{n}$ from $\\tilde{P}_{n-1}$ is as follows:\n",
    " \n",
    " 1) for each  $g \\in \\tilde{P}_{n-1}$ obtain the set $\\mathbb{E}(g)$ (using a implemenation of the Algorithm of Section $5.1$),\n",
    "     \n",
    " 2) for each set $\\mathbb{E}(g)$ obtain the set $\\{g+\\epsilon_{I} | I \\in \\mathbb{E}(g)\\}$,\n",
    " \n",
    " 3) take the union as above to obtain $\\tilde{P}_{n}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b26078-b8f6-4ba6-b3e4-670308b444d4",
   "metadata": {},
   "source": [
    "To obtain a decomposition of $|\\tilde{P}_{n}|$, for each $g \\in \\tilde{P}_{n-1}$ we record $|\\mathbb{E}(g)|$, which allows one to obtain the sequences $\\boldsymbol{e}_{n}$ and $\\boldsymbol{d}_{n}$. The sequences then give $p_{n+1}=\\boldsymbol{e}_{n}\\cdot \\boldsymbol{d}_{n}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df2673cf-764a-4a22-9fe6-faf1f80f85ce",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce6e7fa-eaa4-4303-b669-8aeccfb123b6",
   "metadata": {},
   "source": [
    "1) We obtain the sequence of $p_n$ for $1 \\le n\\le 6$.\n",
    "\n",
    "  $$1,2,10,154,10334,5399325.$$\n",
    "\n",
    "We also have that,\n",
    "\n",
    "$$p_6=5399325=114*125+121*65+126*237+138*112+158*248+162*247+165*132+169*117+173*132+178*122+182*106+183*132+187*24+192*134+194*123+208*144+209*22+216*234+217*126+218*61+221*125+227*22+229*307+230*250+232*120+233*119+236*122+241*30+242*102+247*61+248*53+250*114+251*59+260*184+268*106+269*64+271*186+273*118+274*56+278*52+279*41+281*136+284*112+289*67+293*133+294*37+300*133+305*67+313*123+324*123+325*132+326*101+329*181+338*120+343*59+345*113+356*19+381*121+390*44+397*107+419*20+420*46+421*23+422*39+429*64+433*35+436*128+437*23+455*64+477*53+496*48+502*16+509*38+518*12+520*107+524*20+531*36+538*76+539*62+553*36+555*66+566*144+578*61+605*62+607*66+613*11+640*28+659*30+759*48+765*21+781*108+802*119+814*42+881*42+938*8+974*135+977*45+983*135+1002*45+1026*126+1029*63+1033*63+1068*96+1121*108+1145*22+1178*39+1189*39+1209*44+1212*11+1224*66+1257*44+1312*11+1322*32+1377*36+1409*16+1421*10+1450*54+1511*20+1666*21+1753*24+2110*42+2193*95+2285*4+2290*54+3544*12+3673*42+3820*48+3983*18+6280*1+6474*6+6702*14+6960*16+7250*9+7580*4$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a683c86d-6b1a-49a6-b8f7-e5098ad5a61d",
   "metadata": {},
   "source": [
    "where the decomposition of the remaining $p_{n}$ are stated in Section $5.1$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf4e57b-30fa-4e17-9368-3bc7f96cf041",
   "metadata": {},
   "source": [
    "2) We provide a method to obtain $\\mathbb{E}(g)$ for any $g \\in \\tilde{P}_{n}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208eebce-828d-487b-a8d3-f84c17d451a9",
   "metadata": {},
   "source": [
    "3) We provide evidence for the Conjecture defined in Section 5.2 by showing that such functions attain $U_n$ for low $n$. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f4123a7-eea1-4f31-910f-bafe80d32be3",
   "metadata": {},
   "source": [
    "## Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76033a7f-9ea9-456f-96f8-2aec61e2744e",
   "metadata": {},
   "source": [
    "In section \"$\\tilde{P}_{6}$ and $|\\tilde{P}_{6}|$ decomposition\" we break the computation into parts due to its computational time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f2948b-3504-4032-969f-683165f4db97",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "# Table of contents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8af8e17-04fe-45d8-b777-f03c0d270a18",
   "metadata": {},
   "source": [
    "1. [Functions](#s1)\n",
    "    1. [Main Functions](#s11)\n",
    "    2. [Secondary Functions](#s12)\n",
    "2. [Example](#s2)\n",
    "2. [$\\tilde{P}_{n}$ and $|\\tilde{P}_{n}|$ decomposition](#s3)\n",
    "    1. [$\\tilde{P}_{3}$ and $|\\tilde{P}_{3}|$ decomposition](#s31)\n",
    "    2. [$\\tilde{P}_{4}$ and $|\\tilde{P}_{4}|$ decomposition](#s32)\n",
    "    3. [$\\tilde{P}_{5}$ and $|\\tilde{P}_{5}|$ decomposition](#s33)\n",
    "    4. [$\\tilde{P}_{6}$ and $|\\tilde{P}_{6}|$ decomposition](#s34)\n",
    "3. [Upper bound for $|\\tilde{P}_{n}|$ ](#s4)\n",
    "    1. [$U_n$](#s41)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41aea88b-d6ca-43e0-8e60-06838d30ac22",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Functions <a name=\"s1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f21e69-c510-4276-8a6a-33e4575aa42a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Used throughout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed66ac4c-d294-4fe1-b82f-f780dc1cb1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "# import ast\n",
    "# import inspect"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810e3cf9-8716-4fa0-bc63-90fe3a373715",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "## Main Functions <a name=\"s11\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42629652-2c50-4b7e-8e29-c76cdb7d4f3c",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "### Constructing $\\tilde{P}_{n}$ from $\\tilde{P}_{n-1}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad5a07b-0c7e-4082-a33c-d06779b1c258",
   "metadata": {},
   "source": [
    "The function get\\_Pnp1 determines $\\tilde{P}_{n}$ following the **procedure**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61fe8504-7cbc-4214-b55c-f80ecf31e9e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This function returns Pn+1\n",
    "def get_Pnp1(Pn,n):\n",
    "    \"\"\"\n",
    "    Objective:\n",
    "    Input:\n",
    "    Returns:\n",
    "    \"\"\"\n",
    "\n",
    "    #inputs\n",
    "    # Pn and n.\n",
    "\n",
    "    #New data created\n",
    "    np1=n+1\n",
    "    power_set_str,power_set_str_np1=get_n_np1_powersets(n)\n",
    "\n",
    "    #Load Pn as a list of dictionaries.\n",
    "    list_df_Pn=Pn.to_dict(orient='records')\n",
    "\n",
    "    #Create Pn+1 and hold as dataframe.\n",
    "    P_n1=Build_Pn_1(list_df_Pn,power_set_str,n)\n",
    "    Pnp1=extend_sets_to_Pnp1(P_n1)\n",
    "\n",
    "    Pnp1 = Pnp1.reindex(columns=power_set_str_np1)\n",
    "\n",
    "    inspect_Pn1(Pnp1)\n",
    "\n",
    "    return Pnp1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "723a8d87-b0e5-40f7-a173-25d5c6b67d9d",
   "metadata": {},
   "source": [
    "The main subfunctions of which is the Build\\_Pn\\_1, and extend\\_sets\\_to\\_Pnp1 puts the data obtained from Build\\_Pn\\_1 into a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df4d0e84-d129-4cae-aea5-e7f81a2b05d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def Build_Pn_1(list_df_Pn,power_set_str,n):\n",
    "    \"\"\"\n",
    "    Objective:\n",
    "    Input:\n",
    "    Returns:\n",
    "    \"\"\"\n",
    "    # Returns:packets of extensions for each f_dict from Pn, can check those with max size of closed sets (later)\n",
    "    \n",
    "    # global power_set_str\n",
    "    \n",
    "    P_n1=[]\n",
    "    for f_dict in list_df_Pn:\n",
    "\n",
    "        # Store primitive closed sets \n",
    "\n",
    "        PC=[(x,get_barj({x},f_dict)) for x in power_set_str]\n",
    "        dict_PC=dict(PC)\n",
    "        set_PC=[sorted_frozenset(get_barj({x},f_dict)) for x in power_set_str]\n",
    "\n",
    "        #Get all closed sets for extensions for f_dict\n",
    "        Eg=list(get_Eg(dict_PC,power_set_str,set_PC))\n",
    "        Eg.append(\"empty\")\n",
    "\n",
    "        #Build extensions for f_dict\n",
    "        extension_of_f_dict=[]\n",
    "        for term in Eg:\n",
    "            if term ==\"empty\":\n",
    "                extension_of_f_dict.append(empty_case_get_extension_of_f(f_dict,term,power_set_str,n))\n",
    "            else:\n",
    "                extension_of_f_dict.append(get_extension_of_f(f_dict,term,power_set_str,n))\n",
    "\n",
    "        #We record packets of extensions where we take +1\n",
    "        P_n1.append(extension_of_f_dict)\n",
    "    \n",
    "    return P_n1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "94d04f4a-271e-4975-a610-d737d1b232a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extend_sets_to_Pnp1(P_n1):\n",
    "    \"\"\"\n",
    "    Objective:\n",
    "    Input:\n",
    "    Returns:\n",
    "    \"\"\"\n",
    "    #Return the data frame of Pn+1\n",
    "    \n",
    "    final_P_n1=[]\n",
    "    for ls in P_n1:\n",
    "        final_P_n1=final_P_n1+ls # Adding all the extension packets together.\n",
    "    df=pd.DataFrame(final_P_n1)\n",
    "    # df = df.reindex(columns=power_set_str_np1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde4f87b-aa8a-4193-8219-05acb48ec10d",
   "metadata": {},
   "source": [
    "The function Build\\_Pn\\_1 for each $g \\in \\tilde{P}_{n-1}$ obtains the set of $f=g+\\epsilon_{I}$ for $I \\in \\mathbb{E}(g)$ and then take the union of such sets. The is achieved by get\\_extension\\_of\\_f (and empty\\_case\\_get\\_extension\\_of\\_f for $I=\\emptyset \\in \\mathbb{E}(g)$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f1802047-e709-4048-a244-ee25e2201ca5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_extension_of_f(f_dict,extender,power_set_str,n):\n",
    "    \"\"\"\n",
    "    Objective:\n",
    "    Input:\n",
    "    Returns:\n",
    "    \"\"\"\n",
    "    # Need to attatch n+1 to strings to build extension of function by epsilon.\n",
    "\n",
    "    # Build the extension of f by epsilon.\n",
    "    \n",
    "    # Add the (key,values) of f_dict\n",
    "    builder_ext_0=[(k, f_dict[k]) for k in f_dict]\n",
    "\n",
    "    #We add 1 to the function value of f_dict for x in extender\n",
    "    builder_ext_p1=[(add_n_p_1_to_string(x,n),f_dict[x]+1) for x in list(extender)]\n",
    "\n",
    "    #We add 0 to the function value of f_dict for x NOT in extender\n",
    "    compl_extender=set(power_set_str) - set(extender)\n",
    "    builder_ext_p2=[(add_n_p_1_to_string(x,n),f_dict[x]+0) for x in list(compl_extender)]\n",
    "    \n",
    "    # We include f({n+1})=0\n",
    "    builder_ext_np1=[(add_n_p_1_to_string(\"\",n),int(0)),]\n",
    "\n",
    "\n",
    "    #Compile together.\n",
    "    extension_f_dict={**dict(builder_ext_0),**dict(builder_ext_p1),**dict(builder_ext_p2),**dict(builder_ext_np1)}\n",
    "    \n",
    "    #Example\n",
    "    # get_extension_of_f(frozenset({'13', '23'}))\n",
    "\n",
    "    return extension_f_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b7c29017-cebe-4aea-a579-43f4c06ce537",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def empty_case_get_extension_of_f(f_dict,extender,power_set_str,n):\n",
    "    \"\"\"\n",
    "    Objective:\n",
    "    Input:\n",
    "    Returns:\n",
    "    \"\"\"\n",
    "    # Need to attatch n+1 to strings to build extension of function by epsilon.\n",
    "\n",
    "    # Build the extension of f by epsilon.\n",
    "    \n",
    "    # Add the (key,values) of f_dict\n",
    "    builder_ext_0=[(k, f_dict[k]) for k in f_dict]\n",
    "\n",
    "    builder_ext_p2=[(add_n_p_1_to_string(x,n),f_dict[x]+0) for x in list(power_set_str)]\n",
    "\n",
    "    builder_ext_np1=[(add_n_p_1_to_string(\"\",n),int(0)),]\n",
    "\n",
    "    \n",
    "    #Compile together.\n",
    "    extension_f_dict={**dict(builder_ext_0),**dict(builder_ext_p2),**dict(builder_ext_np1)}\n",
    "    \n",
    "    return extension_f_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a14ce5-9993-4f2d-9af7-f336c71eb595",
   "metadata": {},
   "source": [
    "To obtain $\\mathbb{E}(g)$ we use the function get\\_Eg. Which is the implmentation of th Algorithm of section $5.1$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb2605b5-4e85-462c-944c-d2b3b6886243",
   "metadata": {
    "tags": []
   },
   "source": [
    "Algorithm: Obtain $\\mathbb{E}(g)$\n",
    "**Input:** $g \\in \\tilde{P}_{n}$\n",
    "**Output:** $\\mathbb{E}(g)$\n",
    "1. **Initialization:** Set $\\mathbb{E}(g) = \\{\\emptyset\\}$\n",
    "2. Define a recursive function: Recursion($\\overline{I}, y$)\n",
    "    1. Let $\\overline{J} := \\overline{I} \\cup \\overline{\\{y\\}}$\n",
    "    2. Add $\\overline{J}$ to $\\mathbb{E}(g)$\n",
    "    3. For each $w \\in \\mathcal{P}_{n}^{+} \\setminus \\overline{J}$, do the following:\n",
    "        1. Call Recursion($\\overline{J}, w$)\n",
    "3. **End Function**\n",
    "4. For each $x \\in \\mathcal{P}_{n}^{+}$, do the following:\n",
    "    1. Let $I := \\{x\\}$\n",
    "    2. Add $\\overline{I}$ to $\\mathbb{E}(g)$\n",
    "    3. For each $y \\in \\mathcal{P}_{n}^{+} \\setminus \\overline{I}$, do the following:\n",
    "        1. Call Recursion($\\overline{I}, y$)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c69d8c-d538-4779-ae10-6c5940d4589b",
   "metadata": {},
   "source": [
    "To enhance efficiency and reduce computation time of step 4.C. (so that we do not need to iterate through the powerset completely each time) we've introduced:\n",
    "\n",
    "- **Memory:** We utilize the \"Memory\" variable as a memoization technique to store previous results, thus preventing redundant calculations.\n",
    "\n",
    "These stored results are referred to as \"indicators.\" Here's how it works:\n",
    "\n",
    "- Before initiating a new recursion with a specific set of indicators (which track the current state), we check if these indicators are already present in Memory. If they are, we skip the associated calculations, saving processing time.\n",
    "- If a set of indicators is not found in Memory, it signifies that our algorithm hasn't encountered this specific combination previously. Consequently, we proceed with the recursion and store this set of indicators in \"Memory.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9afc331b-1936-40ec-af67-c09cfe031ddd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_Eg(dict_PC,power_set_str,set_PC):\n",
    "    \"\"\"\n",
    "    Objective: Compute the set of all closed sets, Eg, using a given dictionary of primitive closed sets (dict_PC),\n",
    "               the power set of elements (power_set_str), and a set of primitive closed sets (set_PC).\n",
    "               \n",
    "               We do this by building up Eg using Recur()\n",
    "               \n",
    "               We deal with the empty set separatley.\n",
    "\n",
    "    Input:\n",
    "    - dict_PC (dict): A dictionary where keys are elements of the power set (as strings) \n",
    "    and values are primitive closed sets.\n",
    "    - power_set_str (list or set): The power set of elements represented as a list or set.\n",
    "    - set_PC (set): A set of primitive closed sets.\n",
    "\n",
    "    Returns:\n",
    "    - Eg (set): The set of all closed sets.\n",
    "    \"\"\"\n",
    "    \n",
    "    #We start with what we know which are the primitve closed sets.\n",
    "    Eg={frozenset(power_set_str)}.union(set_PC) \n",
    "    \n",
    "\n",
    "    Memory={sorted_frozenset((\"0\"))}    # contains indicators which are tuples of x \\in powerset for primitives sets.\n",
    "    \n",
    "    for x in power_set_str: #(Step 1 of Algorthim)\n",
    "        # print(f\"Term in powerset: {x}\")\n",
    "        Ibar=dict_PC[x] #primitive closed set #(Step 2 of Algorthim)\n",
    "        power_complment=set(power_set_str)-Ibar # \\mathcal{P}_{n}^{+} \\setminus \\overline{I}\n",
    "        for y in power_complment: #exhaustively getting all closed sets. #(Step 4 of Algorthim)\n",
    "            \n",
    "            # print(\"Eg size:\",len(Eg))\n",
    "            #We introduce indicators which records that we are taking y in the complement of the closure of x\n",
    "            indicators=(x,y)\n",
    "            set_indicators=set([sorted_frozenset(tuple(indicators)),])\n",
    "            \n",
    "            Memory=Memory.union(set_indicators)            \n",
    "            Eg,Memory=Recur(Ibar,indicators,Eg,Memory,dict_PC)\n",
    "            \n",
    "    return Eg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ea9ad0-de1a-4fe1-8053-2e586ebc7060",
   "metadata": {
    "tags": []
   },
   "source": [
    "The following function is the recusive part of above algorithm, in particular from step 4.C onwards. We do this separate the recursive part from the outer for loop for simplicity, as primitive closed sets are easy to obtain (seen later) and so are $\\mathcal{P}_{n}^{+}$ and $\\emptyset$ (which are always in $\\mathbb{E}(g)$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "45743dd0-2e96-482e-a730-d5dd0f92b5ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def Recur(Ibar,indicators,Eg,Memory,dict_PC):\n",
    "    \"\"\"\n",
    "    Objective: Recursively generate Eg while preventing repeated calculations using Memory.\n",
    "\n",
    "    Input:\n",
    "    - Ibar (set): The set closure of I for some I \\subseteq \\mathcal{P}{n}^{+}\n",
    "    \n",
    "    - indicators (tuple): A tuple of elements of \\mathcal{P}{n}^{+} indicators \n",
    "    indicators store recursive paths we have taking that is \n",
    "    e.g when we take y in the complement of the closure of x. \n",
    "    So for the algorithim stated above example indicators would be (x,y) (x,y,w)\n",
    "    We write indicators in a standard ordered form to help memoization process\n",
    "\n",
    "    - Memory (set): A set used for memoization to prevent repeated calculations storing tuples of indicators\n",
    "\n",
    "    - Eg (set): Begins as the set of primitive closed sets and ends at the full set Eg\n",
    "    \n",
    "    - dict_PC (dict): A dictionary recording the element of p_n^{+} and the primitive closed sets.\n",
    "\n",
    "    Returns:\n",
    "    - Eg (set): The updated set of generated primitive closed sets.\n",
    "    - Memory (set): The updated set of indicators used for memoization.\n",
    "    \"\"\"\n",
    "    # global dict_PC\n",
    "        \n",
    "    # To save recalulating we uses this series of checks, if fails checks end recursion turn.\n",
    "    \n",
    "    if indicators in Memory:# Memortisation for preventing repeated calculations.\n",
    "        # print(\"Fails Memory check\")\n",
    "        # print(f\"\\n At this failure we have \\n Eg: {len(Eg)} \\n Memory: {len(Memory)} \\n\")\n",
    "        return Eg,Memory\n",
    "    \n",
    "    #Steps 2A and 2B of algo\n",
    "    \n",
    "    y=indicators[-1]\n",
    "    # print(f\"term taken for primitive closed set we are unioning {y}\")\n",
    "    P_y=dict_PC[y] # the primitive closed set wrt y\n",
    "    Jbar= Ibar.union(P_y)\n",
    "    \n",
    "    # End if alread have Jbar\n",
    "    \n",
    "    if len(Jbar)==len(power_set_str): # We always have the power set in Eg\n",
    "        # print(f\"Fails as {Jbar} == poweset\")\n",
    "        # print(f\"\\n At this failure we have \\n Eg: {len(Eg)} \\n Memory: {len(Memory)} \\n\")\n",
    "        return Eg,Memory\n",
    "              \n",
    "    if Jbar in Eg:\n",
    "        # print(f\"Fails as {Jbar} in Eg\")\n",
    "        # print(f\"\\n At this failure we have \\n Eg: {len(Eg)} \\n Memory: {len(Memory)} \\n\")\n",
    "        return Eg,Memory\n",
    "    \n",
    "    #Repeat recursion step\n",
    "    else:\n",
    "        # print(\"Passes Checks \\n\")\n",
    "        #Add the new data to memory\n",
    "        \n",
    "        set_indicators=set([sorted_frozenset(tuple(indicators)),])\n",
    "        Memory=Memory.union(set_indicators)\n",
    "        \n",
    "        Jbar_union=set([sorted_frozenset(Jbar),])#Correct format for union\n",
    "        #Add new data to Eg\n",
    "        Eg=Eg.union(Jbar_union) # will ge an issue with where defines and globals.\n",
    "\n",
    "        #Move onto the next recursion.\n",
    "        power_complment=set(power_set_str)-Jbar\n",
    "        for w in power_complment: # pick one in the complement to to continus exhaustive method\n",
    "            new_indicators=indicators+(w,) #want to add it at end\n",
    "            Eg,Memory=Recur(Jbar,new_indicators,Eg,Memory,dict_PC)\n",
    "            # print(f\"Done with {new_indicators} \\n\")\n",
    "                \n",
    "    return Eg,Memory # will also be an issue."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d2be00c-bf93-4c79-ae8d-0fab880ca1bc",
   "metadata": {},
   "source": [
    "It remains to show how we take closure of any $I \\subseteq \\mathcal{P}_{n}^{+}$ with respect to $g$. Recall Definition $5.1.4$. That the closure of some $I \\subseteq \\mathcal{P}_{n}^{+}$ denoted as, $\\overline{I}$, with respect to $g$ is be the largest set in the following sequence of subsets of $\\mathcal{P}_{n}^+$,\n",
    "\n",
    "$$I=I_0 \\subseteq  \\cdots \\subseteq I_k $$\n",
    "\n",
    "where $I_{i}:=B_{i-1}\\cup I_{i-1}$ (we call this the $i$-partial closure of $I$) such that \n",
    "\n",
    "$$    B_{i-1}=  \\left\\{y \\in \\mathcal{P}_{n}^{+} \\mid \\forall x \\in I_{i-1} \\text{ such that } y \\supsetneq x \\text{ is $g$-minimal} \\text{ or }\n",
    "y \\subsetneq x  \\text{ is $g$-maximal} \\right\\}.$$ \n",
    "\n",
    "\n",
    "The next function takes $I:=I_0 \\in \\mathcal{P}_{n}^{+}$ and returns $I_{1}$ as defined above.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b6b01230-5cc3-46e1-8e10-d4962994677b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def next_j(ji,f_dict):\n",
    "    \"\"\"\n",
    "    Objective: Get the $i+1$-partial closure of $I$ of ji with respect to f_dict. \n",
    "    \n",
    "    By iterating through elements in ji and checks conditions involving fmin and fmax to determine which elements should be included in the new set jip1.\n",
    "    \n",
    "    Input:\n",
    "    #ji is the ith recursion set on constructing the closure. \n",
    "    f_dict: the function ususal denoted as g\n",
    "    \n",
    "    Returns: closure of ji.\n",
    "    \"\"\"\n",
    "    # print(\"ji\",ji)\n",
    "    # global f\n",
    "    \n",
    "    my_list=[]    \n",
    "    \n",
    "    \n",
    "    for x in power_set_str:\n",
    "        for y in ji:\n",
    "            if fmin(y,x,f_dict) and string_to_set(y).issubset(string_to_set(x)):\n",
    "                # print(\"y is\",y)\n",
    "                my_list.append(x)\n",
    "                # print(f\"{x} containing {y} f min \")\n",
    "    for x in power_set_str:\n",
    "        for y in ji:\n",
    "            if fmax(x,y,f_dict) and string_to_set(x).issubset(string_to_set(y)):\n",
    "                my_list.append(x)\n",
    "                \n",
    "    \n",
    "    jip1=set(my_list).union(ji)\n",
    "    \n",
    "    return jip1    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b6b67a9-1c66-4cd4-ba6c-33cd6b31c47c",
   "metadata": {},
   "source": [
    "The following function allows us to go from $I_i$ to $I_{i+1}$, until we end at the closure of $I$ wrt $g$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1694586d-c6d0-47d5-9447-d56f2120a8eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def rec_j(T,S,f_dict):\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    Objective: Given the $i$-partial closure of $S:=Ii$ to the $i+1$-partial closure of $T:=Ii+1$\n",
    "    Input:\n",
    "    T: (T=Ii)\n",
    "    S : S=Ii-1)\n",
    "    \n",
    "    f_dict : function\n",
    "    \n",
    "    Returns: The closure of S.\n",
    "    \"\"\"\n",
    "    # T=Ji and S=Ji-1, |T|\\ge |S|.\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    We ask if the set T=S. If so them T is closed, if not we are not finished taking the closure.\n",
    "    \"\"\"\n",
    "    C=string_to_set(T)-string_to_set(S) #T \\S # New elements\n",
    "    C={str(x) for x in C}    \n",
    "    # print(\"C\",C,f\"S term {S}\",f\"T term {T}\")\n",
    "    \n",
    "    #We are done\n",
    "    if len(C)==0: #Check if closed set \n",
    "        return T # return closed set\n",
    "    \n",
    "    #Not done yet.\n",
    "    if len(C)>0:\n",
    "        \"\"\"We then take the next partial-closure of T wrt Definion 5.1.4\"\"\"\n",
    "        U=next_j(T,f_dict) #next_j(T)\n",
    "        \n",
    "        #We then repeat this function.\n",
    "        Z=rec_j(U,T,f_dict)\n",
    "    # print(T)\n",
    "    return Z"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42473b3d-8468-4a77-9d76-18fc61ab731f",
   "metadata": {},
   "source": [
    "Finally the last function combines next\\_j and rec\\_j to give the closure of $I$ with respect to $g$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "40620542-7e0b-43e0-b977-b35ae35cba51",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_barj(J,f_dict):\n",
    "    \"\"\"\n",
    "    Objective: Gets the closure of J \\subseteq \\mathcal{P}_{n}^{+} with respect to f in \\tilde{P}_n.\n",
    "    Input:\n",
    "    J: is a element of the \\mathcal{P}_{n}^{+}\n",
    "    f_dict in \\tilde{P}_n.\n",
    "    \n",
    "    Returns:closure of J\n",
    "    \"\"\"\n",
    "    \n",
    "    j0=J\n",
    "    j1=next_j(j0,f_dict)\n",
    "    T=rec_j(j1,j0,f_dict)\n",
    "    return T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e38278e4-66bf-4da5-b07b-f096bcef1118",
   "metadata": {},
   "source": [
    "Note that we can use get\\_barj to immediatley obtain all primitive closed sets with respect to $g$. Remark: The inputs dict\\_PC and set\\_PC  for get\\_Eg, are a dictionary and set of primitive closed sets respectively, of a function $g \\in\\tilde{P}_{n-1}$, which are obtained by get\\_barj. Note we obtain the primitive closed sets, $\\mathcal{P}_{n}^{+}$ and $\\emptyset$ separately."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d4f330-c7a5-4ff8-a6ea-92f172786e66",
   "metadata": {},
   "source": [
    "Lastly we need to method to determine for $A,B \\in \\mathcal{P}_{n}^{+}$ whether $A \\subseteq B$ is $g$-minimal or $g$-maximal. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b37abe83-df41-4ce9-b808-f58ad12c4909",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fmin(A,B,f_dict):\n",
    "    \"\"\"\n",
    "    Objective: Determine if A is f-minimal with respect to B using a given dictionary of values.\n",
    "\n",
    "    Input:\n",
    "        - A: A string representing a set from the power set P_n.\n",
    "        - B: A string representing another set from the power set P_n where A is a subset of B.\n",
    "        - f_dict: A dictionary mapping set strings to corresponding values.\n",
    "\n",
    "    Returns:\n",
    "        - True if A is f-minimal with respect to B, False otherwise.\n",
    "    \"\"\"\n",
    "    \n",
    "    #A included in B\n",
    "    # global f_dict\n",
    "    \n",
    "    valA=f_dict[A]\n",
    "    valB=f_dict[B]\n",
    "    compBA=set_to_string(string_to_set(B)-string_to_set(A)) # B minus A\n",
    "    if len(compBA)==0: # to avoide when taking the complement gives empty set\n",
    "        return False\n",
    "    valBA=f_dict[compBA]\n",
    "    if valB==valA+valBA:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def fmax(A,B,f_dict):\n",
    "    \"\"\"\n",
    "    Objective: Determine if A is f-maximal with respect to B using a given dictionary of values.\n",
    "\n",
    "    Input:\n",
    "        - A: A string representing a set from the power set P_n.\n",
    "        - B: A string representing another set from the power set P_n where A is a subset of B.\n",
    "        - f_dict: A dictionary mapping set strings to corresponding values.\n",
    "\n",
    "    Returns:\n",
    "        - True if A is f-maximal with respect to B, False otherwise.\n",
    "    \"\"\"\n",
    "    #A included in B\n",
    "    # global f_dict\n",
    "    \n",
    "    valA=f_dict[A]\n",
    "    valB=f_dict[B]\n",
    "    compBA=set_to_string(string_to_set(B)-string_to_set(A)) # B minus A\n",
    "    \n",
    "    #A has to be a subset of B first\n",
    "    if len(compBA)==0: # to avoide when taking the complement gives empty set\n",
    "        return False\n",
    "    valBA=f_dict[compBA]\n",
    "    if valB==valA+valBA+1:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c290038e-0add-4427-ac6b-28b906828c24",
   "metadata": {},
   "source": [
    "### To determine $|\\tilde{P}_{n}|$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c338e5-09f0-45c9-9ba5-b3a2bfd213a5",
   "metadata": {},
   "source": [
    "As stated in the thesis. To decompose $p_n$ we give the sequences $\\boldsymbol{e}_{n}$ and $\\boldsymbol{d}_{n}$ by recording for each  $g \\in \\tilde{P}_{n-1}$ the size $|\\mathbb{E}(g)|$ when we construct $\\tilde{P}_{n}$ from $\\tilde{P}_{n-1}$. We then state $p_{n+1}=e_n \\cdot d_n$. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521fcc1f-9c97-4a0d-9c1a-c9582363c401",
   "metadata": {},
   "source": [
    "The following function allows us to record the size of $\\mathbb{E}(g)$ for each $g \\in \\tilde{P}_{n-1}$ by adding the key:value pair of the form 'Eg\\_Size':$|\\mathbb{E}(g)|$ to each $f=g+\\epsilon_{I} \\in \\tilde{P}_{n}$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "64633e16-52d5-4bc4-83e3-47899c59b0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Eg_column_Pn(df):\n",
    "    df=df.copy()\n",
    "\n",
    "    # Create a new column called \"new_column\"\n",
    "    df['Eg_Size'] = None\n",
    "\n",
    "    # Insert data into the new column\n",
    "    for i, row in df.iterrows():    \n",
    "        Eg=get_Eg_for_single_g(df,i,power_set_str)\n",
    "        df.at[i, 'Eg_Size'] = int(len(Eg))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a31ea3ff-6787-4495-ab23-adfda51a0418",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "## Secondary <a name=\"s12\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2413d8-5ecd-4d2f-867b-cf5d4e8b138e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### General constructing functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112393a1-0db2-4e17-accb-c8bb9075449d",
   "metadata": {},
   "source": [
    "The following functions allow us to state $\\mathcal{P}_{n}^{+}=\\mathcal{P}_{n} \\setminus \\emptyset$ and $\\mathcal{P}(\\mathcal{P}_{n}^{+})$ (where $\\mathcal{P}_{n}$ is the powerset of $\\{1,\\dots ,n\\}$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "42c764fc-7c14-4a1e-8b6f-3ea21bbdb9f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_powerset_str(n):\n",
    "    \"\"\"\n",
    "    Objective: Generate the power set of integers from 1 to n and represent it as a list of sorted strings.\n",
    "    \n",
    "    Input:\n",
    "        - n: An integer representing the upper bound of the set of integers (1 to n).\n",
    "        \n",
    "    Returns:\n",
    "        - power_set_str: A list of sorted strings representing the power set of integers from 1 to n.\n",
    "    \"\"\"\n",
    "    s=set(range(1,n+1))\n",
    "    power_set = [set(x)  for r in range(len(s) + 1) for x in itertools.combinations(s, r)]\n",
    "    power_set_str=[set_to_string(x) for x in power_set if len(x)>0]\n",
    "\n",
    "    return power_set_str\n",
    "\n",
    "def get_n_np1_powersets(n):\n",
    "    \"\"\"\n",
    "    Objective: Generate the power sets of integers from 1 to n and 1 to (n+1), representing them as lists of sorted strings.\n",
    "    \n",
    "    Input:\n",
    "        - n: An integer representing the upper bound of the sets of integers (1 to n and 1 to n+1).\n",
    "        \n",
    "    Returns:\n",
    "        - power_set_str: A list of sorted strings representing the power set of integers from 1 to n.\n",
    "        - power_set_str_np1: A list of sorted strings representing the power set of integers from 1 to n+1.\n",
    "    \"\"\"\n",
    "    s=set(range(1,n+1))\n",
    "    power_set = [set(x)  for r in range(len(s) + 1) for x in itertools.combinations(s, r)]\n",
    "    power_set_str=[set_to_string(x) for x in power_set if len(x)>0]\n",
    "\n",
    "    np1=n+1\n",
    "    sp1=set(range(1,n+2))\n",
    "    power_set_np1 = [set(x)  for r in range(np1+1 + 1) for x in itertools.combinations(sp1, r)]\n",
    "    power_set_str_np1=[set_to_string(x) for x in power_set_np1 if len(x)>0]\n",
    "\n",
    "    return power_set_str,power_set_str_np1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7afce88-1571-40f9-9db4-5e4f11208e95",
   "metadata": {},
   "source": [
    "As sets $I \\in\\mathcal{P}_{n}^{+}$ are mutable we use the following function to put them into a standard form and make them immutable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "78cd4a3c-12c5-4447-835e-c7f2f0d55e6a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sorted_frozenset(s):\n",
    "    \"\"\"\n",
    "    Objective: Sort the elements of a set and return them as a frozenset.\n",
    "    \n",
    "    Input:\n",
    "        - s: A set of elements.\n",
    "        \n",
    "    Returns:\n",
    "        - r: A frozenset containing the sorted elements from the input set.\n",
    "    \"\"\"\n",
    "    t=sorted(s)\n",
    "    r=frozenset(t)\n",
    "    return r"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a0a48a-ba87-4a03-9a52-f1469c798427",
   "metadata": {},
   "source": [
    "The following functions allow us to store $g \\in \\tilde{P}_n$ as a dictionary (e.g. of the form {'1': 0, '2': 0, '12': 0}) in particular the keys as a string representation of $I \\in \\mathcal{P}_{n}^{+}$ and to change back to set notation when needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "55cf9933-2266-41eb-bf1c-022de645e6bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_to_string(s):\n",
    "    \"\"\"\n",
    "    Objective: Convert a set of integers to a sorted string representation.\n",
    "    \n",
    "    Input:\n",
    "        - s: A set of integers.\n",
    "        \n",
    "    Returns:\n",
    "        - result: A string containing the sorted integers from the input set.\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    s = list(s)\n",
    "    s.sort()\n",
    "    # Convert the list of numbers to a list of strings\n",
    "    my_list=s\n",
    "    my_list = [str(i) for i in my_list]\n",
    "    # Use the join() function to convert the list of strings to a single string\n",
    "    result = ''.join(my_list)\n",
    "    return result\n",
    "\n",
    "def string_to_set(s):\n",
    "    \"\"\"\n",
    "    Objective: Convert a string of digits to a set of integers.\n",
    "    \n",
    "    Input:\n",
    "        - s: A string of digits.\n",
    "        \n",
    "    Returns:\n",
    "        - my_set: A set containing the integers parsed from the input string.\n",
    "    \"\"\"\n",
    "    my_list = list(s)\n",
    "    # Convert the list of strings to a list of integers\n",
    "    my_list = list(map(int,my_list))\n",
    "    # Convert the list to a set\n",
    "    my_set = set(my_list)\n",
    "    return my_set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9937cd-39f1-460f-a18e-63a47bb58ee3",
   "metadata": {
    "tags": []
   },
   "source": [
    "### For Build\\_Pn\\_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8f678f-ff0f-4161-a4cc-94a2598c1cd5",
   "metadata": {},
   "source": [
    "Let $f=g+\\epsilon_{I}$ for some $I \\in \\mathbb{E}(g)$, we then have $f(A \\cup \\{n+1\\})= g(A)+\\epsilon_{I}(A)$ for $A \\in \\mathcal{P}_{n-1}^{+}$. The following function allow us to obtain $A \\cup \\{n+1\\} \\in \\mathcal{P}_{n}^{+}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "404f5141-50c4-4686-98f2-8270c194059e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def add_n_p_1_to_string(string,n):\n",
    "    \"\"\"\n",
    "    Objective: Adds n+1 to the input string.\n",
    "\n",
    "    Input:\n",
    "    - string (str): The input string to which n+1 will be added.\n",
    "    - n (int): The number to be added to the string.\n",
    "\n",
    "    Returns:\n",
    "    - np1string (str): A new string formed by concatenating the input string and (n+1).\n",
    "    \"\"\"\n",
    "    #Adds n+1 to strings subsets\n",
    "    np1string=string+(f\"{n+1}\")\n",
    "    return np1string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63fec6e2-7e73-460f-8545-03acd49ae4b6",
   "metadata": {
    "tags": []
   },
   "source": [
    "### $\\mathbb{E}(g)$ for a fixed $g$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100bc828-253d-4e0f-b445-a81f24516266",
   "metadata": {},
   "source": [
    "The following function attains $\\mathbb{E}(g)$ for $g$, where power\\_set\\_str denotes $\\mathcal{P}_{n}^{+}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fd166050-336f-44ef-b757-a6ff5934fbea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Eg_for_single_g_dict(funct,power_set_str):\n",
    "    # print(power_set_str)\n",
    "    #Obj: puts Eg into correct format to check if topolgoy\n",
    "    #Inputs: df=Pn, numb used to get a specific function from df\n",
    "    \n",
    "    # Pick function in Pn\n",
    "    g=funct\n",
    "    \n",
    "    # print(power_set_str)\n",
    "\n",
    "    #get primitive closed sets\n",
    "    PC=[(x,get_barj({x},g)) for x in power_set_str]\n",
    "    dict_PC=dict(PC)\n",
    "    set_PC=[sorted_frozenset(get_barj({x},g)) for x in power_set_str]\n",
    "    # print(\"len set_PC\",len(set_PC))\n",
    "    \n",
    "    #Get all closed sets for extensions for g\n",
    "    Eg=list(get_Eg(dict_PC,power_set_str,set_PC))\n",
    "    Eg.append(frozenset()) #rembmer the empty set\n",
    "    return Eg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "16b0788b-d0fd-4a97-a64c-39d48c80d3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Eg_for_single_g(df,numb,power_set_str):\n",
    "\n",
    "    #Obj: puts Eg into correct format to check if topolgoy\n",
    "    #Inputs: df=Pn, numb used to get a specific function from df\n",
    "    \n",
    "    # Pick function in Pn\n",
    "    g=df.iloc[numb].to_dict()\n",
    "\n",
    "    #get primitive closed sets\n",
    "    PC=[(x,get_barj({x},g)) for x in power_set_str]\n",
    "    dict_PC=dict(PC)\n",
    "    set_PC=[sorted_frozenset(get_barj({x},g)) for x in power_set_str]\n",
    "\n",
    "    #Get all closed sets for extensions for g\n",
    "    Eg=list(get_Eg(dict_PC,power_set_str,set_PC))\n",
    "    Eg.append(frozenset()) #rembmer the empty set\n",
    "    return Eg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0533ac9f-3cc6-41c9-86ee-cc92b05d14a1",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Primitive closed sets of $\\mathbb{E}(g)$ for a fixed $g$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42ba9e6-5f46-4c6e-882d-7d37333eae2e",
   "metadata": {},
   "source": [
    "Fix $g \\in \\tilde{P}_{n}$. We now obtain all the primitive closed sets of $\\mathbb{E}(g)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "11494e57-0536-4a18-8b0a-2a5c90acf027",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df=Pn for some n\n",
    "def get_primitive_for_single_g(g,power_set_str):\n",
    "    \"\"\"\n",
    "    Objective:\n",
    "    Input:\n",
    "    Returns: \n",
    "    \n",
    "    set_PC: set of primitive closed set\n",
    "    dict_PC: dictionary with keys as terms of powerset^{+} with value as the primitive closed assoicated.\n",
    "    \"\"\"\n",
    "    #Inputs: df=Pn, numb used to get a specific function from df\n",
    "    \n",
    "    # Pick function in Pn\n",
    "    g=g\n",
    "\n",
    "    #get primitive closed sets\n",
    "    PC=[(x,get_barj({x},g)) for x in power_set_str]\n",
    "    dict_PC=dict(PC)\n",
    "    set_PC=[sorted_frozenset(get_barj({x},g)) for x in power_set_str]\n",
    "\n",
    "    return dict_PC,set_PC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63fd5e57-b661-403c-906c-470e2c681bf2",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "### Analysis of $\\tilde{P}_{n}$<a name=\"s114\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc595f3-f7d3-4230-ad0e-7907b1d184ae",
   "metadata": {},
   "source": [
    "The following function determines whether all constructed functions are distinct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "67ae9795-f32f-4459-9c28-fdd78fe4c676",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def inspect_Pn1(df):\n",
    "    \"\"\"\n",
    "    Objective:\n",
    "    Input:\n",
    "    Returns:\n",
    "    \"\"\"\n",
    "    print(\"Number of functions:\",len(df.index))\n",
    "    # df=df.unique()\n",
    "\n",
    "    duplicate_rows = df[df.duplicated()]\n",
    "    print(\"Are there duplicates?\",duplicate_rows.shape, \"if (0,-) then no common rows\")\n",
    "\n",
    "    # df.head()\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fdf34a3-c2ed-4877-9cac-02b9379a380e",
   "metadata": {},
   "source": [
    "The following functions allow one to check whether a function is mildly super additive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6b65d1bb-b8a3-44d8-9b01-ae02fb506363",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def is_valid_function(f,power_set_str):\n",
    "    \"\"\"\n",
    "    Objective: Check if a given function satisfies the properties of a MSA condition\n",
    "    \n",
    "    Input:\n",
    "    f (dict): A dictionary representing the function, where keys are sets in power_set_str and values are integers.\n",
    "    power_set_str (list of str): A list of string representations of sets.\n",
    "    \n",
    "    Returns:\n",
    "    bool: True if the function satisfies the MSA properties, False otherwise.\n",
    "    \"\"\"\n",
    "    # define the condition to check for each function\n",
    "    Pn=[string_to_set(x) for x in power_set_str] #convert to sets\n",
    "    \n",
    "    # f(T) must equal 0 for elements T in Pn with size 1\n",
    "\n",
    "    for T in Pn:\n",
    "        if any(f[set_to_string(T)] != 0 for T in Pn if len(T) == 1):\n",
    "            return False\n",
    "    # for any I, J in Pn such that I and J have no common elements, 1 > f(I U J) - f(I) - f(J) or 0 = f(I U J) - f(I) - f(J)\n",
    "    for I in Pn:\n",
    "        for J in Pn:\n",
    "            if len(I.intersection(J)) == 0 and f[set_to_string(I.union(J))] - f[set_to_string(I)] - f[set_to_string(J)] < 0 or f[set_to_string(I.union(J))] - f[set_to_string(I)] - f[set_to_string(J)] > 1:\n",
    "            # for any I, J in Pn such that I and J have no common elements, 0 <= f(I U J) - f(I) - f(J) <= 1\n",
    "                return False\n",
    "    return True\n",
    "\n",
    "def check_functs_MSA(df,power_set_str):\n",
    "    \"\"\"\n",
    "    Objective: Check a DataFrame of functions for MSA compliance.\n",
    "    \n",
    "    Input:\n",
    "    df (pd.DataFrame): A DataFrame where each row represents a function as a dictionary.\n",
    "    power_set_str (list of str): A list of string representations of sets.\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: A DataFrame containing the functions that do not satisfy MSA properties.\n",
    "    \"\"\"\n",
    "\n",
    "    num_rows=df.shape[0]\n",
    "\n",
    "    bad_f_in_df=[] #indices of functions fail to be MSA in df\n",
    "    for i in range(0,num_rows):\n",
    "        f=df.loc[i].to_dict()\n",
    "        if  is_valid_function(f,power_set_str)==False:\n",
    "            bad_f_in_df.append(f)\n",
    "    \n",
    "    bad_df=pd.DataFrame(bad_f_in_df)\n",
    "    \n",
    "    return bad_df #indices of functions that are not MSA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "771116fc-4135-48c3-aeb8-d901ba3db821",
   "metadata": {},
   "source": [
    "### Building $\\tilde{P}_{6}$ and decomposing $|\\tilde{P}_{6}|$ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640c31af-af8a-4b21-8494-05dacc8fa831",
   "metadata": {},
   "source": [
    "The following function takes the $\\tilde{P}_{n-1}$ and attains $\\tilde{P}_{n}$ with the column 'Eg_Size':$|\\mathbb{E}(g)|$ for each $g \\in \\tilde{P}_{n-1}$ which extends to said function in $f \\in \\tilde{P}_{n}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "71dee92b-8100-44db-873a-0d0e50a46e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eg_column_Build_Pn_1(list_df_Pn,power_set_str,n):\n",
    "    \n",
    "    \"\"\"\n",
    "    Obj:Use Build_Pn_1 and modify change to include Eg size column in functions\n",
    "    \"\"\"\n",
    "    \n",
    "    # Returns:packets of extensions for each f_dict from Pn, can check those with max size of closed sets (later)\n",
    "    \n",
    "    P_n1=[]\n",
    "    for index,f_dict in enumerate(list_df_Pn):\n",
    "\n",
    "        # Store primitive closed sets \n",
    "        PC=[(x,get_barj({x},f_dict)) for x in power_set_str]\n",
    "        dict_PC=dict(PC)\n",
    "        set_PC=[sorted_frozenset(get_barj({x},f_dict)) for x in power_set_str]\n",
    "\n",
    "        #Get all closed sets for extensions for f_dict\n",
    "        Eg=list(get_Eg(dict_PC,power_set_str,set_PC))\n",
    "        Eg.append(\"empty\")\n",
    "        \n",
    "        Eg_col_kvpair={\"Eg_Size\":len(Eg)}\n",
    "\n",
    "        #Build extensions for f_dict\n",
    "        extension_of_f_dict=[]\n",
    "        for term in Eg:\n",
    "            if term ==\"empty\":                    \n",
    "                funct=empty_case_get_extension_of_f(f_dict,term,power_set_str,n) #dictionary\n",
    "                funct.update(Eg_col_kvpair)\n",
    "                extension_of_f_dict.append(funct)\n",
    "            else:\n",
    "                funct=get_extension_of_f(f_dict,term,power_set_str,n)\n",
    "                funct.update(Eg_col_kvpair)\n",
    "                extension_of_f_dict.append(funct)\n",
    "\n",
    "        #We record packets of extensions where we take +1\n",
    "        P_n1.append(extension_of_f_dict)\n",
    "    \n",
    "    return P_n1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "921c7c13-9b5b-4f2a-a364-242ae3c48ece",
   "metadata": {},
   "source": [
    "We repeat the above process but for the dataframe consisting of a subset of $\\tilde{P}_{n-1}$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c676118b-d859-4167-a324-137ab3548612",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Pnp1_for_single_funct(Pn,n):\n",
    "    \n",
    "    #inputs\n",
    "    # Pn:dataframe and n.\n",
    "    \n",
    "    \"\"\"\n",
    "    Returns a dataframe of extensions in Pn+1 for dataframe of functions in Pn.\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    #Example\n",
    "    n=3\n",
    "    power_set_str,power_set_str_np1=get_n_np1_powersets(n)\n",
    "    # P3\n",
    "\n",
    "    funct_list=[{'1': 0,'2': 0,\"3\":0,\"12\":0,\"23\":0,\"13\":0,\"123\":0}]\n",
    "    Pn=pd.DataFrame(funct_list)\n",
    "\n",
    "    #The following should be functions in P4 that are extendions of functions in funct_list\n",
    "    f_P3=get_Pnp1_for_single_funct(Pn,n)\n",
    "    print(f_P3)\n",
    "    \"\"\"\n",
    "\n",
    "    #New data created\n",
    "    power_set_str,power_set_str_np1=get_n_np1_powersets(n)\n",
    "\n",
    "    #Load Pn as a list of dictionaries.\n",
    "    list_df_Pn=Pn.to_dict(orient='records')\n",
    "\n",
    "    #Create Pn+1 and hold as dataframe.\n",
    "    P_n1=eg_column_Build_Pn_1(list_df_Pn,power_set_str,n)\n",
    "    Pnp1=extend_sets_to_Pnp1(P_n1) #<---- ISSUE\n",
    "    \n",
    "    power_set_str_np1\n",
    "    \n",
    "    columns=list(power_set_str_np1)+[\"Eg_Size\"]\n",
    "    Pnp1 = Pnp1.reindex(columns=columns)\n",
    "\n",
    "\n",
    "    inspect_Pn1(Pnp1)\n",
    "\n",
    "    return Pnp1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36fbc40-d226-4e7f-8f1b-0ee4de7b5b05",
   "metadata": {},
   "source": [
    "Here we see get_Pnp1_for_single_funct in action for P3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f4180022-ed73-47df-a563-6e3fd0f3f13a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The functions we are extending\n",
      "   1  2  3  12  23  13  123\n",
      "0  0  0  0   0   0   0    0\n",
      "Number of functions: 19\n",
      "Are there duplicates? (0, 16) if (0,-) then no common rows\n",
      "    1  2  3  4  12  13  14  23  24  34  123  124  134  234  1234  Eg_Size\n",
      "0   0  0  0  0   0   0   0   0   0   0    0    0    1    0     1       19\n",
      "1   0  0  0  0   0   0   0   0   1   1    0    1    1    1     1       19\n",
      "2   0  0  0  0   0   0   0   0   0   1    0    1    1    1     1       19\n",
      "3   0  0  0  0   0   0   0   0   1   0    0    1    0    1     1       19\n",
      "4   0  0  0  0   0   0   1   0   1   0    0    1    1    1     1       19\n",
      "5   0  0  0  0   0   0   1   0   0   0    0    1    1    1     1       19\n",
      "6   0  0  0  0   0   0   0   0   0   0    0    1    1    1     1       19\n",
      "7   0  0  0  0   0   0   0   0   0   0    0    1    1    0     1       19\n",
      "8   0  0  0  0   0   0   0   0   0   0    0    1    0    0     1       19\n",
      "9   0  0  0  0   0   0   1   0   1   1    0    1    1    1     1       19\n",
      "10  0  0  0  0   0   0   1   0   0   0    0    1    1    0     1       19\n",
      "11  0  0  0  0   0   0   1   0   0   1    0    1    1    1     1       19\n",
      "12  0  0  0  0   0   0   0   0   1   0    0    1    1    1     1       19\n",
      "13  0  0  0  0   0   0   0   0   0   0    0    0    0    0     1       19\n",
      "14  0  0  0  0   0   0   0   0   0   0    0    0    0    1     1       19\n",
      "15  0  0  0  0   0   0   0   0   0   0    0    0    1    1     1       19\n",
      "16  0  0  0  0   0   0   0   0   0   1    0    0    1    1     1       19\n",
      "17  0  0  0  0   0   0   0   0   0   0    0    1    0    1     1       19\n",
      "18  0  0  0  0   0   0   0   0   0   0    0    0    0    0     0       19\n"
     ]
    }
   ],
   "source": [
    "#Testing functions example\n",
    "n=3\n",
    "power_set_str,power_set_str_np1=get_n_np1_powersets(n)\n",
    "# P3\n",
    "\n",
    "# You can take subsets of rows as a database, then extend. Better than below\n",
    "funct_list=[{'1': 0,'2': 0,\"3\":0,\"12\":0,\"23\":0,\"13\":0,\"123\":0}]\n",
    "Pn=pd.DataFrame(funct_list)\n",
    "print(\"The functions we are extending\")\n",
    "print(Pn)\n",
    "\n",
    "#The following should be functions in P4 that are extendions of functions in funct_list\n",
    "f_P3=get_Pnp1_for_single_funct(Pn,n)\n",
    "print(f_P3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baaa4f8a-4c01-47ce-bda5-e67f9623e123",
   "metadata": {},
   "source": [
    "The following function allows us to break the construction of $\\tilde{P}_{6}$ into parts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f1c7587f-14a6-4a93-b242-6bde6b8837ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Pnp1_from_Pn_part(df,n,calc_start,calc_end):\n",
    "    # df where we are extending from\n",
    "    # calc_start=0\n",
    "    # calc_end=5\n",
    "\n",
    "    rows=range(calc_start,calc_end) #What functions we are extending\n",
    "    Pn=df.iloc[rows] #takes database of rows 0,1..,calc_up_to\n",
    "\n",
    "    # print(\"The functions we are extending\")\n",
    "    # print(Pn,\"\\n\")\n",
    "\n",
    "    part_Pn=get_Pnp1_for_single_funct(Pn,n) #Extensions of Pn\n",
    "    # print(part_Pn.shape)\n",
    "    \n",
    "    strt=f\"P{n+1}_parts\\{calc_start}_{calc_end}_Part_fromP{n}.xlsx\"\n",
    "    part_Pn.to_excel(strt) #Stores in excel\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e02a8ba5-8bcf-4a64-8fb0-8c88b6b178cd",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "# Example <a name=\"s2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bfdedce-9fbe-44e3-9918-552f42cf921d",
   "metadata": {},
   "source": [
    "Lets first investigate a single function $g \\in \\tilde{P}_{3}$, and obtain $\\mathbb{E}(g)$ and the subsequent $f=g+\\epsilon_{I}$. First lets define $\\mathcal{P}_{3}^{+}$ and $\\mathcal{P}_{4}^{+}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5068edd4-728d-48c7-a7c7-a244f2e9debd",
   "metadata": {},
   "outputs": [],
   "source": [
    "n=3\n",
    "power_set_str,power_set_str_np1=get_n_np1_powersets(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceba450e-5f2f-4d21-9abc-282fd8f3eadd",
   "metadata": {},
   "source": [
    "Let $g$ (i.e. $f_{U_3}$) be as below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "21457b30-275e-414b-a82c-7e627073c368",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>12</th>\n",
       "      <th>23</th>\n",
       "      <th>13</th>\n",
       "      <th>123</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   1  2  3  12  23  13  123\n",
       "0  0  0  0   0   0   0    0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_u3={'1': 0,'2': 0,\"3\":0,\"12\":0,\"23\":0,\"13\":0,\"123\":0}\n",
    "funct_list=[f_u3]\n",
    "d_funct=pd.DataFrame(funct_list)\n",
    "d_funct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "88ac5c3b-5cfa-4872-8389-53fd76ae7827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of functions: 19\n",
      "Are there duplicates? (0, 16) if (0,-) then no common rows\n",
      "    1  2  3  4  12  13  14  23  24  34  123  124  134  234  1234  Eg_Size\n",
      "0   0  0  0  0   0   0   0   0   0   0    0    0    1    0     1       19\n",
      "1   0  0  0  0   0   0   0   0   1   1    0    1    1    1     1       19\n",
      "2   0  0  0  0   0   0   0   0   0   1    0    1    1    1     1       19\n",
      "3   0  0  0  0   0   0   0   0   1   0    0    1    0    1     1       19\n",
      "4   0  0  0  0   0   0   1   0   1   0    0    1    1    1     1       19\n",
      "5   0  0  0  0   0   0   1   0   0   0    0    1    1    1     1       19\n",
      "6   0  0  0  0   0   0   0   0   0   0    0    1    1    1     1       19\n",
      "7   0  0  0  0   0   0   0   0   0   0    0    1    1    0     1       19\n",
      "8   0  0  0  0   0   0   0   0   0   0    0    1    0    0     1       19\n",
      "9   0  0  0  0   0   0   1   0   1   1    0    1    1    1     1       19\n",
      "10  0  0  0  0   0   0   1   0   0   0    0    1    1    0     1       19\n",
      "11  0  0  0  0   0   0   1   0   0   1    0    1    1    1     1       19\n",
      "12  0  0  0  0   0   0   0   0   1   0    0    1    1    1     1       19\n",
      "13  0  0  0  0   0   0   0   0   0   0    0    0    0    0     1       19\n",
      "14  0  0  0  0   0   0   0   0   0   0    0    0    0    1     1       19\n",
      "15  0  0  0  0   0   0   0   0   0   0    0    0    1    1     1       19\n",
      "16  0  0  0  0   0   0   0   0   0   1    0    0    1    1     1       19\n",
      "17  0  0  0  0   0   0   0   0   0   0    0    1    0    1     1       19\n",
      "18  0  0  0  0   0   0   0   0   0   0    0    0    0    0     0       19\n"
     ]
    }
   ],
   "source": [
    "#The following should be functions in P4 that are extendions of functions in funct_list\n",
    "f_P3=get_Pnp1_for_single_funct(d_funct,n)\n",
    "print(f_P3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ddc0f81-0f00-4cc1-83cd-2c4ff0e8edf7",
   "metadata": {},
   "source": [
    "We see that $|\\mathbb{E}(g)|=19$ and there a $19$ many $f=g+\\epsilon_{I}\\in \\tilde{P}_{4}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7afe81ce-ccfb-4f58-b38a-d417034df20e",
   "metadata": {
    "tags": []
   },
   "source": [
    "We can ask what explicitly is $\\mathbb{E}(g)$? First what are the primitive closed sets in $\\mathbb{E}(g)$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e423a75-32b1-45c5-bf58-4bac29ef1315",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get primitive closed data.\n",
    "# dict_PC,set_PC=get_primitive_for_single_g(f_u3,power_set_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217df5e0-9e17-420e-aab8-91dbeb688bd4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# dict_PC\n",
    "\n",
    "# Primitive closed sets\n",
    "# {'1': {'1', '12', '123', '13'},\n",
    "#  '2': {'12', '123', '2', '23'},\n",
    "#  '3': {'123', '13', '23', '3'},\n",
    "#  '12': {'12', '123'},\n",
    "#  '13': {'123', '13'},\n",
    "#  '23': {'123', '23'},\n",
    "#  '123': {'123'}}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40088bef-9307-44b9-9ea9-c9de831c2ae0",
   "metadata": {},
   "source": [
    "We now obtain the set $\\mathbb{E}(g)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120e2524-bb19-4b5a-99d0-0bcffa228c0b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Eg=get_Eg(dict_PC,power_set_str,set_PC)\n",
    "# Eg.add(\"empty\")\n",
    "\n",
    "# # {'empty',\n",
    "# #  frozenset({'1', '12', '123', '13', '2', '23'}),\n",
    "# #  frozenset({'1', '12', '123', '13', '23'}),\n",
    "# #  frozenset({'1', '12', '123', '13', '2', '23', '3'}),\n",
    "# #  frozenset({'1', '12', '123', '13', '23', '3'}),\n",
    "# #  frozenset({'12', '123'}),\n",
    "# #  frozenset({'12', '123', '13', '2', '23'}),\n",
    "# #  frozenset({'12', '123', '13'}),\n",
    "# #  frozenset({'123', '13'}),\n",
    "# #  frozenset({'123', '23'}),\n",
    "# #  frozenset({'123'}),\n",
    "# #  frozenset({'1', '12', '123', '13'}),\n",
    "# #  frozenset({'12', '123', '2', '23'}),\n",
    "# #  frozenset({'12', '123', '23'}),\n",
    "# #  frozenset({'12', '123', '13', '23'}),\n",
    "# #  frozenset({'123', '13', '23', '3'}),\n",
    "# #  frozenset({'123', '13', '23'}),\n",
    "# #  frozenset({'12', '123', '13', '2', '23', '3'}),\n",
    "# #  frozenset({'12', '123', '13', '23', '3'})}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8582433-41ef-469a-a626-21ee83c5e00e",
   "metadata": {},
   "source": [
    "Let us consider the following function $f_{L_3}$ and determine $\\mathbb{E}(f_{L_3})$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbaf5a90-0426-4dff-b692-6ebbcbf87c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_l3={'1': 0,'2': 0,\"3\":0,\"12\":0,\"23\":1,\"13\":1,\"123\":1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00eaaf31-11ff-4230-a3ef-71e1d37b23c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get primitive closed data.\n",
    "dict_PC,set_PC=get_primitive_for_single_g(f_l3,power_set_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76950ca9-3a8f-45d1-95fa-56a2a6f1ccfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict_PC\n",
    "# {'1': {'1', '12', '123', '3'},\n",
    "#  '2': {'12', '123', '2', '3'},\n",
    "#  '3': {'3'},\n",
    "#  '12': {'12'},\n",
    "#  '13': {'1', '12', '123', '13', '3'},\n",
    "#  '23': {'12', '123', '2', '23', '3'},\n",
    "#  '123': {'12', '123', '3'}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59aa860a-a692-4e27-93cd-c0cf066f76a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eg=get_Eg(dict_PC,power_set_str,set_PC)\n",
    "# Eg.add(\"empty\")\n",
    "# Eg\n",
    "# {'empty',\n",
    "#  frozenset({'1', '12', '123', '2', '23', '3'}),\n",
    "#  frozenset({'1', '12', '123', '2', '3'}),\n",
    "#  frozenset({'1', '12', '123', '13', '2', '23', '3'}),\n",
    "#  frozenset({'1', '12', '123', '13', '2', '3'}),\n",
    "#  frozenset({'1', '12', '123', '13', '3'}),\n",
    "#  frozenset({'12', '3'}),\n",
    "#  frozenset({'12'}),\n",
    "#  frozenset({'1', '12', '123', '3'}),\n",
    "#  frozenset({'12', '123', '3'}),\n",
    "#  frozenset({'12', '123', '2', '3'}),\n",
    "#  frozenset({'12', '123', '2', '23', '3'}),\n",
    "#  frozenset({'3'})}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7aa5c0-28d5-4056-bc75-59c9de402ba2",
   "metadata": {
    "tags": []
   },
   "source": [
    "# $\\tilde{P}_{n}$ and $|\\tilde{P}_{n}|$ decomposition <a name=\"s3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f36e728-9109-4cc5-a745-c800c7c7a4d3",
   "metadata": {},
   "source": [
    "We now determine $\\tilde{P}_{n}$ by $\\tilde{P}_{n-1}$ for $n \\le 6$ recursively using the get_Pnp1() described in Section \"Functions\",\n",
    "\n",
    " and give a decomposition of $|\\tilde{P}_{n}|$ in terms $|\\tilde{P}_{n-1}|$. Recall the following. Let $(p_{n})_{n \\in \\mathbb{N}}$ denote the sequence of terms $p_{n}:=|\\tilde{P}_n|$. Let $\\boldsymbol{e}_{n}:=(e_{n,i})$ denote the increasing sequence of distinct terms $|\\mathbb{E}(g)|$ for $g \\in \\tilde{P}_{n}$, and $\\boldsymbol{d}_{n}:=(d_{n,i})$ denote the sequence where $d_{n,i}$ denotes the number of $g \\in \\tilde{P}_{n}$ which give the value $e_{n,i}$.\n",
    "\n",
    "  $$p_{n+1} =\\boldsymbol{e}_n \\cdot \\boldsymbol{d}_{n}=\\sum e_{n,i}\n",
    " \\times d_{n,i}.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c428a3-0381-4985-b328-e08ad5745e48",
   "metadata": {
    "tags": []
   },
   "source": [
    "## $\\tilde{P}_{3}$ and $|\\tilde{P}_{3}|$ decomposition <a name=\"s31\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b34b406-0903-4cb5-8f29-14ddceb9400d",
   "metadata": {},
   "source": [
    "We now obtian $\\tilde{P}_{3}$ by extending $\\tilde{P}_{2}$. It is clear that $\\tilde{P}_{2}$ consists of exactly two functions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "c99dc305-d4de-4ec5-be05-49b146c03544",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Easy to know $P_2$\n",
    "P2=pd.DataFrame([{'1': 0, '2': 0, '12': 0},{'1': 0, '2': 0, '12': 1}])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bdc28c4-ce8b-4e2b-bf8f-fcb451b3ce89",
   "metadata": {},
   "source": [
    "We first define $\\mathcal{P}_{2}^{+}$ and $\\mathcal{P}_{3}^{+}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "dfdbe3c2-df6f-4741-ae52-482ab7d49306",
   "metadata": {},
   "outputs": [],
   "source": [
    "n=2\n",
    "power_set_str,power_set_str_np1=get_n_np1_powersets(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "8f0ce6f9-dea3-4381-9f19-5c9be32e3980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of functions: 10\n",
      "Are there duplicates? (0, 7) if (0,-) then no common rows\n",
      "   1  2  3  12  13  23  123\n",
      "0  0  0  0   0   1   0    1\n",
      "1  0  0  0   0   1   1    1\n",
      "2  0  0  0   0   0   1    1\n",
      "3  0  0  0   0   0   0    1\n",
      "4  0  0  0   0   0   0    0\n",
      "5  0  0  0   1   1   1    2\n",
      "6  0  0  0   1   0   1    1\n",
      "7  0  0  0   1   1   1    1\n",
      "8  0  0  0   1   1   0    1\n",
      "9  0  0  0   1   0   0    1\n",
      "CPU times: total: 0 ns\n",
      "Wall time: 14.7 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "P3=get_Pnp1(P2,2)\n",
    "print(P3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780169ec-99ff-4006-bee2-b38713eb8658",
   "metadata": {},
   "source": [
    "When consider the extension of $\\tilde{P}_{2}$ to $\\tilde{P}_{3}$ we record the size of each $|\\mathbb{E}(g)|$ for $ \\in \\tilde{P}_{2}$. We then obtain the sequences $e_{2}$ and $d_{2}$ (possiblly not ordered by increasing size), and state\n",
    "\n",
    "$$p_3=\\boldsymbol{e}_2 \\cdot \\boldsymbol{d}_2.$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "b76cecd6-98e2-4107-a8eb-b566f1a6d047",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e_n : d_n\n",
      "5    2\n",
      "Name: Eg_Size, dtype: int64\n",
      "   1  2  12 Eg_Size\n",
      "0  0  0   0       5\n",
      "1  0  0   1       5\n"
     ]
    }
   ],
   "source": [
    "P2_eg=get_Eg_column_Pn(P2)\n",
    "P2_eg=P2_eg.sort_values('Eg_Size') \n",
    "df=P2_eg\n",
    "print(f\"e_n : d_n\")\n",
    "print(df['Eg_Size'].value_counts()) #count number of 13s and 19s\n",
    "# print(P2_eg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92fb7904-dc63-4302-ae17-63034b44797c",
   "metadata": {
    "tags": []
   },
   "source": [
    "We have $p_3=5\\cdot1 +5 \\cdot 1$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46acc1ff-fea8-49b5-a26a-b521c3ec1dda",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## $\\tilde{P}_{4}$ and $|\\tilde{P}_{4}|$ decomposition <a name=\"s32\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dae68ca-3c6b-45dc-a471-a6520840f6fe",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "We now obtian $\\tilde{P}_{4}$ by extending $\\tilde{P}_{3}$. We first define $\\mathcal{P}_{3}^{+}$ and $\\mathcal{P}_{4}^{+}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "648d268d-3bc4-49ed-9efb-15b019697303",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n=3\n",
    "power_set_str,power_set_str_np1=get_n_np1_powersets(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "3e8491dd-4444-41f0-9cb6-dba9da3c8f3b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of functions: 154\n",
      "Are there duplicates? (0, 15) if (0,-) then no common rows\n",
      "CPU times: total: 78.1 ms\n",
      "Wall time: 84.6 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "P4=get_Pnp1(P3,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd35b3d-1328-43f6-8e9f-da3f245bdbcd",
   "metadata": {
    "tags": [
     "p3"
    ],
    "toc-hr-collapsed": true
   },
   "source": [
    "We can check that each  $f \\in \\tilde{P}_{4}$ is in fact MSA. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7f30ea-6127-4071-8e49-cbccd6a74066",
   "metadata": {},
   "outputs": [],
   "source": [
    "# power4=get_powerset_str(4) #powerset on 4 elements\n",
    "# check_functs_MSA(P4,power_set_str_np1).shape\n",
    "#Yes (0, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df9b155-1a5d-4ddd-8c5d-8b1efa224fcf",
   "metadata": {},
   "source": [
    "When consider the extension of $\\tilde{P}_{3}$ to $\\tilde{P}_{4}$ we record the size of each $|\\mathbb{E}(g)|$ for $ \\in \\tilde{P}_{3}$. We then obtain the sequences $e_{3}$ and $d_{3}$ (possiblly not ordered by increasing size), and state\n",
    "\n",
    "$$p_4=\\boldsymbol{e}_3 \\cdot \\boldsymbol{d}_3.$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "d74ba281-e7b6-45f3-9ce7-da1e766adc3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "P3_eg=get_Eg_column_Pn(P3)\n",
    "P3_eg=P3_eg.sort_values('Eg_Size') # get those 13,then 19\n",
    "\n",
    "df=P3_eg\n",
    "print(f\"e_n : d_n\")\n",
    "print(df['Eg_Size'].value_counts()) #count number of 13s and 19s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "f01c9d5b-6368-41ea-b337-48a395240831",
   "metadata": {},
   "outputs": [],
   "source": [
    "# min_df = df[df['Eg_Size'] == 13]\n",
    "# min_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21fa353f-47a7-4674-b203-fa843dc5833e",
   "metadata": {},
   "source": [
    "In particular $p_4 = 13 \\cdot 6 + 19 \\cdot 4$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35251b4-e820-41b9-ad18-687a624d6611",
   "metadata": {
    "tags": []
   },
   "source": [
    "## $\\tilde{P}_{5}$ and $|\\tilde{P}_{5}|$ decomposition <a name=\"s33\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9153d52-095f-472d-b770-d870786ea63b",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "We now obtian $\\tilde{P}_{5}$ by extending $\\tilde{P}_{4}$. We first define $\\mathcal{P}_{4}^{+}$ and $\\mathcal{P}_{5}^{+}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "9c88f27c-a368-4fa2-a135-6538c5f2feb5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n=4\n",
    "power_set_str,power_set_str_np1=get_n_np1_powersets(n) #gives powerset on 4 and 5 elements respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "ff90b67e-ccf1-4a6a-a54d-46f8e2ee3c65",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of functions: 10334\n",
      "Are there duplicates? (0, 31) if (0,-) then no common rows\n",
      "CPU times: total: 6.33 s\n",
      "Wall time: 10 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "P5=get_Pnp1(P4,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f9891b-984f-4cd3-9dfc-c812d682f863",
   "metadata": {
    "tags": [
     "p3"
    ],
    "toc-hr-collapsed": true
   },
   "source": [
    "We can check that each  $f \\in \\tilde{P}_{5}$ is in fact MSA. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eba7f17-0273-4bbd-aaaf-4740da3d6331",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# power5=get_powerset_str(5) #powerset on 4 elements\n",
    "# check_functs_MSA(P5,power5).shape\n",
    "# #Yes (0, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b26d32a0-fe80-465e-92d3-c0afdba7957b",
   "metadata": {},
   "source": [
    "When consider the extension of $\\tilde{P}_{4}$ to $\\tilde{P}_{5}$ we record the size of each $|\\mathbb{E}(g)|$ for $ \\in \\tilde{P}_{4}$. We then obtain the sequences $e_{4}$ and $d_{4}$ (possiblly not ordered by increasing size), and state\n",
    "\n",
    "$$p_5=\\boldsymbol{e}_4 \\cdot \\boldsymbol{d}_4.$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "de105ce3-0a16-499b-b703-c72ac26c36aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e_n : d_n\n",
      "42     24\n",
      "45     24\n",
      "47     24\n",
      "82     16\n",
      "46     12\n",
      "54     12\n",
      "111    12\n",
      "99     10\n",
      "69      8\n",
      "133     8\n",
      "167     4\n",
      "Name: Eg_Size, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "P4_eg=get_Eg_column_Pn(P4)\n",
    "P4_eg=P4_eg.sort_values('Eg_Size') # get those 13,then 19\n",
    "df=P4_eg\n",
    "print(f\"e_n : d_n\")\n",
    "print(df['Eg_Size'].value_counts()) #count number of 13s and 19s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c89e17c-e2bd-4c54-b066-46a433a6cafe",
   "metadata": {},
   "source": [
    "Want to determinie the form of $f_{L_{n}}$ and how to extend (its definition)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1186ac52-5b97-44de-8363-475afdf1db2a",
   "metadata": {},
   "source": [
    "$p_5 = 42 · 24 + 45 · 24 + 46 · 12 + 47 · 24 + 54 · 12 + 69 · 8 + 82 · 16 + 99 · 10 + 111 · 12 + 133 · 8 + 167 · 4$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25fbd56d-8a1f-4b3e-9c85-dfd4e32accbc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## $\\tilde{P}_{6}$ and $|\\tilde{P}_{6}|$ decomposition <a name=\"s34\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3551dccd-9f26-4ff7-9dec-2e5e31c390a3",
   "metadata": {},
   "source": [
    "As obtaining, \n",
    "\n",
    "P6=get\\_Pnp1(P5,5),\n",
    "\n",
    "takes too long we break the construction into parts. During this process we record the $|\\mathbb{E}(g)|$ for $g \\in \\tilde{P}_{5}$ from which we can determine $p_{6}=\\boldsymbol{e}_{5} \\cdot \\boldsymbol{d}_{5}$. First we outline the process of building in parts by building $\\tilde{P}_{4}$ from $\\tilde{P}_{3}$ in parts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f445619-ff65-49de-8783-2cd4aaef6ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "n=3\n",
    "power_set_str,power_set_str_np1=get_n_np1_powersets(n)\n",
    "# P3\n",
    "df=P3 #Total dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46372f5d-8e2e-405e-914d-359cd6e5dec5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "calc_start=0\n",
    "calc_end=5\n",
    "\n",
    "rows=range(calc_start,calc_end) #What functions we are extending\n",
    "Pn=df.iloc[rows] #takes database of rows 0,1..,calc_up_to\n",
    "\n",
    "print(\"The functions we are extending\")\n",
    "print(Pn,\"\\n\")\n",
    "\n",
    "part_Pn=get_Pnp1_for_single_funct(Pn,n) #Extensions of Pn\n",
    "print(part_Pn)\n",
    "strt=f\"P3_parts_example\\{calc_start}_{calc_end}_PartP4.xlsx\"\n",
    "part_Pn.to_excel(strt) #Stores in excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c946b1-0817-4d01-bca7-f7c383bfb59d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "calc_start=5\n",
    "calc_end=10\n",
    "\n",
    "rows=range(calc_start,calc_end) #What functions we are extending\n",
    "Pn=df.iloc[rows] #takes database of rows 0,1..,calc_up_to\n",
    "\n",
    "print(\"The functions we are extending\")\n",
    "print(Pn,\"\\n\")\n",
    "\n",
    "part_Pn=get_Pnp1_for_single_funct(Pn,n) #Extensions of Pn\n",
    "print(part_Pn)\n",
    "strt=f\"P3_parts_example\\{calc_start}_{calc_end}_PartP4.xlsx\"\n",
    "part_Pn.to_excel(strt) #Stores in excel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53fec167-9598-4afc-ab81-c560bdcc1657",
   "metadata": {},
   "source": [
    " We now merge the parts together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ccf1533-81a9-447d-a6ab-ac28b9043b02",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "P4_part1=pd.read_excel('P3_parts_example/0_5_PartP4.xlsx', index_col=0) \n",
    "P4_part2=pd.read_excel('P3_parts_example/5_10_PartP4.xlsx', index_col=0) \n",
    "\n",
    "merged_df = pd.concat([P4_part1, P4_part2], ignore_index=True)\n",
    "\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "812fb652-2ad6-40f4-9955-bdd0c3aaa2c3",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "We now construct $\\tilde{P}_{6}$ from $\\tilde{P}_{5}$ in parts (take about 4hrs). First we load $\\tilde{P}_{5}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e69e520-3348-4cd9-8b15-adc3f8fc81ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part builder cell for P5 to P6 #At this rate it will take 1.43hrs<time<6hrs to run this calculation\n",
    "n=5\n",
    "power_set_str,power_set_str_np1=get_n_np1_powersets(n)\n",
    "df=P5 #Total dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0acd366b-7cfb-4a76-af17-294f1d7d9c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start_perf,start_process = time.perf_counter(),time.process_time()\n",
    "# Pnp1_from_Pn_part(df,n,0,100)\n",
    "# end_perf,end_process = time.perf_counter(),time.process_time()\n",
    "\n",
    "# print(f\"Perf timer {end_perf-start_perf}\") #This method returns the time in seconds.\n",
    "# print(f\"Process timer {end_process-start_process}\") #measures the time the process takes, including time that the process is blocked"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41818c17-2c4e-4e32-ae46-9030396f029f",
   "metadata": {},
   "source": [
    "The following cells considers$100$ functions in $\\tilde{P}_{5}$ and determines the set of extensions $f=g+\\epsilon_{I}$ for $I \\in \\mathbb{E}(g)$. This process constructs a series of 101 xlxs files, which store dataframes of which the union is  $\\tilde{P}_{6}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fed5a9b-a41d-4272-98c0-1ec7180b9b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def runner(start,end): \n",
    "    start_perf,start_process = time.perf_counter(),time.process_time()\n",
    "    Pnp1_from_Pn_part(df,n,start,end)\n",
    "    end_perf,end_process = time.perf_counter(),time.process_time()\n",
    "\n",
    "    print(f\"Perf timer {end_perf-start_perf}\") #This method returns the time in seconds.\n",
    "    print(f\"Process timer {end_process-start_process}\") #measures the time the process takes, including time that the process is blocked\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad84ca6d-1e2b-47da-9c7f-7f92a452077a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in range(0, 10300, 100):\n",
    "    start=i\n",
    "    end=start+100\n",
    "    runner(start,end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7791920b-6a0e-459e-9247-e51d24747d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_start=10300\n",
    "calc_end=10334\n",
    "\n",
    "rows=range(calc_start,calc_end) #What functions we are extending\n",
    "Pn=df.iloc[rows] #takes database of rows 0,1..,calc_up_to\n",
    "\n",
    "part_Pn=get_Pnp1_for_single_funct(Pn,n) #Extensions of Pn\n",
    "strt=f\"P6_parts\\{calc_start}_{calc_end}_Part_fromP5.xlsx\"\n",
    "part_Pn.to_excel(strt) #Stores in excel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923217ce-f605-4380-9c2d-ada764ea8e79",
   "metadata": {},
   "source": [
    "To obtain $p_{6}=\\boldsymbol{e}_{5} \\cdot \\boldsymbol{d}_{5}$ we load the files in P6\\_parts and record $\\boldsymbol{e}_{5}$ and $\\boldsymbol{d}_{5}$ (we can find $p_{6}$ by sum of the sizes of dataframes)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40fde0ce-d698-45f4-921f-2e0f60831971",
   "metadata": {},
   "source": [
    "The following loads the data for the parts of $\\tilde{P}_6$ stored in files (takes about 1.5hrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84fcbd31-ff13-4285-b070-fd0cca060f38",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Store number of rows for each data packet of P6\n",
    "P6_size_list=[]\n",
    "Eg_numb_functs_init_counter=[]\n",
    "\n",
    "#Main Body of calculations\n",
    "for i in range(0, 10300, 100):\n",
    "    #Stores number for this packet in P6_size_list\n",
    "    start=i\n",
    "    end=start+100\n",
    "    P6_part=pd.read_excel(f'P6_parts/{start}_{end}_Part_fromP5.xlsx', index_col=0)\n",
    "    print(f'P6_parts/{start}_{end}_Part_fromP5.xlsx')\n",
    "    row_numb=P6_part.shape[0]\n",
    "    P6_size_list.append(row_numb)\n",
    "\n",
    "    # In this packet gets Eg_Size and get counter for eg sizes and number of functions in Eg_numb_functs_init_counter\n",
    "    values = P6_part['Eg_Size'].value_counts(ascending=True).keys().tolist()\n",
    "    counts = P6_part['Eg_Size'].value_counts(ascending=True).tolist()\n",
    "    zipped=list(zip(values,counts))\n",
    "    Eg_numb_functs_init_counter.extend(zipped)\n",
    "    \n",
    "# It remains to do 10300-10334\n",
    "#Stores number for this packet in P6_size_list\n",
    "start,end=(10300,10334)\n",
    "P6_part=pd.read_excel(f'P6_parts/{start}_{end}_Part_fromP5.xlsx', index_col=0)\n",
    "print(f'P6_parts/{start}_{end}_Part_fromP5.xlsx')\n",
    "row_numb=P6_part.shape[0]\n",
    "P6_size_list.append(row_numb)\n",
    "\n",
    "# In this packet gets Eg_Size and get counter for eg sizes and number of functions in Eg_numb_functs_init_counter\n",
    "values = P6_part['Eg_Size'].value_counts(ascending=True).keys().tolist()\n",
    "counts = P6_part['Eg_Size'].value_counts(ascending=True).tolist()\n",
    "zipped=list(zip(values,counts))\n",
    "Eg_numb_functs_init_counter.extend(zipped)\n",
    "\n",
    "#output-------------------------------------------------------------------------\n",
    "\n",
    "#Final answer\n",
    "P6_size=sum(P6_size_list)\n",
    "print(f\"There are {P6_size} functions in P6 \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14929769-bd31-411b-9b13-44e6df7ef766",
   "metadata": {
    "tags": []
   },
   "source": [
    "With Eg\\_numb\\_functs\\_init\\_counter we record terms $(x,y(x))$ where $x=|\\mathbb{E}(g)|$ and $y(x)$ is the sum of terms $x$, and therefore counts the number of time $x$ appears in a specific P6\\_part. Let $Y(x)$ denote the number of times $x$ that appears in all files P6\\_part i.e the sum of the $y(x)$ terms divided by $x$. As a consequence we have $\\boldsymbol{e}_{5}$ consisting of the $x$ terms and $\\boldsymbol{d}_{5}$ consisting of the $Y(x)$ terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538f4675-80f2-4c83-bd79-e8e74cd9597d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#He now obtain Eg_numb_functs from Eg_numb_functs_init_counter\n",
    "\n",
    "# This is a List of tuples where have  joined e.g (13, 6),(13, 19) to (13, 25) from Eg_numb_functs_init_counter\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "sums = defaultdict(int)\n",
    "\n",
    "for first, second in Eg_numb_functs_init_counter:\n",
    "    sums[first] += second\n",
    "\n",
    "Eg_numb_functs = [(first, second) for first, second in sums.items()]\n",
    "Eg_numb_functs = sorted(Eg_numb_functs, key=lambda x: x[0])#order so in increasing with respect to eg size\n",
    "\n",
    "#Build a string using a for loop, using the tuples in Eg_numb_functs\n",
    "f1,f2=Eg_numb_functs[0]\n",
    "\n",
    "f2_div=int(f2/f1)\n",
    "\n",
    "stringer=f'{f1}*{f2_div}'\n",
    "\n",
    "for item in Eg_numb_functs[1:]: #first item in stringer already\n",
    "    eg,numb=item #eg,numb not all the same\n",
    "    num_div=int(numb/eg)\n",
    "    s=f'+{eg}*{num_div}'\n",
    "    stringer += s\n",
    "    \n",
    "#Output\n",
    "print(f\"Which decomposes as follows:\\n {P6_size}={stringer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9539b3-a3bb-4ff7-982e-82777d3694ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check output calculates 5399325 #Yes\n",
    "s=114*125+121*65+126*237+138*112+158*248+162*247+165*132+169*117+173*132+178*122+182*106+183*132+187*24+192*134+194*123+208*144+209*22+216*234+217*126+218*61+221*125+227*22+229*307+230*250+232*120+233*119+236*122+241*30+242*102+247*61+248*53+250*114+251*59+260*184+268*106+269*64+271*186+273*118+274*56+278*52+279*41+281*136+284*112+289*67+293*133+294*37+300*133+305*67+313*123+324*123+325*132+326*101+329*181+338*120+343*59+345*113+356*19+381*121+390*44+397*107+419*20+420*46+421*23+422*39+429*64+433*35+436*128+437*23+455*64+477*53+496*48+502*16+509*38+518*12+520*107+524*20+531*36+538*76+539*62+553*36+555*66+566*144+578*61+605*62+607*66+613*11+640*28+659*30+759*48+765*21+781*108+802*119+814*42+881*42+938*8+974*135+977*45+983*135+1002*45+1026*126+1029*63+1033*63+1068*96+1121*108+1145*22+1178*39+1189*39+1209*44+1212*11+1224*66+1257*44+1312*11+1322*32+1377*36+1409*16+1421*10+1450*54+1511*20+1666*21+1753*24+2110*42+2193*95+2285*4+2290*54+3544*12+3673*42+3820*48+3983*18+6280*1+6474*6+6702*14+6960*16+7250*9+7580*4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc3ba87-2cb3-4c69-b9b7-cbba9a7783fb",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Upper bound for $|\\tilde{P}_{n}|$ <a name=\"s4\"></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d5f4053-c41c-4460-a179-f57739e5c7a1",
   "metadata": {},
   "source": [
    "Recall Section $5.2$ of the thesis. In particular we have the sequences $\\mathcal{U}=(U_n)$ and $\\mathcal{L}=(L_n)$ where $U_n$ are defined by the maximal term of $\\boldsymbol{e}_n$. In a Conjecture in that section we ask, which $f \\in \\tilde{P}_{n-1}$ attain $U_n$. Let $g \\in \\tilde{P}_{n-1}$ be such that $g(I)=0$ for all $I \\in \\mathcal{P}_{n-1}^{+}$. We conjecture that $f=g+\\epsilon_{I} \\in  \\mathcal{P}_{n}^{+}$ attains $|\\mathbb{E}(f)|=U_n$ if $I=\\emptyset$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361957b6-92b3-41d9-a103-6722799dbe6a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## $U_n$ <a name=\"s41\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdfb5b3a-1aa0-4ac8-8f08-6cb0ef80be4a",
   "metadata": {},
   "source": [
    "Let $g \\in \\tilde{P}_{n-1}$ be such that $g(I)=0$ for all $I \\in \\mathcal{P}_{n-1}^{+}$ and let $f_{U_n},=g+\\epsilon_{I} \\in  \\mathcal{P}_{n}^{+}$ such that $I=\\emptyset$. We will now show that $f_{U_n}$ attains $|\\mathbb{E}(f_{U_n})|=U_n$ for low $n$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c911a210-320c-41d9-a23c-aa810ee87725",
   "metadata": {
    "tags": []
   },
   "source": [
    "### $U_3$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2050643e-ef5e-44e3-a032-c8315d471257",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_u2={'1': 0, '2': 0, '12': 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5da96421-d394-4367-9c9b-5984fdc8f533",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_f_u2=pd.DataFrame([f_u2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a67065e3-2917-4f59-a47e-a21cdcd7448d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e_n : d_n\n",
      "5    1\n",
      "Name: Eg_Size, dtype: int64\n",
      "CPU times: total: 0 ns\n",
      "Wall time: 8.02 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "power_set_str=get_powerset_str(2)\n",
    "df_f_u2_eg=get_Eg_column_Pn(df_f_u2)\n",
    "df_f_u2_eg=df_f_u2_eg.sort_values('Eg_Size') \n",
    "df=df_f_u2_eg\n",
    "print(f\"e_n : d_n\")\n",
    "print(df['Eg_Size'].value_counts()) #count number of 13s and 19s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35839e81-6fb1-4090-9f1a-84112196d4ce",
   "metadata": {
    "tags": []
   },
   "source": [
    "### $U_4$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "83c42e5c-7d94-4cd7-8599-e9a963760c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_u3={'1': 0, '2': 0, '12': 0,'3':0,'13':0,'23':0,'123':0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2c900fb6-2657-4e47-8913-a37b20c4b9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_f_u3=pd.DataFrame([f_u3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0ff5f3da-ffc4-4806-a6a6-e4378949047d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e_n : d_n\n",
      "19    1\n",
      "Name: Eg_Size, dtype: int64\n",
      "CPU times: total: 0 ns\n",
      "Wall time: 16.6 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "power_set_str=get_powerset_str(3)\n",
    "df_f_u3_eg=get_Eg_column_Pn(df_f_u3)\n",
    "df_f_u3_eg=df_f_u3_eg.sort_values('Eg_Size') # get those 13,then 19\n",
    "df=df_f_u3_eg\n",
    "print(f\"e_n : d_n\")\n",
    "print(df['Eg_Size'].value_counts()) #count number of 13s and 19s\n",
    "# e_n : d_n\n",
    "# 19    1\n",
    "# Name: Eg_Size, dtype: int64\n",
    "# CPU times: total: 0 ns\n",
    "# Wall time: 8.4 ms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc98be4-dbe9-42fe-9c36-2c147dbded7f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### $U_5$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "72a21259-7271-4056-a29d-ec82c0544391",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_u4={'1': 0,'2': 0,'3': 0,'4': 0,'12': 0,'13': 0,'14': 0,'23': 0,'24': 0,'34': 0,'123': 0,'124': 0,'134': 0,'234': 0,'1234': 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e0af316f-9c0b-40ae-a176-c3c9e1640a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_f_u4=pd.DataFrame([f_u4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d49c560c-d307-47df-9916-594d0cb6de5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e_n : d_n\n",
      "167    1\n",
      "Name: Eg_Size, dtype: int64\n",
      "CPU times: total: 31.2 ms\n",
      "Wall time: 45.7 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "power_set_str=get_powerset_str(4)\n",
    "df_f_u4_eg=get_Eg_column_Pn(df_f_u4)\n",
    "df_f_u4_eg=df_f_u4_eg.sort_values('Eg_Size') # get those 13,then 19\n",
    "df=df_f_u4_eg\n",
    "print(f\"e_n : d_n\")\n",
    "print(df['Eg_Size'].value_counts()) #count number of 13s and 19s\n",
    "# e_n : d_n\n",
    "# 167    1\n",
    "# Name: Eg_Size, dtype: int64\n",
    "# CPU times: total: 31.2 ms\n",
    "# Wall time: 45.7 ms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89074c00-f416-4813-9b9c-c42e6bd520c4",
   "metadata": {
    "tags": []
   },
   "source": [
    "### $U_6$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e20c1fe4-0acd-4d18-bbca-aa5021952a40",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "f_u5={'1': 0,'2': 0,'3': 0,'4': 0,'5': 0,'12': 0,'13': 0,'14': 0,'15': 0,'23': 0,'24': 0,'25': 0,'34': 0,'35': 0,'45': 0,'123': 0,'124': 0,'125': 0,'134': 0,'135': 0,'145': 0,'234': 0,'235': 0,'245': 0,'345': 0,'1234': 0,'1235': 0,'1245': 0,'1345': 0,'2345': 0,'12345': 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e407b647-da0a-405e-b00a-1501b661e2e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_f_u5=pd.DataFrame([f_u5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "88e556ef-b5d6-40da-b6dc-6c305571d83d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e_n : d_n\n",
      "7580    1\n",
      "Name: Eg_Size, dtype: int64\n",
      "CPU times: total: 1.83 s\n",
      "Wall time: 3.32 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "power_set_str=get_powerset_str(5)\n",
    "df_f_u5_eg=get_Eg_column_Pn(df_f_u5)\n",
    "df_f_u5_eg=df_f_u5_eg.sort_values('Eg_Size') # get those 13,then 19\n",
    "df=df_f_u5_eg\n",
    "print(f\"e_n : d_n\")\n",
    "print(df['Eg_Size'].value_counts()) #count number of 13s and 19s\n",
    "# 7580    1\n",
    "# Name: Eg_Size, dtype: int64\n",
    "# CPU times: total: 938 ms\n",
    "# Wall time: 3.18 s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71bf21a2-02c6-45ab-9040-94ba66327d7e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### $U_7$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "fc2cbfb7-189d-49a9-9edb-249f2ba477ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "n=6\n",
    "power_set_str=get_powerset_str(n)\n",
    "f_u6 = {}\n",
    "for key in power_set_str:\n",
    "    f_u6[key] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1c99c37a-265e-4c01-b261-6b4636e15f97",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_f_u6=pd.DataFrame([f_u6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2b608e-593f-4e7b-b0aa-a7378e2f54db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "power_set_str=get_powerset_str(6)\n",
    "df_f_u6_eg=get_Eg_column_Pn(df_f_u6)\n",
    "df_f_u6_eg=df_f_u6_eg.sort_values('Eg_Size') # get those 13,then 19\n",
    "df=df_f_u6_eg\n",
    "print(f\"e_n : d_n\")\n",
    "print(df['Eg_Size'].value_counts()) #count number of 13s and 19s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51937baa-20d3-47bd-b7d9-4184e1ff3d6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e6d6a91c-45d7-49af-82d7-7445a10a9299",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "# Leftovers (Please ignore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "9e0e2b18-c838-46fa-b4f2-07b51fabd4f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42, 31)"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# P5.shape\n",
    "# df=P5\n",
    "# # f_l4={'1': 0, '2': 0, '3':0,\n",
    "# #       '12': 1,'13':0,'23':0,'14': 1,'24': 1,'34': 1,\n",
    "# #       '123':1,'124': 2,'134': 1,'234': 1,'1234': 2}\n",
    "\n",
    "# condition = (df['1'] == 0) & (df['2'] == 0) & (df['3'] == 0) & (df['4'] == 0) & (df['12'] == 1) & (df['13'] == 0) & (df['23'] == 0) & (df['14'] == 1) & (df['24'] == 1) & (df['34'] == 1) & (df['123'] == 1) & (df['124'] == 2) & (df['134'] == 1)& (df['234'] == 1) & (df['1234'] == 2)\n",
    "# # condition=df[df['Eg_size']==114]\n",
    "# # min_df = df[df['Eg_Size'] == 13]\n",
    "\n",
    "# result_df = df[condition]\n",
    "\n",
    "# result_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d6ca2a-c1a4-49b6-8276-a6cd9b424028",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "min_df = df[df['Eg_Size'] == 42]\n",
    "min_df\n",
    "# min_df.shape#(24, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60bb680-1adf-42f2-80e3-b9e3269dbd13",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "column_to_remove = 'Eg_Size'\n",
    "min_df_42 = min_df.drop(column_to_remove, axis=1)\n",
    "min_df_42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "41ccb6aa-d922-46e3-85e1-4aa2f54cde19",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "l_min_df_42=min_df_42.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "1edc496e-e862-459c-aa30-8be40965575f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1': 0, '2': 0, '3': 0, '4': 0, '12': 1, '13': 1, '14': 1, '23': 0, '24': 1, '34': 0, '123': 1, '124': 2, '134': 1, '234': 1, '1234': 2, '5': 0, '15': 1, '25': 1, '35': 1, '45': 1, '125': 2, '135': 2, '145': 2, '235': 1, '245': 2, '345': 1, '1235': 2, '1245': 3, '1345': 2, '2345': 2, '12345': 3}\n",
      "e_n : d_n\n",
      "251    1\n",
      "Name: Eg_Size, dtype: int64\n",
      "{'1': 0, '2': 0, '3': 0, '4': 0, '12': 0, '13': 1, '14': 1, '23': 1, '24': 0, '34': 1, '123': 1, '124': 1, '134': 2, '234': 1, '1234': 2, '5': 0, '15': 1, '25': 1, '35': 1, '45': 1, '125': 1, '135': 2, '145': 2, '235': 2, '245': 1, '345': 2, '1235': 2, '1245': 2, '1345': 3, '2345': 2, '12345': 3}\n",
      "e_n : d_n\n",
      "251    1\n",
      "Name: Eg_Size, dtype: int64\n",
      "{'1': 0, '2': 0, '3': 0, '4': 0, '12': 1, '13': 0, '14': 1, '23': 0, '24': 0, '34': 0, '123': 1, '124': 1, '134': 1, '234': 0, '1234': 1, '5': 0, '15': 1, '25': 1, '35': 1, '45': 1, '125': 2, '135': 1, '145': 2, '235': 1, '245': 1, '345': 1, '1235': 2, '1245': 2, '1345': 2, '2345': 1, '12345': 2}\n",
      "e_n : d_n\n",
      "169    1\n",
      "Name: Eg_Size, dtype: int64\n",
      "{'1': 0, '2': 0, '3': 0, '4': 0, '12': 0, '13': 1, '14': 0, '23': 1, '24': 0, '34': 0, '123': 1, '124': 0, '134': 1, '234': 1, '1234': 1, '5': 0, '15': 1, '25': 1, '35': 1, '45': 1, '125': 1, '135': 2, '145': 1, '235': 2, '245': 1, '345': 1, '1235': 2, '1245': 1, '1345': 2, '2345': 2, '12345': 2}\n",
      "e_n : d_n\n",
      "169    1\n",
      "Name: Eg_Size, dtype: int64\n",
      "{'1': 0, '2': 0, '3': 0, '4': 0, '12': 0, '13': 0, '14': 0, '23': 1, '24': 1, '34': 0, '123': 1, '124': 1, '134': 0, '234': 1, '1234': 1, '5': 0, '15': 1, '25': 1, '35': 1, '45': 1, '125': 1, '135': 1, '145': 1, '235': 2, '245': 2, '345': 1, '1235': 2, '1245': 2, '1345': 1, '2345': 2, '12345': 2}\n",
      "e_n : d_n\n",
      "169    1\n",
      "Name: Eg_Size, dtype: int64\n",
      "{'1': 0, '2': 0, '3': 0, '4': 0, '12': 0, '13': 0, '14': 1, '23': 1, '24': 1, '34': 1, '123': 1, '124': 1, '134': 1, '234': 2, '1234': 2, '5': 0, '15': 1, '25': 1, '35': 1, '45': 1, '125': 1, '135': 1, '145': 2, '235': 2, '245': 2, '345': 2, '1235': 2, '1245': 2, '1345': 2, '2345': 3, '12345': 3}\n",
      "e_n : d_n\n",
      "251    1\n",
      "Name: Eg_Size, dtype: int64\n",
      "{'1': 0, '2': 0, '3': 0, '4': 0, '12': 1, '13': 1, '14': 0, '23': 1, '24': 1, '34': 0, '123': 2, '124': 1, '134': 1, '234': 1, '1234': 2, '5': 0, '15': 1, '25': 1, '35': 1, '45': 1, '125': 2, '135': 2, '145': 1, '235': 2, '245': 2, '345': 1, '1235': 3, '1245': 2, '1345': 2, '2345': 2, '12345': 3}\n",
      "e_n : d_n\n",
      "251    1\n",
      "Name: Eg_Size, dtype: int64\n",
      "{'1': 0, '2': 0, '3': 0, '4': 0, '12': 0, '13': 0, '14': 0, '23': 1, '24': 0, '34': 1, '123': 1, '124': 0, '134': 1, '234': 1, '1234': 1, '5': 0, '15': 1, '25': 1, '35': 1, '45': 1, '125': 1, '135': 1, '145': 1, '235': 2, '245': 1, '345': 2, '1235': 2, '1245': 1, '1345': 2, '2345': 2, '12345': 2}\n",
      "e_n : d_n\n",
      "169    1\n",
      "Name: Eg_Size, dtype: int64\n",
      "{'1': 0, '2': 0, '3': 0, '4': 0, '12': 1, '13': 0, '14': 1, '23': 0, '24': 1, '34': 1, '123': 1, '124': 2, '134': 1, '234': 1, '1234': 2, '5': 0, '15': 1, '25': 1, '35': 1, '45': 1, '125': 2, '135': 1, '145': 2, '235': 1, '245': 2, '345': 2, '1235': 2, '1245': 3, '1345': 2, '2345': 2, '12345': 3}\n",
      "e_n : d_n\n",
      "251    1\n",
      "Name: Eg_Size, dtype: int64\n",
      "{'1': 0, '2': 0, '3': 0, '4': 0, '12': 1, '13': 1, '14': 0, '23': 0, '24': 0, '34': 0, '123': 1, '124': 1, '134': 1, '234': 0, '1234': 1, '5': 0, '15': 1, '25': 1, '35': 1, '45': 1, '125': 2, '135': 2, '145': 1, '235': 1, '245': 1, '345': 1, '1235': 2, '1245': 2, '1345': 2, '2345': 1, '12345': 2}\n",
      "e_n : d_n\n",
      "169    1\n",
      "Name: Eg_Size, dtype: int64\n",
      "{'1': 0, '2': 0, '3': 0, '4': 0, '12': 1, '13': 1, '14': 1, '23': 1, '24': 0, '34': 0, '123': 2, '124': 1, '134': 1, '234': 1, '1234': 2, '5': 0, '15': 1, '25': 1, '35': 1, '45': 1, '125': 2, '135': 2, '145': 2, '235': 2, '245': 1, '345': 1, '1235': 3, '1245': 2, '1345': 2, '2345': 2, '12345': 3}\n",
      "e_n : d_n\n",
      "251    1\n",
      "Name: Eg_Size, dtype: int64\n",
      "{'1': 0, '2': 0, '3': 0, '4': 0, '12': 1, '13': 0, '14': 0, '23': 1, '24': 0, '34': 0, '123': 1, '124': 1, '134': 0, '234': 1, '1234': 1, '5': 0, '15': 1, '25': 1, '35': 1, '45': 1, '125': 2, '135': 1, '145': 1, '235': 2, '245': 1, '345': 1, '1235': 2, '1245': 2, '1345': 1, '2345': 2, '12345': 2}\n",
      "e_n : d_n\n",
      "169    1\n",
      "Name: Eg_Size, dtype: int64\n",
      "{'1': 0, '2': 0, '3': 0, '4': 0, '12': 0, '13': 0, '14': 0, '23': 0, '24': 1, '34': 1, '123': 0, '124': 1, '134': 1, '234': 1, '1234': 1, '5': 0, '15': 1, '25': 1, '35': 1, '45': 1, '125': 1, '135': 1, '145': 1, '235': 1, '245': 2, '345': 2, '1235': 1, '1245': 2, '1345': 2, '2345': 2, '12345': 2}\n",
      "e_n : d_n\n",
      "169    1\n",
      "Name: Eg_Size, dtype: int64\n",
      "{'1': 0, '2': 0, '3': 0, '4': 0, '12': 1, '13': 1, '14': 0, '23': 1, '24': 0, '34': 1, '123': 2, '124': 1, '134': 1, '234': 1, '1234': 2, '5': 0, '15': 1, '25': 1, '35': 1, '45': 1, '125': 2, '135': 2, '145': 1, '235': 2, '245': 1, '345': 2, '1235': 3, '1245': 2, '1345': 2, '2345': 2, '12345': 3}\n",
      "e_n : d_n\n",
      "251    1\n",
      "Name: Eg_Size, dtype: int64\n",
      "{'1': 0, '2': 0, '3': 0, '4': 0, '12': 0, '13': 0, '14': 1, '23': 0, '24': 0, '34': 1, '123': 0, '124': 1, '134': 1, '234': 1, '1234': 1, '5': 0, '15': 1, '25': 1, '35': 1, '45': 1, '125': 1, '135': 1, '145': 2, '235': 1, '245': 1, '345': 2, '1235': 1, '1245': 2, '1345': 2, '2345': 2, '12345': 2}\n",
      "e_n : d_n\n",
      "169    1\n",
      "Name: Eg_Size, dtype: int64\n",
      "{'1': 0, '2': 0, '3': 0, '4': 0, '12': 1, '13': 1, '14': 1, '23': 0, '24': 0, '34': 1, '123': 1, '124': 1, '134': 2, '234': 1, '1234': 2, '5': 0, '15': 1, '25': 1, '35': 1, '45': 1, '125': 2, '135': 2, '145': 2, '235': 1, '245': 1, '345': 2, '1235': 2, '1245': 2, '1345': 3, '2345': 2, '12345': 3}\n",
      "e_n : d_n\n",
      "251    1\n",
      "Name: Eg_Size, dtype: int64\n",
      "{'1': 0, '2': 0, '3': 0, '4': 0, '12': 0, '13': 1, '14': 0, '23': 1, '24': 1, '34': 1, '123': 1, '124': 1, '134': 1, '234': 2, '1234': 2, '5': 0, '15': 1, '25': 1, '35': 1, '45': 1, '125': 1, '135': 2, '145': 1, '235': 2, '245': 2, '345': 2, '1235': 2, '1245': 2, '1345': 2, '2345': 3, '12345': 3}\n",
      "e_n : d_n\n",
      "251    1\n",
      "Name: Eg_Size, dtype: int64\n",
      "{'1': 0, '2': 0, '3': 0, '4': 0, '12': 1, '13': 0, '14': 1, '23': 1, '24': 1, '34': 0, '123': 1, '124': 2, '134': 1, '234': 1, '1234': 2, '5': 0, '15': 1, '25': 1, '35': 1, '45': 1, '125': 2, '135': 1, '145': 2, '235': 2, '245': 2, '345': 1, '1235': 2, '1245': 3, '1345': 2, '2345': 2, '12345': 3}\n",
      "e_n : d_n\n",
      "251    1\n",
      "Name: Eg_Size, dtype: int64\n",
      "{'1': 0, '2': 0, '3': 0, '4': 0, '12': 0, '13': 0, '14': 1, '23': 0, '24': 1, '34': 0, '123': 0, '124': 1, '134': 1, '234': 1, '1234': 1, '5': 0, '15': 1, '25': 1, '35': 1, '45': 1, '125': 1, '135': 1, '145': 2, '235': 1, '245': 2, '345': 1, '1235': 1, '1245': 2, '1345': 2, '2345': 2, '12345': 2}\n",
      "e_n : d_n\n",
      "169    1\n",
      "Name: Eg_Size, dtype: int64\n",
      "{'1': 0, '2': 0, '3': 0, '4': 0, '12': 1, '13': 0, '14': 0, '23': 0, '24': 1, '34': 0, '123': 1, '124': 1, '134': 0, '234': 1, '1234': 1, '5': 0, '15': 1, '25': 1, '35': 1, '45': 1, '125': 2, '135': 1, '145': 1, '235': 1, '245': 2, '345': 1, '1235': 2, '1245': 2, '1345': 1, '2345': 2, '12345': 2}\n",
      "e_n : d_n\n",
      "169    1\n",
      "Name: Eg_Size, dtype: int64\n",
      "{'1': 0, '2': 0, '3': 0, '4': 0, '12': 1, '13': 0, '14': 0, '23': 1, '24': 1, '34': 1, '123': 1, '124': 1, '134': 1, '234': 2, '1234': 2, '5': 0, '15': 1, '25': 1, '35': 1, '45': 1, '125': 2, '135': 1, '145': 1, '235': 2, '245': 2, '345': 2, '1235': 2, '1245': 2, '1345': 2, '2345': 3, '12345': 3}\n",
      "e_n : d_n\n",
      "251    1\n",
      "Name: Eg_Size, dtype: int64\n",
      "{'1': 0, '2': 0, '3': 0, '4': 0, '12': 0, '13': 1, '14': 1, '23': 0, '24': 0, '34': 0, '123': 1, '124': 1, '134': 1, '234': 0, '1234': 1, '5': 0, '15': 1, '25': 1, '35': 1, '45': 1, '125': 1, '135': 2, '145': 2, '235': 1, '245': 1, '345': 1, '1235': 2, '1245': 2, '1345': 2, '2345': 1, '12345': 2}\n",
      "e_n : d_n\n",
      "169    1\n",
      "Name: Eg_Size, dtype: int64\n",
      "{'1': 0, '2': 0, '3': 0, '4': 0, '12': 0, '13': 1, '14': 0, '23': 0, '24': 0, '34': 1, '123': 1, '124': 0, '134': 1, '234': 1, '1234': 1, '5': 0, '15': 1, '25': 1, '35': 1, '45': 1, '125': 1, '135': 2, '145': 1, '235': 1, '245': 1, '345': 2, '1235': 2, '1245': 1, '1345': 2, '2345': 2, '12345': 2}\n",
      "e_n : d_n\n",
      "169    1\n",
      "Name: Eg_Size, dtype: int64\n",
      "{'1': 0, '2': 0, '3': 0, '4': 0, '12': 0, '13': 1, '14': 1, '23': 0, '24': 1, '34': 1, '123': 1, '124': 1, '134': 2, '234': 1, '1234': 2, '5': 0, '15': 1, '25': 1, '35': 1, '45': 1, '125': 1, '135': 2, '145': 2, '235': 1, '245': 2, '345': 2, '1235': 2, '1245': 2, '1345': 3, '2345': 2, '12345': 3}\n",
      "e_n : d_n\n",
      "251    1\n",
      "Name: Eg_Size, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "power_set_str=get_powerset_str(5)\n",
    "\n",
    "for funct in l_min_df_42:\n",
    "    \n",
    "    for term in power_set_str:\n",
    "        if '5' in term:\n",
    "            if term=='5':\n",
    "                funct[term]=0 #extend by empty\n",
    "                continue\n",
    "            x_list = list(term)\n",
    "            x_list.remove('5')\n",
    "            # Convert the list back to a string\n",
    "            without = ''.join(x_list)\n",
    "            \n",
    "            funct[term]=funct[without]+1?? #extend by empty\n",
    "    \n",
    "    f_l5=funct\n",
    "    df_f_l5=pd.DataFrame([f_l5])\n",
    "    df_f_l5_eg=get_Eg_column_Pn(df_f_l5)\n",
    "    df_f_l5_eg=df_f_l5_eg.sort_values('Eg_Size') # get those 13,then 19\n",
    "    df=df_f_l5_eg\n",
    "    print(f_l5)\n",
    "    print(f\"e_n : d_n\")\n",
    "    print(df['Eg_Size'].value_counts()) #count number of 13s and 19s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dfec087-cc9b-4d05-9fc9-f5cb154bfbdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60765644-90bd-44c2-b45a-37919d4f7f65",
   "metadata": {
    "tags": []
   },
   "source": [
    "## $L_n$ <a name=\"s42\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f69565b-15a4-440c-b050-8349aa6f84b9",
   "metadata": {},
   "source": [
    "Let $g \\in \\tilde{P}_{n-1}$ be such that $g:=f_{L_{n-1}}$ and let $f_{L_n}=g+\\epsilon_{I} \\in  \\mathcal{P}_{n}^{+}$ such that $I=\\mathcal{P}_{n-1}^{+}$ (if $n$ is even) or $I=\\emptyset$ if $n$ is odd. We will now show that $f_{L_n}$ attains $|\\mathbb{E}(f_{L_n})|=L_n$ for low $n$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c6e5b5-4267-494c-808e-a224089ec90b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### $L_2$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53981fde-c239-466f-bbe6-d4c5af2a5190",
   "metadata": {},
   "source": [
    "Consider the function $f_{L_2}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "95a6a1f2-6c4f-4113-83fa-176171b50860",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_l2={'1': 0, '2': 0, '12': 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "3698965e-8b0c-4273-9797-de41d873ed4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_f_l2=pd.DataFrame([f_l2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c322b031-11fc-423e-992e-8bc5bbad3e54",
   "metadata": {},
   "source": [
    "We determine the number of extensions of $f_{L_2}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "22f8c2c6-56dd-4701-98e6-035689bc1016",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Term in powerset: 1\n",
      "Eg size: 3\n",
      "Eg size: 4\n",
      "Term in powerset: 2\n",
      "Eg size: 4\n",
      "Eg size: 4\n",
      "Term in powerset: 12\n",
      "e_n : d_n\n",
      "5    1\n",
      "Name: Eg_Size, dtype: int64\n",
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "power_set_str=get_powerset_str(2)\n",
    "df_f_l2_eg=get_Eg_column_Pn(df_f_l2)\n",
    "df_f_l2_eg=df_f_l2_eg.sort_values('Eg_Size') \n",
    "\n",
    "df=df_f_l2_eg\n",
    "print(f\"e_n : d_n\")\n",
    "print(df['Eg_Size'].value_counts()) #count number of 13s and 19s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499eca00-51ad-426c-9b8c-a74c695fe46d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### $L_3$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0004cd43-4679-41a4-b16e-960034765fd4",
   "metadata": {},
   "source": [
    "Consider the function $f_{L_3}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "3a49a16b-22b7-4c4a-a0af-5365b56eff58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# f_l3={'1': 0, '2': 0, '12': 0,'3':0,'13':1,'23':1,'123':1}\n",
    "\n",
    "f_l3={'1': 0, '2': 0, '12': 1,'3':0,'13':0,'23':0,'123':1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "a1a70f79-5993-4cdc-88ea-8e5f3dfc1e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_f_l3=pd.DataFrame([f_l3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d20f4f97-702e-49ba-8ab4-68c1c269feff",
   "metadata": {},
   "source": [
    "We determine the number of extensions of $f_{L_3}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "8c21b18d-70c3-49f8-8ba5-3f917fabb8e6",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Term in powerset: 1\n",
      "Eg size: 8\n",
      "Eg size: 8\n",
      "Eg size: 8\n",
      "Eg size: 9\n",
      "Eg size: 9\n",
      "Term in powerset: 2\n",
      "Eg size: 10\n",
      "Eg size: 10\n",
      "Eg size: 10\n",
      "Eg size: 10\n",
      "Eg size: 10\n",
      "Term in powerset: 3\n",
      "Eg size: 11\n",
      "Term in powerset: 12\n",
      "Eg size: 11\n",
      "Term in powerset: 13\n",
      "Eg size: 11\n",
      "Eg size: 11\n",
      "Eg size: 11\n",
      "Eg size: 11\n",
      "Eg size: 11\n",
      "Eg size: 11\n",
      "Term in powerset: 23\n",
      "Eg size: 12\n",
      "Eg size: 12\n",
      "Eg size: 12\n",
      "Eg size: 12\n",
      "Eg size: 12\n",
      "Eg size: 12\n",
      "Term in powerset: 123\n",
      "Eg size: 12\n",
      "Eg size: 12\n",
      "e_n : d_n\n",
      "13    1\n",
      "Name: Eg_Size, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "power_set_str=get_powerset_str(3)\n",
    "df_f_l3_eg=get_Eg_column_Pn(df_f_l3)\n",
    "df_f_l3_eg=df_f_l3_eg.sort_values('Eg_Size') # get those 13,then 19\n",
    "df=df_f_l3_eg\n",
    "print(f\"e_n : d_n\")\n",
    "print(df['Eg_Size'].value_counts()) #count number of 13s and 19s\n",
    "\n",
    "# e_n : d_n\n",
    "# 13    1\n",
    "# Name: Eg_Size, dtype: int64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed0be2b7-301d-433e-b5f1-95b71b320979",
   "metadata": {
    "tags": []
   },
   "source": [
    "### $L_4$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd922f78-1cb0-4874-a4e0-784edd43b267",
   "metadata": {},
   "source": [
    "Consider the function $f_{L_4}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "15c70fad-6322-4e0e-9ab1-416ee4071cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# f_l3={'1': 0, '2': 0, '12': 1,'3':0,'13':0,'23':0,'123':1}\n",
    "# f_l4={'1': 0, '2': 0, '12': 1,'3':0,'13':0,'23':0,'123':1,'4': 0,'14': 1,'24': 1,'34': 1,'124': 2,'134': 1,'234': 1,'1234': 2}\n",
    "\n",
    "# f_l3={'1': 0, '2': 0, '12': 1,'3':0,'13':0,'23':0,'123':1}\n",
    "f_l4={'1': 0, '2': 0, '12': 1,'3':0,'13':0,'23':0,'123':1,'4': 0,'14': 1,'24': 1,'34': 1,'124': 2,'134': 1,'234': 1,'1234': 2}     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "98abdb39-de01-4f37-b2bc-a21d314e4895",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_f_l4=pd.DataFrame([f_l4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8c9898-b381-4bdd-8173-67bc7b401afc",
   "metadata": {},
   "source": [
    "We determine the number of extensions of $f_{L_4}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "b630ecaa-23cf-42cf-964c-58cb0ddf5f2e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e_n : d_n\n",
      "42    1\n",
      "Name: Eg_Size, dtype: int64\n",
      "CPU times: total: 31.2 ms\n",
      "Wall time: 74.7 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# df_f_l4=pd.DataFrame([f_l4])\n",
    "power_set_str=get_powerset_str(4)\n",
    "df_f_l4_eg=get_Eg_column_Pn(df_f_l4)\n",
    "df_f_l4_eg=df_f_l4_eg.sort_values('Eg_Size') # get those 13,then 19\n",
    "df=df_f_l4_eg\n",
    "\n",
    "print(f\"e_n : d_n\")\n",
    "print(df['Eg_Size'].value_counts()) #count number of 13s and 19s\n",
    "\n",
    "# e_n : d_n\n",
    "# 42    1\n",
    "# Name: Eg_Size, dtype: int64\n",
    "# CPU times: total: 62.5 ms\n",
    "# Wall time: 95.5 ms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8897f890-a1c5-4a7a-b69a-77b40a478f48",
   "metadata": {
    "tags": []
   },
   "source": [
    "### $L_{5}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed658833-49b1-43d2-af60-decf6f68b027",
   "metadata": {},
   "source": [
    "Consider the function $f_{L_5}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "6e18b82f-0dd7-41cc-8f8b-c9233c989056",
   "metadata": {},
   "outputs": [],
   "source": [
    "# f_l4={'1': 0, '2': 0, '12': 1,'3':0,'13':0,'23':0,'123':1,'4': 0,'14': 1,'24': 1,'34': 1,'124': 2,'134': 1,'234': 1,'1234': 2}  \n",
    "# f_l5={'1': 0, '2': 0, '3': 0, '4': 0, '5': 0,'12': 1,'13':0,'23':0,'123':1,'14': 1,'24': 1,'34': 1,'124': 2,'134': 1,'234': 1,'1234': 2,'15': 0, '25': 0, '35': 0, '45': 0,'125': 1,'135': 0, '145': 1,'235': 0,'245': 1,'345': 1,'1235': 1,'1245': 2,'1345': 1,'2345': 1, '12345': 2}\n",
    "\n",
    "# f_l4={'1': 0, '2': 0, '3':0,'12': 0,'13':1,'23':1,'123':1,'4': 0,'14': 0,'24': 0,'34': 0,'124': 0,'134': 1,'234': 1,'1234': 1}     \n",
    "# f_l5={'1': 0, '2': 0, '3':0,'12': 0,'13':1,'23':1,'123':1,'4': 0,'14': 0,'24': 0,'34': 0,'124': 0,'134': 1,'234': 1,'1234': 1, '5': 0,'15': 1, '25': 1, '35': 1, '45': 1,'125': 1,'135': 2, '145': 1,'235': 2,'245': 1,'345': 1,'1235': 2,'1245': 1,'1345': 2,'2345': 2, '12345': 2}\n",
    "\n",
    "#empty ext\n",
    "# f_l4={'1': 0, '2': 0, '12': 1,'3':0,'13':0,'23':0,'123':1,'4': 0,'14': 1,'24': 1,'34': 1,'124': 2,'134': 1,'234': 1,'1234': 2}     \n",
    "f_l5={'1': 0, '2': 0, '12': 1,'3':0,'13':0,'23':0,'123':1,'4': 0,'14': 1,'24': 1,'34': 1,'124': 2,'134': 1,'234': 1,'1234': 2, '5': 0,'15': 0, '25': 0, '35': 0, '45': 0,'125': 1,'135': 0, '145': 1,'235': 0,'245': 1,'345': 1,'1235': 1,'1245': 2,'1345': 1,'2345': 1, '12345': 2}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "18a455c4-4c4b-4baa-9e0f-c0a1429e1208",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_f_l5=pd.DataFrame([f_l5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "40523b49-02d3-4deb-a17e-b508ab7fe8c1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e_n : d_n\n",
      "169    1\n",
      "Name: Eg_Size, dtype: int64\n",
      "CPU times: total: 422 ms\n",
      "Wall time: 650 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# df_f_l5=pd.DataFrame([f_l5])\n",
    "power_set_str=get_powerset_str(5)\n",
    "df_f_l5_eg=get_Eg_column_Pn(df_f_l5)\n",
    "df_f_l5_eg=df_f_l5_eg.sort_values('Eg_Size') # get those 13,then 19\n",
    "df=df_f_l5_eg\n",
    "print(f\"e_n : d_n\")\n",
    "print(df['Eg_Size'].value_counts()) #count number of 13s and 19s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78a8d66-0dee-4149-b5b8-e7b965561afa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cd3a06d0-86f4-4bc0-94bd-e5c28a71a163",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Remark <a name=\"s43\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62584730-b2f3-49d9-8195-8ee9c503a106",
   "metadata": {},
   "source": [
    "As there are many functions $f$ that also give $U_n$ (and similarly $L_{n}$), we wish to determine whether if  for all such $f$, we have $\\mathbb{E}(f)$ are equal. We show this is not the case."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b6c91da-c08e-45e1-a197-d1f4c114b002",
   "metadata": {},
   "source": [
    "Simplist case to consider is $\\tilde{P}_3$. We determine $f \\in \\tilde{P}_3$ and determine $\\mathbb{E}(f)$ for each, then extract those $f$ such that we have\n",
    "$|\\mathbb{E}(f)|=U_3$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed531b01-cbab-41b5-a1b5-d1a23a51d083",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get P3\n",
    "P2=pd.DataFrame([{'1': 0, '2': 0, '12': 0},{'1': 0, '2': 0, '12': 1}])\n",
    "n=2\n",
    "power_set_str,power_set_str_np1=get_n_np1_powersets(n)\n",
    "P3=get_Pnp1(P2,2)\n",
    "print(P3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba9040c-e393-46c9-ab30-9de7b884ade9",
   "metadata": {},
   "outputs": [],
   "source": [
    "power_set_str=get_powerset_str(3)\n",
    "\n",
    "P3_eg=get_Eg_column_Pn(P3)\n",
    "P3_eg=P3_eg.sort_values('Eg_Size') # get those 13,then 19\n",
    "\n",
    "df=P3_eg\n",
    "print(f\"e_n : d_n\")\n",
    "print(df['Eg_Size'].value_counts()) #count number of 13s and 19s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205f15c9-9f8a-41de-bc77-5205affecea5",
   "metadata": {},
   "source": [
    "There are $4$ which give $U_3$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45881ad-5fc7-4ff5-9da2-2ebbd9cf9e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=P3_eg[P3_eg.Eg_Size == 19]\n",
    "print(y)\n",
    "print(y.shape)\n",
    "#Get Eg for the function in P3\n",
    "#3  0  0  0   0   0   0    1      19"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ef3baf-00a8-4fca-9fbb-caf7a2dad115",
   "metadata": {},
   "source": [
    "Remove \"Eg_Size\" column and turn to a list of dictionaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97544926-ad69-4b61-a781-f0b65f5bb174",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y.drop('Eg_Size', axis=1, inplace=True)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60cc642-b35b-4ac3-95cd-e9abd4dc00f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=y\n",
    "list_of_dicts = df.to_dict(orient='records')\n",
    "list_of_dicts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "147422cc-98ae-4c9d-ac3d-02ea5f8fe0e1",
   "metadata": {},
   "source": [
    "We now determine $\\mathbb{E}(g)$ for each of the above functions. Recall get_Eg_for_single_g(). \n",
    "\n",
    "As the order of the output of get_Eg_for_single_g() can vary we sort everything into a standard format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42459e2-d6e4-4f44-a33e-ecad1310eb07",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Eg_cases=[]\n",
    "sorted_Eg_cases = []\n",
    "\n",
    "for g in list_of_dicts:\n",
    "    print(g)\n",
    "    #[{'1': 0, '2': 0, '3': 0, '12': 0, '13': 0, '23': 0, '123': 1},\n",
    "    EEg_example=get_Eg_for_single_g_dict(g,power_set_str)\n",
    " # [frozenset({'12'}), frozenset({'2', '23', '13', '12', '1'}), frozenset({'2', '23', '3', '13', '12', '1', '123'}), \n",
    " #  frozenset({'2', '23', '3', '13', '12', '1'}), frozenset({'23'}), frozenset({'13', '12', '2', '23'}),\n",
    " #  frozenset({'1', '13', '12'}), frozenset({'13', '12'}), frozenset({'12', '23'}), frozenset({'2', '23', '3', '13', '12'}), \n",
    " #  frozenset({'13', '23'}), frozenset({'13', '12', '23', '3'}), frozenset({'23', '3', '13', '12', '1'}), frozenset({'1', '13', '12', '23'}), \n",
    " #  frozenset({'13', '12', '23'}), frozenset({'13', '23', '3'}), frozenset({'13'}), frozenset({'12', '2', '23'}), frozenset()] \n",
    "    \n",
    "    e=EEg_example\n",
    "    sorted_e=[] #elements are\n",
    "    # [['12'], ['1', '12', '13', '2', '23'], ['1', '12', '123', '13', '2', '23', '3'], ['1', '12', '13', '2', '23', '3'],\n",
    "    #  ['23'], ['12', '13', '2', '23'], ['1', '12', '13'], ['12', '13'], ['12', '23'], ['12', '13', '2', '23', '3'], ['13', '23'],\n",
    "    #  ['12', '13', '23', '3'], ['1', '12', '13', '23', '3'], \n",
    "    #  ['1', '12', '13', '23'], ['12', '13', '23'], ['13', '23', '3'], ['13'], ['12', '2', '23'], []]\n",
    "    for fs in e:\n",
    "        sorted_fs=sorted(list(fs))\n",
    "        sorted_e.append(sorted_fs)\n",
    "        \n",
    "    sorted_Eg_cases.append(sorted_e)\n",
    "    print(sorted_e,\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa54bfaf-fec0-4ad3-85ca-9c9ec4374bad",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a65a19df-a0c9-4def-ae99-ab003f19daa2",
   "metadata": {},
   "source": [
    "What is $\\mathbb{E}(g)$. \n",
    "\n",
    "{'1': 0, '2': 0, '3': 0, '12': 0, '13': 0, '23': 0, '123': 0}\n",
    "[['12', '123', '13'], ['12', '123', '2', '23'], ['1', '12', '123', '13', '2', '23', '3'], ['12', '123'], ['1', '12', '123', '13', '2', '23'], ['123', '13'], ['12', '123', '13', '23', '3'], ['12', '123', '13', '2', '23', '3'], ['123', '23'], ['123', '13', '23'], ['12', '123', '23'], ['12', '123', '13', '23'], ['1', '12', '123', '13', '23'], ['123', '13', '23', '3'], ['12', '123', '13', '2', '23'], ['1', '12', '123', '13', '23', '3'], ['1', '12', '123', '13'], ['123'], []] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0399b96-4624-4d19-a7ca-e943928d3518",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Previous code to pick a good candidate that gives L_n\n",
    "\n",
    "y=P3_eg[P3_eg.Eg_Size == 13]\n",
    "print(y)\n",
    "print(y.shape)\n",
    "#Get Eg for the function in P3\n",
    "#3  0  0  0   0   0   0    1      19\n",
    "\n",
    "y.drop('Eg_Size', axis=1, inplace=True)\n",
    "# y\n",
    "df=y\n",
    "list_of_dicts = df.to_dict(orient='records')\n",
    "list_of_dicts\n",
    "\n",
    "# Eg_cases=[]\n",
    "sorted_Eg_cases = []\n",
    "\n",
    "for g in list_of_dicts:\n",
    "    print(g)\n",
    "# {'1': 0, '2': 0, '3': 0, '12': 0, '13': 0, '23': 1, '123': 1}\n",
    "    EEg_example=get_Eg_for_single_g(g,power_set_str)\n",
    "\n",
    "    \n",
    "    e=EEg_example\n",
    "    sorted_e=[] #elements are\n",
    "  # [['12'], ['12', '123', '13', '2', '3'], ['12', '13', '2', '3'], ['13', '3'], ['12', '13', '3'], ['1', '12', '123', '13', '2', '23', '3'], ['12', '13', '2'], ['12', '2'], ['12', '123', '13', '2', '23', '3'], ['12', '13'], ['1', '12', '123', '13', '2', '3'], ['13'], []] \n",
    "    for fs in e:\n",
    "        sorted_fs=sorted(list(fs))\n",
    "        sorted_e.append(sorted_fs)\n",
    "        \n",
    "    sorted_Eg_cases.append(sorted_e)\n",
    "    print(sorted_e,\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef935d6-0b06-4e68-ae67-31b2c92e7c0d",
   "metadata": {},
   "source": [
    "We see that for $f$={'1': 0, '2': 0, '3': 0, '12': 0, '13': 1, '23': 1, '123': 1}.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b08ada3d-01b8-4c51-839c-e0155c39b463",
   "metadata": {},
   "source": [
    "We have $\\mathbb{E}(f)$=\n",
    "[['12', '3'], ['12'], ['1', '12', '123', '2', '3'], ['12', '123', '2', '23', '3'], ['1', '12', '123', '13', '2', '23', '3'], ['1', '12', '123', '2', '23', '3'], ['12', '123', '3'], ['12', '123', '2', '3'], ['1', '12', '123', '13', '2', '3'], ['3'], ['1', '12', '123', '13', '3'], ['1', '12', '123', '3'], []] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d90d5c5-c675-46ba-93b6-a2da465870f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "P3_eg=get_Eg_column_Pn(P3)\n",
    "P3_eg=P3_eg.sort_values('Eg_Size') # get those 13,then 19\n",
    "\n",
    "df=P3_eg\n",
    "print(f\"e_n : d_n\")\n",
    "print(df['Eg_Size'].value_counts()) #count number of 13s and 19s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ff6d82-9142-4e4a-bb06-c9eff6bf32ab",
   "metadata": {},
   "source": [
    "For example we can extract exactly all those function which have $|\\mathbb{E}(g)|=13$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f73c196-e456-4680-8358-d707d625a0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=P3_eg[P3_eg.Eg_Size == 13]\n",
    "print(y)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a3d4022-addf-413e-90b4-d2ae33bb653c",
   "metadata": {},
   "source": [
    "Similar to section \"4) Example $\\mathbb{E}(g)$ for $g \\in  \\tilde{P}_{3}$\" we can obtain $E(g)$ for a fixed function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37806ca-c8bd-4466-8ea9-a5595cf34390",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get Eg for the function in P3\n",
    "#3  0  0  0   0   0   0    1      19\n",
    "numb =3\n",
    "df=P3\n",
    "g=df.iloc[numb].to_dict()\n",
    "\n",
    "g={'1': 0, '2': 0, '3': 0, '12': 0, '13': 0, '23': 0, '123': 1}\n",
    "\n",
    "print(g,\"\\n\")\n",
    "EEg_example=get_Eg_for_single_g(df,numb,power_set_str)\n",
    "EEg_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2bda558-827f-4d8a-bac8-32a4b54b0dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_Eg_for_single_g(df,numb,power_set_str):\n",
    "\n",
    "#     #Obj: puts Eg into correct format to check if topolgoy\n",
    "#     #Inputs: df=Pn, numb used to get a specific function from df\n",
    "    \n",
    "#     # Pick function in Pn\n",
    "#     g=df.iloc[numb].to_dict()\n",
    "\n",
    "#     #get primitive closed sets\n",
    "#     PC=[(x,get_barj({x},g)) for x in power_set_str]\n",
    "#     dict_PC=dict(PC)\n",
    "#     set_PC=[sorted_frozenset(get_barj({x},g)) for x in power_set_str]\n",
    "\n",
    "#     #Get all closed sets for extensions for g\n",
    "#     Eg=list(get_Eg(dict_PC,power_set_str,set_PC))\n",
    "#     Eg.append(frozenset()) #rembmer the empty set\n",
    "#     return Eg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2aeffe-7291-4f7d-b542-901fff919010",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_Pnp1_for_single_funct(Pn,n):\n",
    "    \n",
    "#     #inputs\n",
    "#     # Pn:dataframe and n.\n",
    "    \n",
    "#     \"\"\"\n",
    "#     Returns a dataframe of extensions in Pn+1 for dataframe of functions in Pn.\n",
    "#     \"\"\"\n",
    "#     \"\"\"\n",
    "#     #Example\n",
    "#     n=3\n",
    "#     power_set_str,power_set_str_np1=get_n_np1_powersets(n)\n",
    "#     # P3\n",
    "\n",
    "#     funct_list=[{'1': 0,'2': 0,\"3\":0,\"12\":0,\"23\":0,\"13\":0,\"123\":0}]\n",
    "#     Pn=pd.DataFrame(funct_list)\n",
    "\n",
    "#     #The following should be functions in P4 that are extendions of functions in funct_list\n",
    "#     f_P3=get_Pnp1_for_single_funct(Pn,n)\n",
    "#     print(f_P3)\n",
    "#     \"\"\"\n",
    "\n",
    "#     #New data created\n",
    "#     power_set_str,power_set_str_np1=get_n_np1_powersets(n)\n",
    "\n",
    "#     #Load Pn as a list of dictionaries.\n",
    "#     list_df_Pn=Pn.to_dict(orient='records')\n",
    "\n",
    "#     #Create Pn+1 and hold as dataframe.\n",
    "#     P_n1=eg_column_Build_Pn_1(list_df_Pn,power_set_str,n)\n",
    "#     #As previous was done in E(g) parts, joint together\n",
    "#     Pnp1=extend_sets_to_Pnp1(P_n1)\n",
    "        \n",
    "#     Pnp1=get_Eg_column_Pn(Pnp1)\n",
    "    \n",
    "#     columns=list(power_set_str_np1)+[\"Eg_Size\"]\n",
    "#     Pnp1 = Pnp1.reindex(columns=columns)\n",
    "    \n",
    "#     # inspect_Pn1(Pnp1)\n",
    "\n",
    "#     return Pnp1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a709733b-7718-467e-a62f-f477342ec486",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def check_all_funct_topspace(df,power_set_str):\n",
    "#     length=[]\n",
    "#     for i,g in enumerate(df.to_dict(\"records\")): #list of dictionaries of functions\n",
    "#         check_top=check_top_for_single_g(df,i,power_set_str)\n",
    "#         if check_top == False:\n",
    "#             print(f\"Function {i} does NOT give a topolgical space: {check_top}\")\n",
    "#         else:\n",
    "#             length.append(check_top)\n",
    "            \n",
    "#     if len(df.to_dict(\"records\"))==len(length):\n",
    "#         print(\"Every function produces a topological space\" )\n",
    "#     else:\n",
    "#         print(\"something is not a topological space\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54482ac-172c-4846-91a8-0373067a01ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def is_finite_topological_space(X, T):\n",
    "    \n",
    "#     \"\"\"\n",
    "#         # Does this account for unions? \n",
    "\n",
    "#     # X = {'a', 'b', 'c'}\n",
    "#     # T = [X, set(), {'a'}, { 'c'}, {'b'}]\n",
    "#     # print(is_finite_topological_space(X, T)) # prints False\n",
    "\n",
    "#     # This condition is not met because the union of {'a'} and {'c'} is {'a','c'} which is not in T.\n",
    "#     \"\"\"\n",
    "    \n",
    "#     if not all(isinstance(x, set) for x in T):\n",
    "#         # T must be a collection of sets\n",
    "#         print(x)\n",
    "        \n",
    "#         return False\n",
    "#     if not all(x.issubset(X) for x in T):\n",
    "#         # Each element of T must be a subset of X\n",
    "#         print(\"here1\")\n",
    "\n",
    "#         return False\n",
    "#     if not all(x.intersection(y) in T for x in T for y in T):\n",
    "#         print(\"here2\")\n",
    "\n",
    "#         # The intersection of any two elements of T must be in T\n",
    "#         return False\n",
    "#     if not all(x.union(y) in T for x in T for y in T):\n",
    "#         # The union of any two elements of T must be in T\n",
    "#         print(\"here3\")\n",
    "#         return False\n",
    "    \n",
    "#     if not X in T:\n",
    "#         print(\"here4\")\n",
    "#         print(x)\n",
    "\n",
    "#         # X must be in T\n",
    "#         return False\n",
    "#     if not set() in T:\n",
    "#         print(\"here5\")\n",
    "\n",
    "#         # The empty set must be in T\n",
    "#         return False\n",
    "#     return True\n",
    "\n",
    "# def check_top_for_single_g(df,numb,power_set_str):\n",
    "#     #Inputs:\n",
    "#     # df=Pn\n",
    "#     # numb=choice of function\n",
    "#     # power_set_str for df\n",
    "    \n",
    "#     # Output:True or False\n",
    "    \n",
    "#     Eg=get_Eg_for_single_g(df,numb,power_set_str)\n",
    "#     Top=list(set(x) for x in Eg)\n",
    "#     Top.append(set())\n",
    "    \n",
    "#     X_Eg=set(power_set_str)\n",
    "    \n",
    "#     return is_finite_topological_space(X_Eg, Top)\n",
    "\n",
    "\n",
    "# def check_df_duplicates(df1,df2,How,value):\n",
    "#         \"\"\"\n",
    "#     Objective:\n",
    "#     Input:\n",
    "#     Returns:\n",
    "#     \"\"\"\n",
    "#     #Compare df1,df2 if that common rows\n",
    "    \n",
    "#     # how is either \"right\" or \"left\"\n",
    "#     # for left gives those in df1 and says True or false if also in df2\n",
    "    \n",
    "#     #     example\n",
    "#     #     df1 = pd.DataFrame({'team' : ['A', 'B', 'C', 'D', 'E'], \n",
    "#     #                     'points' : [12, 15, 22, 29, 24]}) \n",
    "#     #  #create second DataFrame\n",
    "#     # df2 = pd.DataFrame({'team' : ['A', 'D', 'F', 'G', 'H'],\n",
    "#     #                     'points' : [12, 29, 15, 19, 10]})\n",
    "    \n",
    "#     #merge two dataFrames and add indicator column\n",
    "#     all_df = pd.merge(df1, df2, how=How, indicator='exists')\n",
    "\n",
    "#     #add column to show if each row in first DataFrame exists in second\n",
    "#     all_df['exists'] = np.where(all_df.exists == 'both', True, False)\n",
    "\n",
    "#     #view updated DataFrame\n",
    "#     # print (all_df)\n",
    "\n",
    "#     m=all_df.loc[all_df['exists'] == True]\n",
    "    \n",
    "#     #Number of terms common\n",
    "#     num_items = m.loc[m['exists'] == value].shape[0]\n",
    "#     print(f\"Number of those in both: {num_items} \\n\")\n",
    "\n",
    "#     return m    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82245cc3-6aef-4d47-9238-309d07fdd4ea",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Examples for understanding code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "812f3d77-e016-4f04-a3ce-3f15d6394da2",
   "metadata": {},
   "source": [
    "Are primitive closed sets a basis for the topology? (Maybe not relevant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc939b0b-3234-4592-8b67-cadea14c5757",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Asides:\n",
    "- Is Eg a matriod? No does not satisfy downward closure. In our sepcific example f(12)=1,f(123)=1 else 0 Take {1} in the closure of 1 i.e {1,13}, {1} is not a closed set.\n",
    "- Are primite closed sets a basis for the topology? Is there a way to construct $\\mathbb{E}(g)$ using primitive (using minimal basis)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ae0abb-2438-4c3d-b8e3-9b22e1c8d0ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# dict_PC,set_PC=get_primitive_for_single_g(df,numb)\n",
    "\n",
    "# # print(dict_PC) #Remembers what the terms of powerset is\n",
    "# set_PC.append(frozenset()) # add empty set: this is the set of primitive closed sets\n",
    "# # for i in set_PC:\n",
    "# #     print(set(i))\n",
    "    \n",
    "# X_Eg= {'13', '23', '123', '12', '2', '3', '1'} #total space ie powerset\n",
    "# Prim_Top= list(set(x) for x in set_PC) # primitive set as a topology? is it a basis?\n",
    "\n",
    "# def is_basis(X, T, B):\n",
    "#     if not all(isinstance(x, set) for x in B):\n",
    "#         # B must be a collection of sets\n",
    "#         return False\n",
    "#     if not all(x.issubset(X) for x in B):\n",
    "#         # Each element of B must be a subset of X\n",
    "#         return False\n",
    "    \n",
    "    \n",
    "#     if not all(x.intersection(y) == set() for x in B for y in B if x != y):\n",
    "#         # The intersection of any two distinct elements of B must be empty\n",
    "#         return False\n",
    "    \n",
    "#     if not all(x.union(y) in T for x in B for y in B):\n",
    "#         # The union of any two elements of T must be in T\n",
    "#         return False\n",
    "    \n",
    "#     if not all(x.issubset(y) or y.issubset(x) for x in B for y in T):\n",
    "#         # Each element of B must be a subset of some element of T or conversely\n",
    "#         return False\n",
    "#     return True\n",
    "\n",
    "# # Example usage\n",
    "# X = {'a', 'b', 'c'}\n",
    "# T = [X, set(), {'a', 'b'}, {'b', 'c'}, {'b'}]\n",
    "# B = [{'a', 'b'}, {'b', 'c'}]\n",
    "# print(is_basis(X, T, B)) # prints True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e67f6d6-6df5-45ad-9f97-3a91381e76c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get all functions in P3 stored a data frame\n",
    "\n",
    "#Construct P3\n",
    "pre_functs=[[\"12\",\"123\"],[\"13\",\"123\"],[\"23\",\"123\"],[\"12\",\"13\",\"123\"],[\"12\",\"23\",\"123\"],[\"13\",\"23\",\"123\"],[\"12\",\"13\",\"23\",\"123\"],[],[\"123\"]]\n",
    "ds=[]\n",
    "for vals in pre_functs:\n",
    "    builder1=[(x,1) for x in vals]\n",
    "    builder0=[(x,0) for x in power3 if x not in vals]\n",
    "    f_dict={**dict(builder1),**dict(builder0)}\n",
    "    ds.append(f_dict)\n",
    "big={'123': 2, '1': 0, '2': 0, '3': 0, '12': 1, '13': 1, '23': 1} #remaining case, with 2 value\n",
    "dp=ds+[big,]\n",
    "\n",
    "#Build dataframe\n",
    "P3 = pd.DataFrame(dp)\n",
    "\n",
    "#order columns of P3\n",
    "power3=get_powerset_str(3) #powerset on 3 elements #for \n",
    "column_order=power3 #as strings\n",
    "P3 = P3.reindex(columns=column_order)\n",
    "\n",
    "print(P3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50638e8e-56f6-42ea-a952-78841485fa15",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Checking if the calculations for P5, are the same as our old calculations for P5 in xlsx.\n",
    "\n",
    "# #Previous data P5 in correct format\n",
    "# dataframe2 = pd.read_excel('P4_P5_xlsx\\P_5.xlsx')\n",
    "\n",
    "# #Make sure columns are in the same order as P5\n",
    "\n",
    "# #Reordering columns\n",
    "# column_order=[int(x) for x in power_set_str_np1]\n",
    "# dataframe2 = dataframe2.reindex(columns=column_order)\n",
    "\n",
    "# #Making sure columns are the same, in string format\n",
    "# dataframe2=string_cols(dataframe2)\n",
    "\n",
    "# # print(dataframe2.head)\n",
    "# print(dataframe2.shape) #(10334, 31)\n",
    "\n",
    "# # n=4\n",
    "# # power_set_str,alt_power_set_str_np1=get_n_np1_powersets(n)\n",
    "# # check_functs_MSA(dataframe2,power_set_str_np1).shape #(0,0) i.e all are msa\n",
    "\n",
    "# Comparision of P5 and dataframe 2. We see they are the same.\n",
    "\n",
    "# compar=check_df_duplicates(P5,dataframe2,\"left\",True) #True:10334 , False:0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8bcb6fb-157f-48ad-a4f5-02b4fee4c27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # The calculations for P4, are the same as our old calculations for P4 in xlsx.\n",
    "\n",
    "# dataframe1 = pd.read_excel('P4_P5_xlsx\\P_4.xlsx')\n",
    "# #Making sure columns are the same, in string format and order as P4 above\n",
    "# dataframe1=string_cols(dataframe1)\n",
    "\n",
    "# # #Comparision of P4 and xlsx version\n",
    "# compar=check_df_duplicates(P4,dataframe1,\"left\",True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88dc3c7-0fb0-44e6-8253-15e1f937bbb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# n=3\n",
    "# # Create a set with 3 elements\n",
    "# # s = {1, 2, 3}\n",
    "# s=set(range(1,n+1))\n",
    "\n",
    "# # Generate all possible subsets of the set\n",
    "# power_set = [set(x)  for r in range(len(s) + 1) for x in itertools.combinations(s, r)]\n",
    "\n",
    "# # Print the power set\n",
    "# print(power_set)\n",
    "\n",
    "# power_set_str=[set_to_string(x) for x in power_set]\n",
    "# power_set_str=[set_to_string(x) for x in power_set if len(x)>0]\n",
    "# power_set_str\n",
    "\n",
    "# #Get a function in P3\n",
    "\n",
    "# val1_loc=[\"12\",\"123\"] #where it take 1\n",
    "# val0_loc= [x for x in power_set_str if x not in val1_loc] #where it takes 0\n",
    "# # print(val0_loc)\n",
    "\n",
    "# builder1=[(x,1) for x in val1_loc]\n",
    "# builder0=[(x,0) for x in val0_loc]\n",
    "# builder0\n",
    "# dict(builder0)\n",
    "# dict(builder1)\n",
    "# f_dict={**dict(builder1),**dict(builder0)}\n",
    "# f_dict\n",
    "\n",
    "# A,B=\"1\",\"123\"\n",
    "# print(f\"Is {A} subset of {B}, f minimal? : {fmin(A,B,f_dict)}\")\n",
    "# print(f\"Is {A} subset of {B}, f maximal? : {fmax(A,B,f_dict)}\")\n",
    "\n",
    "#Testing for obtaining primitive sets:\n",
    "# #Example\n",
    "# for x in power_set_str:\n",
    "#     print(x,get_barj({x},f_dict))\n",
    "\n",
    "#As all the closed sets, checked by hand:\n",
    "# 3 T term {'13', '123', '1', '3', '23', '2'}\n",
    "# 1 {'1', '13'}\n",
    "# 2 {'23', '2'}\n",
    "# 12 {'1', '12', '123', '13', '2', '23'} \n",
    "# 13 {'13'} # should be just 13\n",
    "# 23 {'23'} # should be 23\n",
    "# 123 {'13', '123', '1', '23', '2'} # should not have 3 or 12\n",
    "\n",
    "# Store primitive closed sets \n",
    "\n",
    "# PC=[(x,get_barj({x},f_dict)) for x in power_set_str]\n",
    "# dict_PC=dict(PC)\n",
    "# set_PC=[sorted_frozenset(get_barj({x},f_dict)) for x in power_set_str]\n",
    "# # set(set_PC)\n",
    "# Eg={sorted_frozenset(power_set_str)}.union(set_PC)\n",
    "\n",
    "# Using main functions:\n",
    "# Eg=list(get_Eg(dict_PC,power_set_str,set_PC))\n",
    "# # print(len(x)) # I get like 13 so this is an issue.\n",
    "# Eg\n",
    "# Eg.append(\"empty\")\n",
    "# Eg\n",
    "\n",
    "\n",
    "#Rows are not in the same order:\n",
    "# # print(P4.equals(dataframe1))\n",
    "\n",
    "#Checking if duplicates, #https://stackoverflow.com/questions/48647534/find-difference-between-two-data-frames?noredirect=1&lq=1\n",
    "# df = P4.merge(dataframe1, how = 'inner' ,indicator=False)\n",
    "\"\"\" \n",
    "# first dataframe\n",
    "df1 = pd.DataFrame({\n",
    "    'Age': ['20', '14', '56', '28', '10'],\n",
    "    'Weight': [59, 29, 73, 56, 48]})\n",
    "display(df1)\n",
    "\n",
    "# second dataframe\n",
    "df2 = pd.DataFrame({\n",
    "    'Age': ['16', '20', '24', '40', '22'],\n",
    "    'Weight': [55, 59, 73, 85, 56]})\n",
    "display(df2)\n",
    "\n",
    "#Common rows:\n",
    "df = df1.merge(df2, how = 'inner' ,indicator=False)\n",
    "print(df)\n",
    "\"\"\"\n",
    "\n",
    "\"The above method only works for those data frames that don't already have duplicates themselves. For example:\"\n",
    "no_dups=pd.concat([P4,dataframe1]).drop_duplicates(keep=False)\n",
    "no_dups.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6909d71f-36f7-427c-80b0-af89bc3a05e7",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "## E(g) is a topolgical space <a name=\"s4\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60cd9cf7-747b-4202-b2a1-978cbbf0d882",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "### Example f in P3 form a Topological space <a name=\"s41\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "580cf815-a85f-4c17-acd8-1d9b93849e69",
   "metadata": {},
   "source": [
    "The set $\\mathbb{E}(g)$ is the topology assoicated to the function $g$ and can be used to construct the extensions of $g$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11afd118-d73e-41e0-a898-67184ba96369",
   "metadata": {},
   "source": [
    "We now have:\n",
    "- A function/method to get $\\mathbb{E}(g)$.\n",
    "- A function to check if $\\mathbb{E}(g)$ is a finite topology.\n",
    "- Check if all function in P3,P4,P5 generate a topology: Answer P3,P4 yes, examples of P5 yes\n",
    "\n",
    "What we could do next:\n",
    "- A way to determine the size of $\\mathbb{E}(g)$ (using basis).\n",
    "- Are all Top(g) for $g \\in P_n$ homeomorphic? (topologies are different sizes)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c02253-1861-4545-a7ec-d524e0581875",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Specific Example from P3 is topological space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0cbb07e-026b-4f98-bde2-34061b09c1c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "power_set_str=get_powerset_str(3)\n",
    "\n",
    "df=P3\n",
    "numb=4\n",
    "#Get data\n",
    "Eg=get_Eg_for_single_g(df,numb,power_set_str)\n",
    "# print(power_set_str)\n",
    "print(P3.iloc[numb].to_dict(),\"\\n\")\n",
    "\n",
    "for term in Eg:\n",
    "    print(set(term))\n",
    "    \n",
    "print(\"\\n  All closed sets\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb349a0-98f1-4201-af27-60a38a21983d",
   "metadata": {},
   "source": [
    "Check if Eg is a finite topological space on the powerset for an example g in P3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28575e50-b390-4bc5-9a0a-759606995780",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Eg= {'13', '23', '123', '12', '2', '3', '1'} #total space ie powerset\n",
    "Top=list(set(x) for x in Eg) #topology\n",
    "\n",
    "print(is_finite_topological_space(X_Eg, Top))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a7c114-a8a1-454e-88d6-75f0c220a1a2",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Consider Top(g) for two different g,g' in P3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bda02a9-abbd-46d2-8ab9-78580bafcace",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setup data\n",
    "power_set_str=get_powerset_str(3)\n",
    "df=P3\n",
    "X_Eg= set(power_set_str) #total space ie powerset\n",
    "\n",
    "#Inputs\n",
    "numb1=0\n",
    "numb2=1\n",
    "\n",
    "#Top space 1\n",
    "Eg1=get_Eg_for_single_g(df,numb,power_set_str)\n",
    "Top1=list(set(x) for x in Eg1) #topology\n",
    "print(is_finite_topological_space(X_Eg, Top1))\n",
    "#------------------------------\n",
    "#Top space 2\n",
    "Eg2=get_Eg_for_single_g(df,numb2,power_set_str)\n",
    "Top2=list(set(x) for x in Eg2) #topology\n",
    "print(is_finite_topological_space(X_Eg, Top2))\n",
    "#------------------------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f2db93-ca23-46b3-a4f9-76e4c132804a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "### Check if all function in P3,P4,P5 generate a topological space: Yes <a name=\"s42\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c8e0f6-a8e7-4bea-9f36-324fb2e37861",
   "metadata": {
    "tags": []
   },
   "source": [
    "### P3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3492c0c7-9d9b-4f70-b8f2-d88967224c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#inputs\n",
    "df=P3\n",
    "power_set_str=get_powerset_str(3)\n",
    "check_all_funct_topspace(df,power_set_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2524d1a-961d-416b-b30f-59476b66e14a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### P4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473e1069-5d02-4497-acee-2729441e1377",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#inputs\n",
    "df=P4\n",
    "power_set_str=get_powerset_str(4)\n",
    "check_all_funct_topspace(df,power_set_str) #False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb5149c1-f805-426f-8719-0b5914af8c3b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### P5 (where Eg for a function allow for calc of part of P6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f69c5a-613c-4e92-ba29-3f5a151aa6dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Take long: \n",
    "\n",
    "#inputs\n",
    "df=P5\n",
    "power_set_str=get_powerset_str(5)\n",
    "check_all_funct_topspace(df,power_set_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc848042-cdd3-4222-8a95-95d5e9a1ddb6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Works for some choosen example.\n",
    "\n",
    "df=P5\n",
    "power_set_str=get_powerset_str(5)\n",
    "numb=0 # function indexed at 0\n",
    "\n",
    "Eg=get_Eg_for_single_g(df,numb,power_set_str) # set of closed sets\n",
    "X_Eg= set(power_set_str) #total space ie powerset\n",
    "Top=list(set(x) for x in Eg) #topology from closed sets Eg #Size: 1178\n",
    "\n",
    "print(len(Top))\n",
    "\n",
    "#Check whether topological space:\n",
    "print(is_finite_topological_space(X_Eg, Top)) #The total powerset on 4 elements is not included.\n",
    "\n",
    "#Result:\n",
    "#numb=0\n",
    "#1178 #Top size\n",
    "#True"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
